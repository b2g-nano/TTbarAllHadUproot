{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy.stats as ss\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea import util\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoesDirectoryExist(mypath): #extra precaution (Probably overkill...)\n",
    "    '''Checks to see if Directory exists before running mkdir_p'''\n",
    "    \n",
    "    if path.exists(mypath):\n",
    "        pass\n",
    "    else:\n",
    "        mkdir_p(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindirectory = os.getcwd() # changes accordingly\n",
    "print(maindirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reiterate categories ---- #\n",
    "ttagcats = [\"at\"] #, \"0t\", \"1t\", \"It\", \"2t\"]\n",
    "btagcats = [\"0b\", \"1b\", \"2b\"]\n",
    "ycats = ['cen', 'fwd']\n",
    "\n",
    "list_of_cats = [ t+b+y for t,b,y in itertools.product( ttagcats, btagcats, ycats) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filesets import filesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_unweighted = {}\n",
    "for name,files in filesets.items():\n",
    "    outputs_unweighted[name] = util.load('TTbarResCoffea_' + name + '_unweighted_output_partial_2021_dask_run.coffea')\n",
    "outputs_unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- CREATE RAW MISTAG PLOTS ---------------- \"\"\"\n",
    "# ---- Only Use This Cell When LookUp Tables Are Not In Use (i.e. UseLookUpTables = False) ---- #\n",
    "# ---- Mistag plot for every dataset in every category for debugging if necessary or for curiosity ---- #\n",
    "# ---- Look up tables are a bit more sophisticated and useful to the analysis ---- #\n",
    "\n",
    "SaveDirectory = maindirectory + '/MistagPlots/'\n",
    "DoesDirectoryExist(SaveDirectory) # no need to create the directory several times\n",
    "\n",
    "# Function sqrt(x)\n",
    "def forward(x):\n",
    "    return x**(1/2)\n",
    "\n",
    "\n",
    "def inverse(x):\n",
    "    return x**2\n",
    "\n",
    "print(SaveDirectory)\n",
    "for iset in filesets:\n",
    "    for icat in list_of_cats:\n",
    "        print(iset)\n",
    "        print(icat)\n",
    "        title = iset + ' mistag ' + icat\n",
    "        filename = 'mistag_' + iset + '_' + icat + '.' + 'png'\n",
    "        print(outputs_unweighted[iset]['numerator'])\n",
    "        Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat', icat).integrate('dataset', iset)\n",
    "        Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat', icat).integrate('dataset', iset)\n",
    "        print(Numerator)\n",
    "        print(Denominator)\n",
    "        mistag = hist.plotratio(num = Numerator, denom = Denominator,\n",
    "                                error_opts={'marker': '.', 'markersize': 10., 'color': 'k', 'elinewidth': 1},\n",
    "                                unc = 'num')\n",
    "        plt.title(title)\n",
    "        plt.ylim(bottom = 0, top = 0.12)\n",
    "        plt.xlim(left = 100, right = 2500)\n",
    "        \n",
    "        # ---- Better mistag plots are made in 'TTbarResCoffea_MistagAnalysis-BkgEst' python script ---- #\n",
    "        # ---- However, if one wants to save these raw plots, they may uncomment the following 5 lines ---- #\n",
    "        \n",
    "        #plt.xticks(np.array([0, 500, 600, 700]))\n",
    "        #mistag.set_xscale('function', functions=(forward, inverse))\n",
    "        #mistag.set_xscale('log')\n",
    "        #plt.savefig(SaveDirectory+filename, bbox_inches=\"tight\")\n",
    "        #print(filename + ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- Scale-Factors for JetHT Data According to Year---------------- \"\"\"\n",
    "Nevts2016 = 625516390. # from dasgoclient\n",
    "Nevts2017 = 410461585. # from dasgoclient\n",
    "Nevts2018 = 676328827. # from dasgoclient\n",
    "Nevts = Nevts2016 + Nevts2017 + Nevts2018 # for all three years\n",
    "\n",
    "if 'JetHT2016_Data' in filesets:\n",
    "    Nevts2016_sf = Nevts2016/outputs_unweighted['JetHT2016_Data']['cutflow']['all events']\n",
    "    print(Nevts2016_sf)\n",
    "if 'JetHT2017_Data' in filesets:\n",
    "    Nevts2017_sf = Nevts2017/outputs_unweighted['JetHT2017_Data']['cutflow']['all events']\n",
    "    print(Nevts2017_sf)\n",
    "if 'JetHT2018_Data' in filesets:\n",
    "    Nevts2018_sf = Nevts2018/outputs_unweighted['JetHT2018_Data']['cutflow']['all events']\n",
    "    print(Nevts2018_sf)\n",
    "if 'JetHT' in filesets:\n",
    "    Nevts_sf = Nevts / outputs_unweighted['JetHT']['cutflow']['all events']\n",
    "    print(Nevts_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- Luminosities, Cross Sections, Scale-Factors ---------------- \"\"\" \n",
    "Lum2016 = 35920. # pb^-1 from https://twiki.cern.ch/twiki/bin/viewauth/CMS/PdmVAnalysisSummaryTable\n",
    "Lum2017 = 41530.\n",
    "Lum2018 = 59740.\n",
    "Lum     = 137190.\n",
    "\n",
    "ttbar_BR = 0.457 # 0.442 from PDG 2018\n",
    "ttbar_xs = 1.0   # Monte Carlo already includes xs in event weight!! Otherwise, ttbar_xs = 831.76 * ttbar_BR  pb\n",
    "\n",
    "ttbar2016_sf = ttbar_xs*Lum2016/(142155064.)\n",
    "ttbar2017_sf = ttbar_xs*Lum2017/(142155064.)\n",
    "ttbar2018_sf = ttbar_xs*Lum2018/(142155064.)\n",
    "ttbar_sf = ttbar_xs*Lum/(142155064.)\n",
    "\n",
    "print(ttbar2016_sf)\n",
    "print(ttbar2017_sf)\n",
    "print(ttbar2018_sf)\n",
    "print(ttbar_sf)\n",
    "\n",
    "qcd_xs = 1370000000.0 #pb From https://cms-gen-dev.cern.ch/xsdb\n",
    "#qcd_sf = qcd_xs*Lum/18455107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- CREATE LOOK UP TABLE .CSV FILES ---------------- \"\"\"\n",
    "\n",
    "runLUTS = True # Make separate Directory to place Look-Up Tables and perform ttbar subtraction for mistag weights\n",
    "\n",
    "def multi_dict(K, type): # definition from https://www.geeksforgeeks.org/python-creating-multidimensional-dictionary/\n",
    "    if K == 1: \n",
    "        return defaultdict(type) \n",
    "    else: \n",
    "        return defaultdict(lambda: multi_dict(K-1, type))\n",
    "    \n",
    "luts = {}\n",
    "luts = multi_dict(2, str)\n",
    "\n",
    "if runLUTS : \n",
    "\n",
    "    SaveDirectory = maindirectory + '/LookupTables/'\n",
    "    DoesDirectoryExist(SaveDirectory)\n",
    "    \n",
    "    # ---- Check if TTbar simulation was used in previous processor ---- #\n",
    "    if 'TTbar' in filesets:\n",
    "        for iset in filesets:\n",
    "            filename = 'mistag_' + iset + '_' + icat + '.' + 'csv'\n",
    "            #if iset != 'TTbar' or iset != 'QCD': # if JetHT filesets are found...\n",
    "            if 'JetHT' in iset:\n",
    "                print('\\t\\tfileset: ' + iset + '\\n*****************************************************\\n')\n",
    "                for icat in list_of_cats:\n",
    "                    title = iset + ' mistag ' + icat\n",
    "\n",
    "                    # ---- Info from TTbar ---- #\n",
    "                    Numerator_tt = outputs_unweighted['TTbar']['numerator'].integrate('anacat',icat).integrate('dataset','TTbar')\n",
    "                    Denominator_tt = outputs_unweighted['TTbar']['denominator'].integrate('anacat',icat).integrate('dataset','TTbar')\n",
    "                    N_vals_tt = Numerator_tt.values()[()] \n",
    "                    D_vals_tt = Denominator_tt.values()[()] \n",
    "\n",
    "                    # ---- Info from JetHT datasets ---- #\n",
    "                    Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                    Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                    N_vals = Numerator.values()[()]\n",
    "                    D_vals = Denominator.values()[()]\n",
    "\n",
    "                    # ---- Properly scale chunks of data and ttbar MC according to year of dataset used---- #\n",
    "                    if '2016' in iset:\n",
    "                        N_vals *= Nevts2016_sf \n",
    "                        D_vals *= Nevts2016_sf\n",
    "                        N_vals_tt *= ttbar2016_sf\n",
    "                        D_vals_tt *= ttbar2016_sf\n",
    "                    elif '2017' in iset:\n",
    "                        N_vals *= Nevts2017_sf \n",
    "                        D_vals *= Nevts2017_sf\n",
    "                        N_vals_tt *= ttbar2017_sf\n",
    "                        D_vals_tt *= ttbar2017_sf\n",
    "                    elif '2018' in iset:\n",
    "                        N_vals *= Nevts2018_sf \n",
    "                        D_vals *= Nevts2018_sf\n",
    "                        N_vals_tt *= ttbar2018_sf\n",
    "                        D_vals_tt *= ttbar2018_sf\n",
    "                    else: # all years\n",
    "                        N_vals *= Nevts_sf \n",
    "                        D_vals *= Nevts_sf\n",
    "                        N_vals_tt *= ttbar_sf\n",
    "                        D_vals_tt *= ttbar_sf\n",
    "\n",
    "                    # ---- Subtract ttbar MC probe momenta from datasets' ---- #\n",
    "                    N_vals_diff = np.abs(N_vals-N_vals_tt)\n",
    "                    D_vals_diff = np.abs(D_vals-D_vals_tt)\n",
    "\n",
    "                    print(N_vals_diff)\n",
    "                    print(D_vals_diff)\n",
    "                    print()\n",
    "\n",
    "                    # ---- Define Mistag values ---- #\n",
    "                    mistag_vals = np.where(D_vals_diff > 0, N_vals_diff/D_vals_diff, 0)\n",
    "                    \n",
    "                    # ---- Define Momentum values ---- #\n",
    "                    p_vals = []\n",
    "                    for iden in Numerator.identifiers('jetp'):\n",
    "                        p_vals.append(iden)\n",
    "\n",
    "                    # ---- Display and Save Dataframe, df, as Look-up Table ---- #\n",
    "                    print('fileset:  ' + iset)\n",
    "                    print('category: ' + icat)\n",
    "                    print('________________________________________________\\n')\n",
    "\n",
    "                    d = {'p': p_vals, 'M(p)': mistag_vals} # 'data'\n",
    "\n",
    "                    print(\"d vals = \", d)\n",
    "                    print()\n",
    "                    df = pd.DataFrame(data=d)\n",
    "                    luts[iset][icat] = df\n",
    "\n",
    "                    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                        print(df)\n",
    "                    print('\\n')\n",
    "\n",
    "                    df.to_csv(SaveDirectory+filename) # use later to collect bins and weights for re-scaling\n",
    "            else: # If iset is not JetHT...\n",
    "                for icat in list_of_cats:\n",
    "                    Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                    Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                    N_vals = Numerator.values()[()]\n",
    "                    D_vals = Denominator.values()[()]\n",
    "                    print(N_vals)\n",
    "                    print(D_vals)\n",
    "                    print()\n",
    "                    mistag_vals = np.where(D_vals > 0, N_vals/D_vals, 0)\n",
    "\n",
    "                    p_vals = [] # Momentum values\n",
    "                    for iden in Numerator.identifiers('jetp'):\n",
    "                        p_vals.append(iden)\n",
    "                    print('fileset:  ' + iset)\n",
    "                    print('category: ' + icat)\n",
    "                    print('________________________________________________\\n')\n",
    "                    d = {'p': p_vals, 'M(p)': mistag_vals}\n",
    "\n",
    "                    print(\"d vals = \", d)\n",
    "                    print()\n",
    "                    df = pd.DataFrame(data=d)\n",
    "                    luts[iset][icat] = df\n",
    "\n",
    "                    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                        print(df)\n",
    "                    print('\\n')\n",
    "\n",
    "                    df.to_csv(SaveDirectory+filename) # use later to collect bins and weights for re-scaling\n",
    "\n",
    "    else: # If iset did not run over 'TTbar' Simulation...\n",
    "        for iset in filesets:\n",
    "            print('\\t\\tfileset: ' + iset + '\\n*****************************************************\\n')\n",
    "            for icat in list_of_cats:\n",
    "                Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "                N_vals = Numerator.values()[()]\n",
    "                D_vals = Denominator.values()[()]\n",
    "                print(N_vals)\n",
    "                print(D_vals)\n",
    "                print()\n",
    "                \n",
    "                mistag_vals = np.where(D_vals > 0, N_vals/D_vals, 0)\n",
    "\n",
    "                p_vals = []\n",
    "                for iden in Numerator.identifiers('jetp'):\n",
    "                    p_vals.append(iden)\n",
    "                    \n",
    "                print('fileset:  ' + iset)\n",
    "                print('category: ' + icat)\n",
    "                print('________________________________________________\\n')\n",
    "                d = {'p': p_vals, 'M(p)': mistag_vals}\n",
    "\n",
    "                print(\"d vals = \", d)\n",
    "                print()\n",
    "                df = pd.DataFrame(data=d)\n",
    "                luts[iset][icat] = df\n",
    "\n",
    "                with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                    print(df)\n",
    "                print('\\n')\n",
    "\n",
    "                df.to_csv(SaveDirectory+filename) # use later to collect bins and weights for re-scaling\n",
    "            \n",
    "else : # If runLUTS = False, read in [previously made] Look Up Table csv's\n",
    "    for iset in filesets:\n",
    "        print('\\t\\tfileset: ' + iset + '\\n*****************************************************\\n')\n",
    "        for icat in list_of_cats:\n",
    "            title = iset + ' mistag ' + icat\n",
    "            filename = 'mistag_' + iset + '_' + icat + '.' + 'csv'\n",
    "            luts[iset][icat] = pd.read_csv(filename)\n",
    "print(luts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script TTbarResLookUpTables.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

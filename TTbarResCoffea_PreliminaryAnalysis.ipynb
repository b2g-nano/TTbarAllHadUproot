{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays unweighted plots from the corresponding Coffea outputs.  The plots are categorized according to the histogram name (dependant variable) and the tag category defined in the `TTbarResProcessor`.  \n",
    "# NOTE: #\n",
    "All QCD MC histograms are normalized directly to the data, as no corrections are applied via mistag analysis or modmass procedures anyways.  For a more realistic analysis, refer to `TTbarResCoffea_BkgEstAnalysis` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hist\n",
    "from coffea import util\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = 'CoffeaOutputsForCombine/Coffea_FirstRun/'\n",
    "\n",
    "btagdir = ''\n",
    "yeardir = '2016/'\n",
    "\n",
    "APVDir = {\n",
    "    'preVFP': 'APV/',\n",
    "    'postVFP': 'noAPV/'\n",
    "}\n",
    "\n",
    "od = ''\n",
    "oddir = ''\n",
    "if btagdir == '':\n",
    "    od = '_oldANdisc'\n",
    "    oddir = 'Old2016_MediumBTag/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All Data Eras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JetHT2016_unweighted = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfp = 'preVFP'\n",
    "for Era in ['B', 'C', 'D', 'E', 'F']:\n",
    "    JetHT2016_unwgt_str = f'TTbarRes_0l_UL16{vfp}_JetHT{Era}_Data'\n",
    "    JetHT2016_unweighted[Era+'_'+vfp] = util.load(f'{dir1}JetHT/{btagdir}{yeardir}{APVDir[vfp]}{JetHT2016_unwgt_str}{od}.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfp = 'postVFP'\n",
    "for Era in ['F', 'G', 'H']:\n",
    "    JetHT2016_unwgt_str = f'TTbarRes_0l_UL16{vfp}_JetHT{Era}_Data'\n",
    "    JetHT2016_unweighted[Era+'_'+vfp] = util.load(f'{dir1}JetHT/{btagdir}{yeardir}{APVDir[vfp]}{JetHT2016_unwgt_str}{od}.coffea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTbar_unweighted = {}\n",
    "QCD_unweighted = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vfp in ['preVFP', 'postVFP']:\n",
    "    TTbar_unwgt_str = f'TTbarRes_0l_UL16{vfp}_TTbar'\n",
    "    TTbar_unweighted[vfp] = util.load(f'{dir1}TT/{btagdir}{yeardir}{APVDir[vfp]}{TTbar_unwgt_str}{od}.coffea')\n",
    "    \n",
    "    QCD_unwgt_str = f'TTbarRes_0l_UL16{vfp}_QCD'\n",
    "    QCD_unweighted[vfp] = util.load(f'{dir1}QCD/{btagdir}{yeardir}{APVDir[vfp]}{QCD_unwgt_str}{od}.coffea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cutflow can be checked if desired "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EraB = np.array([])\n",
    "EraC = np.array([])\n",
    "EraD = np.array([])\n",
    "EraE = np.array([])\n",
    "EraF1 = np.array([])\n",
    "EraF2 = np.array([])\n",
    "EraG = np.array([])\n",
    "EraH = np.array([])\n",
    "for dataset,output in JetHT2016_unweighted.items():\n",
    "    if 'B' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraB = np.append(EraB,j)\n",
    "        print(EraB)\n",
    "    elif 'C' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraC = np.append(EraC,j)\n",
    "        print(EraC)\n",
    "    elif 'D' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraD = np.append(EraD,j)\n",
    "        print(EraD)\n",
    "    elif 'E' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraE = np.append(EraE,j)\n",
    "        print(EraE)\n",
    "    elif 'F_pre' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraF1 = np.append(EraF1,j)\n",
    "        print(EraF1)\n",
    "    elif 'F_post' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraF2 = np.append(EraF2,j)\n",
    "        print(EraF2)\n",
    "    elif 'G' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraG = np.append(EraG,j)\n",
    "        print(EraG)\n",
    "    if 'H' in dataset:\n",
    "        print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "        for i,j in output['cutflow'].items(): \n",
    "            EraH = np.append(EraH,j)\n",
    "        print(EraH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllData = EraB + EraC + EraD + EraE + EraF1 + EraF2 + EraG + EraH\n",
    "index = 0\n",
    "print(\"------- Unweighted Data Sum of Cutflows--------\")\n",
    "for i,j in JetHT2016_unweighted['B_preVFP']['cutflow'].items():\n",
    "    print( '%20s : %10i' % (i,AllData[index]) )\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for dataset,output in Datasets.items():\n",
    "#     print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "#     for i,j in output['cutflow'].items():        \n",
    "#         print( '%20s : %20s' % (i,j) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoesDirectoryExist(mypath): #extra precaution (Probably overkill...)\n",
    "    '''Checks to see if Directory exists before running mkdir_p'''\n",
    "    import os.path\n",
    "    from os import path\n",
    "    \n",
    "    if path.exists(mypath):\n",
    "        pass\n",
    "    else:\n",
    "        mkdir_p(mypath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare to Loop through Analysis Categories and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re # regular expressions\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- Reiterate categories ---- #\n",
    "ttagcats = [\"AT&Pt\", \"at\", \"pret\", \"0t\", \"1t\", \">=1t\", \"2t\", \">=0t\"] \n",
    "btagcats = [\"0b\", \"1b\", \"2b\"]\n",
    "ycats = ['cen', 'fwd']\n",
    "\n",
    "list_of_cats = [ t+b+y for t,b,y in itertools.product( ttagcats, btagcats, ycats) ]\n",
    "label_dict = {i: label for i, label in enumerate(list_of_cats)}\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindirectory = os.getcwd() # prepare to locally save images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminosity, Cross Sections and Scale Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nevts2016 = 625441538 # from dasgoclient\n",
    "Nevts2016_sf = Nevts2016/AllData[0]\n",
    "\n",
    "Lum2016 = 35920./Nevts2016_sf # pb^-1 from https://twiki.cern.ch/twiki/bin/viewauth/CMS/PdmVAnalysisSummaryTable\n",
    "# Lum2017 = 41530.\n",
    "# Lum2018 = 59740.\n",
    "# Lum     = 137190.\n",
    "\n",
    "t_BR = 0.6741\n",
    "ttbar_BR = 0.4544 #PDG 2019\n",
    "ttbar_xs = 831.76  #pb  Monte Carlo already includes xs in event weight (if not dividing by sumw2)!!\n",
    "toptag_kf = 0.49\n",
    "\n",
    "qcd_xs = 1370000000.0 #pb From https://cms-gen-dev.cern.ch/xsdb\n",
    "\n",
    "# =========== SF =========== #\n",
    "alltt_unwgt_evts = 0\n",
    "allqcd_unwgt_evts = 0\n",
    "\n",
    "for vfp in ['preVFP', 'postVFP']:\n",
    "    alltt_unwgt_evts += TTbar_unweighted[vfp]['cutflow']['all events']\n",
    "    allqcd_unwgt_evts += QCD_unweighted[vfp]['cutflow']['sumw']\n",
    "    \n",
    "ttbar2016_sf = Lum2016*ttbar_BR*toptag_kf/alltt_unwgt_evts \n",
    "qcd2016_sf = Lum2016*qcd_xs/allqcd_unwgt_evts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio Plot Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotratio(numerator, denominator, ax=None, histtype='errorbar', marker='.', markersize=5., color='k', alpha=0.1):\n",
    "    NumeratorAxes = numerator.axes\n",
    "    DenominatorAxes = denominator.axes\n",
    "    \n",
    "    # integer number of bins in this axis #\n",
    "    NumeratorAxis1_BinNumber = NumeratorAxes[0].size - 3 # Subtract 3 to remove overflow\n",
    "    \n",
    "    DenominatorAxis1_BinNumber = DenominatorAxes[0].size - 3 \n",
    "    \n",
    "    if(NumeratorAxis1_BinNumber != DenominatorAxis1_BinNumber):\n",
    "        raise Exception('Numerator and Denominator axes are different sizes; Cannot perform division.')\n",
    "    # else:\n",
    "    #     Numerator = numerator.to_hist()\n",
    "    #     Denominator = denominator.to_hist()\n",
    "        \n",
    "    ratio = numerator / denominator.values()\n",
    "    \n",
    "    if histtype == 'errorbar':\n",
    "        return hep.histplot(ratio, ax=ax, histtype=histtype, marker=marker, markersize=markersize, color=color)\n",
    "    elif histtype == 'fill':\n",
    "        return hep.histplot(ratio, ax=ax, histtype=histtype, color=color, alpha=alpha, lw=5.)\n",
    "    else:\n",
    "        return hep.histplot(ratio, ax=ax, histtype=histtype, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Unweighted MC Plots\n",
    "### NOTE that SDmass used axes called jetmass, so code will get confused unless exception is made for SDmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "PlotType = 'log'\n",
    "\n",
    "# ---- List the Histograms Here ---- #\n",
    "# list_of_hists_4vector = ['ttbarmass', 'jetpt', 'jeteta', 'jetphi', 'jety', 'jetdy', 'jetmass', 'SDmass', 'tau32']\n",
    "list_of_hists_4vector = ['ttbarmass']\n",
    "\n",
    "for ihist in list_of_hists_4vector:\n",
    "    # -- split histograms into subdirectories -- #\n",
    "    SaveDirectory = f'{maindirectory}/UnweightedAnalysisPlots/{yeardir}{btagdir}{oddir}{ihist}/{PlotType}/'\n",
    "    DoesDirectoryExist(SaveDirectory) # no need to create the directory several times if it exists already\n",
    "    for icat, ilabel in label_dict.items(): \n",
    "        plt.rcParams.update({\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 18,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12\n",
    "        })\n",
    "        fig, (ax, rax) = plt.subplots(\n",
    "            nrows=2,\n",
    "            ncols=1,\n",
    "            figsize=(10,10),\n",
    "            gridspec_kw={\"height_ratios\": (3, 1)},\n",
    "            sharex=True\n",
    "        )\n",
    "        fig.subplots_adjust(hspace=.07)\n",
    "        title = ihist + '  ' + ilabel\n",
    "        #filename = ihist + '_' + ilabel + '_LinearScale.' + 'png'\n",
    "        filename = ihist + '_' + ilabel + '.' + 'png'\n",
    "\n",
    "        \n",
    "#    ===================================================================================================================\n",
    "#    DDDD       A    TTTTTTT    A        H     H IIIIIII   SSSSS TTTTTTT   OOO   GGGGGGG RRRRRR     A    M     M   SSSSS     \n",
    "#    D   D     A A      T      A A       H     H    I     S         T     O   O  G       R     R   A A   MM   MM  S          \n",
    "#    D    D   A   A     T     A   A      H     H    I    S          T    O     O G       R     R  A   A  M M M M S           \n",
    "#    D     D  AAAAA     T     AAAAA      HHHHHHH    I     SSSSS     T    O     O G  GGGG RRRRRR   AAAAA  M  M  M  SSSSS      \n",
    "#    D    D  A     A    T    A     A     H     H    I          S    T    O     O G     G R   R   A     A M     M       S     \n",
    "#    D   D   A     A    T    A     A     H     H    I         S     T     O   O  G     G R    R  A     A M     M      S      \n",
    "#    DDDD    A     A    T    A     A     H     H IIIIIII SSSSS      T      OOO    GGGGG  R     R A     A M     M SSSSS\n",
    "#    ===================================================================================================================\n",
    "        # ---- initialize data histograms with first era ---- #\n",
    "        JetHT2016_unwgt_str = 'UL16preVFP_JetHTB_Data'\n",
    "        Data_hist = JetHT2016_unweighted['B_preVFP'][ihist][JetHT2016_unwgt_str, icat, :]\n",
    "        \n",
    "        # ---- Add all data together ---- #\n",
    "        for vfp in ['preVFP', 'postVFP']:\n",
    "            #---- Define Histograms from Coffea Outputs ----# \n",
    "            if vfp == 'preVFP':\n",
    "                for Era in ['C', 'D', 'E', 'F']: #exclude B because histogram is initialized with B era\n",
    "                    JetHT2016_unwgt_str = f'UL16{vfp}_JetHT{Era}_Data'\n",
    "                    Data_hist += JetHT2016_unweighted[Era+'_'+vfp][ihist][JetHT2016_unwgt_str, icat, :]\n",
    "            else:\n",
    "                for Era in ['F', 'G', 'H']: #exclude B because histogram is initialized with B era\n",
    "                    JetHT2016_unwgt_str = f'UL16{vfp}_JetHT{Era}_Data'\n",
    "                    # -- For Observed Signal -- #\n",
    "                    Data_hist += JetHT2016_unweighted[Era+'_'+vfp][ihist][JetHT2016_unwgt_str, icat, :]\n",
    "                    \n",
    "        Data_hist *= Nevts2016_sf\n",
    "#    ===================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE       QQQ     CCCC  DDDD        \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E            Q   Q   C      D   D       \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           Q     Q C       D    D      \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     Q     Q C       D     D     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           Q   Q Q C       D    D      \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E            Q   Q   C      D   D       \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE       QQQ Q   CCCC  DDDD\n",
    "#    ===================================================================================================\n",
    "        \n",
    "        QCD_hist = QCD_unweighted['preVFP'][ihist]['UL16preVFP_QCD', icat, :]\\\n",
    "                 + QCD_unweighted['postVFP'][ihist]['UL16postVFP_QCD', icat, :]\n",
    "        \n",
    "        QCD_hist *= qcd2016_sf #scaled according to luminosity\n",
    "\n",
    "#    ===================================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     TTTTTTT TTTTTTT BBBBBB     A    RRRRRR      \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E              T       T    B     B   A A   R     R     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E              T       T    B     B  A   A  R     R     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE        T       T    BBBBBB   AAAAA  RRRRRR      \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E              T       T    B     B A     A R   R       \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E              T       T    B     B A     A R    R      \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE        T       T    BBBBBB  A     A R     R \n",
    "#    ===================================================================================================================\n",
    "        \n",
    "        TTbar_hist = TTbar_unweighted['preVFP'][ihist]['UL16preVFP_TTbar', icat, :]\\\n",
    "                   + TTbar_unweighted['postVFP'][ihist]['UL16postVFP_TTbar', icat, :]\n",
    "        \n",
    "        TTbar_hist *= ttbar2016_sf #scaled according to luminosity\n",
    "\n",
    "#    ===================================================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     RRRRRR    SSSSS GGGGGGG L       U     U   OOO   N     N     \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           R     R  S      G       L       U     U  O   O  NN    N     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           R     R S       G       L       U     U O     O N N   N     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     RRRRRR   SSSSS  G  GGGG L       U     U O     O N  N  N     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           R   R         S G     G L       U     U O     O N   N N     \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E           R    R       S  G     G L        U   U   O   O  N    NN     \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     R     R SSSSS    GGGGG  LLLLLLL   UUU     OOO   N     N \n",
    "#    ===================================================================================================================================\n",
    "\n",
    "        # RSG1000_hist = RSGluon1000_unweighted[ihist]['UL16postVFP_RSGluon1000', icat, :]\n",
    "        # RSG1000_hist *= RSGluon1000_sf2016 #scaled according to luminosity  \n",
    "        \n",
    "#    ===========================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M     \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           D   D   MM   MM     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           D    D  M M M M     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     D     D M  M  M     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           D    D  M     M     \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E           D   D   M     M     \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M\n",
    "#    ===========================================================================================\n",
    "        \n",
    "        # DM1000_hist = DM1000_unweighted[ihist]['UL16postVFP_DM1000', icat, :]\n",
    "        # DM1000_hist *= DM1000_sf2016 #scaled according to luminosity\n",
    "            \n",
    "#    ===========================================================================\n",
    "#    M     M    A    K     K EEEEEEE     PPPPPP  L         OOO   TTTTTTT   SSSSS     \n",
    "#    MM   MM   A A   K   K   E           P     P L        O   O     T     S          \n",
    "#    M M M M  A   A  K K     E           P     P L       O     O    T    S           \n",
    "#    M  M  M  AAAAA  KKk     EEEEEEE     PPPPPP  L       O     O    T     SSSSS      \n",
    "#    M     M A     A K  K    E           P       L       O     O    T          S     \n",
    "#    M     M A     A K   K   E           P       L        O   O     T         S      \n",
    "#    M     M A     A K   K   EEEEEEE     P       LLLLLLL   OOO      T    SSSSS \n",
    "#    ===========================================================================\n",
    "\n",
    "        MC_hist = TTbar_hist.copy()\n",
    "        MC_hist += QCD_hist\n",
    "        \n",
    "        # ---- Extract both the data and MC events and from histograms ---- #\n",
    "        NtotalMC = np.sum(MC_hist.view().value)\n",
    "        NtotalData = np.sum(Data_hist.view().value)\n",
    "        \n",
    "        # ---- Normalize the total MC histogram directly to the data (for aesthetic purposes only!) ---- #\n",
    "        # -------- Unweighted simulation of the background alone greatly overestimates ------- #\n",
    "        if NtotalMC > 0.:\n",
    "            MC_hist *= (NtotalData/NtotalMC)\n",
    "            TTbar_hist *= (NtotalData/NtotalMC)\n",
    "        else:\n",
    "            MC_hist *= 0.\n",
    "            TTbar_hist *= 0.\n",
    "\n",
    "        #---- Plot Data ----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        Data_hist.plot1d(ax=ax, histtype='errorbar', marker='.', markersize=5., color='k')\n",
    "        \n",
    "        #---- Plot Total MC (simulated QCD + SM ttbar background)----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        MC_hist.plot1d(ax=ax, histtype='fill', color='yellow')\n",
    "        \n",
    "        #---- Plot TTbar MC for comparison ---- #\n",
    "        #-----------------------------------------------------------------#    \n",
    "        TTbar_hist.plot1d(ax=ax, histtype='fill', color='red')\n",
    "        \n",
    "        #---- Plot RSG MC for comparison ---- #\n",
    "        #-----------------------------------------------------------------#   \n",
    "        # RSG1000_hist.plot1d(ax=ax, histtype='step', color='purple')\n",
    "        \n",
    "        \n",
    "        #---- Plot DMM MC for comparison ----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        # DM1000_hist.plot1d(ax=ax, histtype='step', color='black')\n",
    "        \n",
    "        if count < 6 and icat in range(36,42): # Print number of events for each category once\n",
    "            NtotalTT = np.sum(TTbar_hist.view().value)\n",
    "            print(f'\\t\\t{ilabel}\\n===================================================')\n",
    "            print('Observed Data Events   = ', '%10i'% NtotalData)\n",
    "            print('Simulated TTbar Events = ', '%10i'% NtotalTT  )\n",
    "            print()\n",
    "            count += 1\n",
    "            \n",
    "        if icat in range(18,30) or icat in range(36,42):\n",
    "            filename = 'AnalysisCategories/' + ihist + '_' + ilabel + '.' + 'png'\n",
    "            DoesDirectoryExist(SaveDirectory+'AnalysisCategories/') # no need to create the directory several times if it exists already\n",
    "        \n",
    "        plt.autoscale(enable=True, axis='y')\n",
    "        ax.set_ylim(bottom=1.)\n",
    "        ax.set_yscale(PlotType)\n",
    "        ax.set_ylabel('Events')\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_title(title)\n",
    "        # leg = ax.legend(labels=[r'Sim. Bkg', r'$t\\bar{t}$ Sim.', r'RSKK Gluon $1TeV$ Sim.', r'DM Med. $1TeV$ Sim.', r'Data'], fontsize='xx-small')\n",
    "        leg = ax.legend(labels=[r'Sim. Bkg', r'$t\\bar{t}$ Sim.', r'Data'], fontsize='small')\n",
    "        \n",
    "        \n",
    "        #---- Plot Ratio ----#\n",
    "        plotratio(Data_hist, MC_hist, ax = rax, histtype = 'errorbar')\n",
    "        rax.set_ylabel('Data/MC')\n",
    "        rax.axhline(y=1, color='k', linestyle=':')\n",
    "        rax.set_ylim(0,2)\n",
    "        \n",
    "        if ihist == 'ttbarmass':\n",
    "            rax.set_xlim(1000,5000)\n",
    "        if ihist == 'jetpt':\n",
    "            rax.set_xlim(400,2000)\n",
    "        if ihist == 'jeteta':\n",
    "            rax.set_xlim(-3,3)\n",
    "        if ihist == 'tau32':\n",
    "            rax.set_xlim(0,1.2)\n",
    "        \n",
    "        #---- Labeling ----#\n",
    "        Lint = str(Lum2016*.001) # Integrated Luminosity\n",
    "        lumi = plt.text(1.0, 1.06, \"L = \" + Lint[:6] + \" fb$^{-1}$\",\n",
    "                fontsize='x-large',\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes\n",
    "               )\n",
    "        CMS = plt.text(-0.05, 1.06, 'CMS Preliminary',\n",
    "                fontsize='x-large',\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes\n",
    "               )\n",
    "        coffee = plt.text(1.0, 0.87, u\"â˜•\",\n",
    "                      fontsize=50,\n",
    "                      horizontalalignment='left',\n",
    "                      verticalalignment='bottom',\n",
    "                      transform=ax.transAxes\n",
    "                     )\n",
    "\n",
    "#         plt.savefig(SaveDirectory+filename, bbox_inches=\"tight\")\n",
    "#         print(SaveDirectory+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

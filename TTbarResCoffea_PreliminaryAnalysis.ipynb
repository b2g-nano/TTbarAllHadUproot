{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays unweighted plots from the corresponding Coffea outputs.  The plots are categorized according to the histogram name (dependant variable) and the tag category defined in the `TTbarResProcessor`.  \n",
    "# NOTE: #\n",
    "All QCD MC histograms are normalized directly to the data, as no corrections are applied via mistag analysis or modmass procedures anyways.  For a more realistic analysis, refer to `TTbarResCoffea_BkgEstAnalysis` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from coffea import hist\n",
    "from coffea import util\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = 'CoffeaOutputs/UnweightedOutputs/'\n",
    "dir2 = 'CoffeaOutputsForCombine/Coffea_FirstRun/QCD/2016/noAPV/TTbarRes_0l_UL16postVFP_QCD.coffea'\n",
    "\n",
    "QCD_unweighted = util.load('CoffeaOutputsForCombine/Coffea_FirstRun/QCD/2016/noAPV/TTbarRes_0l_UL16postVFP_QCD.coffea')\n",
    "TTbar_unweighted = util.load('CoffeaOutputsForCombine/Coffea_FirstRun/TT/2016/noAPV/TTbarRes_0l_UL16postVFP_TTbar.coffea')\n",
    "JetHT2016_unweighted = util.load('CoffeaOutputsForCombine/Coffea_FirstRun/JetHT/2016/TTbarRes_0l_JetHT2016_Data.coffea')\n",
    "RSGluon1000_unweighted = util.load('CoffeaOutputsForCombine/Coffea_FirstRun/RSGluonToTT/2016/noAPV/TTbarRes_0l_UL16postVFP_RSGluon1000.coffea')\n",
    "DM1000_unweighted = util.load('CoffeaOutputsForCombine/Coffea_FirstRun/ZprimeDMToTTbar/2016/noAPV/TTbarRes_0l_UL16postVFP_DM1000.coffea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cutflow can be checked if desired "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = {\n",
    "    'QCD': QCD_unweighted,\n",
    "    'TTbar': TTbar_unweighted,\n",
    "    'JetHT2016': JetHT2016_unweighted,\n",
    "    'RSGluon1000': RSGluon1000_unweighted,\n",
    "    'DM1000': DM1000_unweighted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset,output in Datasets.items():\n",
    "    print(\"-------\" + dataset + \" Cutflow--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %20s' % (i,j) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoesDirectoryExist(mypath): #extra precaution (Probably overkill...)\n",
    "    '''Checks to see if Directory exists before running mkdir_p'''\n",
    "    import os.path\n",
    "    from os import path\n",
    "    \n",
    "    if path.exists(mypath):\n",
    "        pass\n",
    "    else:\n",
    "        mkdir_p(mypath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare to Loop through Analysis Categories and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re # regular expressions\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- Reiterate categories ---- #\n",
    "# ttagcats = [\"AT&Pt\", \"at\", \"pret\", \"0t\", \"1t\", \">=1t\", \"2t\", \">=0t\"] # 'AT&Pt' = anti-tagged j0 with t-tagged probe jet j1; 'pret' = t-tagged j0\n",
    "ttagcats = [\"AT&Pt\", \"at\", \"pret\", \">=0t\", \"0t\", \">=1t\", \"1t\", \"2t\"]\n",
    "btagcats = [\"0b\", \"1b\", \"2b\"]\n",
    "ycats = ['cen', 'fwd']\n",
    "\n",
    "list_of_cats = [ t+b+y for t,b,y in itertools.product( ttagcats, btagcats, ycats) ]\n",
    "\n",
    "# ---- List the Histograms Here ---- #\n",
    "list_of_hists_4vector = ('SDmass', 'tau32', 'jetmass', 'ttbarmass', 'jetpt', 'jeteta', 'jetphi', 'jety', 'jetdy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindirectory = os.getcwd() # prepare to locally save images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminosity, Cross Sections and Scale Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nevts2016 = 583876623 #625516390. # from dasgoclient \n",
    "# Nevts2017 = 410461585.\n",
    "# Nevts2018 = 676328827.\n",
    "# Nevts = Nevts2016 + Nevts2017 + Nevts2018\n",
    "Nevts_sf2016 = Nevts2016/JetHT2016_unweighted['cutflow']['all events']\n",
    "print(Nevts_sf2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- Luminosity and Cross Sections ---------------- \"\"\"\n",
    "Lum     = 137190. # pb^-1 from https://twiki.cern.ch/twiki/bin/viewauth/CMS/PdmVAnalysisSummaryTable\n",
    "Lum2016 = 35920. / Nevts_sf2016\n",
    "\n",
    "ttbar_BR = 0.45 #Calculated using PDG 2019\n",
    "ttbar_xs = 831.76  #pb Monte Carlo already includes xs in event weight!!\n",
    "# ttbar_sf2016 = ttbar_xs*Lum2016*ttbar_BR/TTbar_unweighted['cutflow']['sumw2'] \n",
    "ttbar_sf2016 = ttbar_xs*Lum2016/TTbar_unweighted['cutflow']['sumw'] \n",
    "print(ttbar_sf2016)\n",
    "\n",
    "qcd_xs = 1370000000.0 #pb From https://cms-gen-dev.cern.ch/xsdb Set to one as a guess that these MC recieved the same treatment as ttbar\n",
    "qcd_sf2016 = qcd_xs*Lum2016/QCD_unweighted['cutflow']['sumw']\n",
    "\n",
    "# ---- https://cms-gen-dev.cern.ch/xsdb/?columns=67108863&currentPage=0&pageSize=0&searchQuery=process_name%3DRSGluon ---- #\n",
    "# ---- May need to be double checked ---- #\n",
    "RSGluon1000_xs = 20.95 # Ignore as a guess and simply divide by the total number of generated events\n",
    "RSGluon1500_xs = 3.679\n",
    "RSGluon2000_xs = 0.9429\n",
    "RSGluon2500_xs = 0.3039\n",
    "RSGluon3000_xs = 0.1163\n",
    "RSGluon3500_xs = 0.05132\n",
    "RSGluon4000_xs = 0.02545\n",
    "RSGluon4500_xs = 0.01422\n",
    "RSGluon5000_xs = 0.008634\n",
    "\n",
    "DM1000_xs = 2.222\n",
    "\n",
    "RSGluon1000_sf2016 = Lum2016/RSGluon1000_unweighted['cutflow']['all events'] # weights are 1 (maybe?)\n",
    "\n",
    "DM1000_sf2016 = Lum2016/DM1000_unweighted['cutflow']['all events']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_ttbar_opts = {'alpha': 0.8, 'edgecolor':(0,0,0,0.3), 'color': 'red'}\n",
    "line_rsg1000_opts = {'color': 'purple'}\n",
    "line_dm1000_opts = {'color': 'black'}\n",
    "stack_background_opts = {'alpha': 0.8, 'edgecolor':(0,0,0,0.3), 'color': 'yellow'}\n",
    "stack_error_opts = {'label':'Stat. Unc.', 'hatch':'///', 'facecolor':'None', 'edgecolor':(0,0,0,.5), 'linewidth': 0, 'label':'_nolegend_'}\n",
    "data_err_opts = {'linestyle': 'none', 'marker': '.', 'markersize': 10., 'color': 'k', 'elinewidth': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Unweighted MC Plots\n",
    "### NOTE that SDmass used axes called jetmass, so code will get confused unless exception is made for SDmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dataset,output in Datasets.items():\n",
    "for ihist in list_of_hists_4vector:\n",
    "    SaveDirectory = maindirectory + '/PreliminaryAnalysisPlots/' + ihist + '/NormalizedToLuminosity/' # split histograms into subdirectories\n",
    "    DoesDirectoryExist(SaveDirectory) # no need to create the directory several times if it exists already\n",
    "    for icat in list_of_cats: \n",
    "        plt.rcParams.update({\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 18,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12\n",
    "        })\n",
    "        fig, (ax, rax) = plt.subplots(\n",
    "            nrows=2,\n",
    "            ncols=1,\n",
    "            figsize=(7,7),\n",
    "            gridspec_kw={\"height_ratios\": (3, 1)},\n",
    "            sharex=True\n",
    "        )\n",
    "        fig.subplots_adjust(hspace=.07)\n",
    "        title = ihist + '  ' + icat\n",
    "        #filename = ihist + '_' + icat + '_LinearScale.' + 'png'\n",
    "        filename = ihist + '_' + icat + '.' + 'png'\n",
    "        legend_labels = {'labels':['QCD Bkg (Sim.)', r'$t\\bar{t}$ Sim.', r'RSKK Gluon $1TeV$ Sim.', r'DM Med. $1TeV$ Sim.', 'Data', '_nolegend_', '_nolegend_', '_nolegend_'],\n",
    "                         'loc': 'upper right',\n",
    "                         'fontsize': 'xx-small'}\n",
    "        \n",
    "#         ttbar_sf2016 = ttbar_xs*Lum2016*ttbar_BR/TTbar_unweighted['cutflow'][icat]\n",
    "#         qcd_sf2016 = qcd_xs*Lum2016/QCD_unweighted['cutflow'][icat]\n",
    "#         RSGluon1000_sf2016 = RSGluon1000_xs*Lum2016/RSGluon1000_unweighted['cutflow'][icat]\n",
    "\n",
    "        \n",
    "#    ===================================================================================================================\n",
    "#    DDDD       A    TTTTTTT    A        H     H IIIIIII   SSSSS TTTTTTT   OOO   GGGGGGG RRRRRR     A    M     M   SSSSS     \n",
    "#    D   D     A A      T      A A       H     H    I     S         T     O   O  G       R     R   A A   MM   MM  S          \n",
    "#    D    D   A   A     T     A   A      H     H    I    S          T    O     O G       R     R  A   A  M M M M S           \n",
    "#    D     D  AAAAA     T     AAAAA      HHHHHHH    I     SSSSS     T    O     O G  GGGG RRRRRR   AAAAA  M  M  M  SSSSS      \n",
    "#    D    D  A     A    T    A     A     H     H    I          S    T    O     O G     G R   R   A     A M     M       S     \n",
    "#    D   D   A     A    T    A     A     H     H    I         S     T     O   O  G     G R    R  A     A M     M      S      \n",
    "#    DDDD    A     A    T    A     A     H     H IIIIIII SSSSS      T      OOO    GGGGG  R     R A     A M     M SSSSS\n",
    "#    ===================================================================================================================\n",
    "        \n",
    "        Data_hist = JetHT2016_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'JetHT2016_Data')\n",
    "        Data_hist.scale(Nevts_sf2016) #scale according to number of events in dataset\n",
    "        \n",
    "#    ===================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE       QQQ     CCCC  DDDD        \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E            Q   Q   C      D   D       \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           Q     Q C       D    D      \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     Q     Q C       D     D     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           Q   Q Q C       D    D      \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E            Q   Q   C      D   D       \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE       QQQ Q   CCCC  DDDD\n",
    "#    ===================================================================================================\n",
    "        \n",
    "        QCD_hist = QCD_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_QCD')\n",
    "        QCD_hist.scale(qcd_sf2016) #scaled according to luminosity\n",
    "\n",
    "#    ===================================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     TTTTTTT TTTTTTT BBBBBB     A    RRRRRR      \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E              T       T    B     B   A A   R     R     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E              T       T    B     B  A   A  R     R     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE        T       T    BBBBBB   AAAAA  RRRRRR      \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E              T       T    B     B A     A R   R       \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E              T       T    B     B A     A R    R      \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE        T       T    BBBBBB  A     A R     R \n",
    "#    ===================================================================================================================\n",
    "        \n",
    "        TTbar_hist = TTbar_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_TTbar')\n",
    "        TTbar_hist.scale(ttbar_sf2016) #scaled according to luminosity\n",
    "\n",
    "#    ===================================================================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     RRRRRR    SSSSS GGGGGGG L       U     U   OOO   N     N     \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           R     R  S      G       L       U     U  O   O  NN    N     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           R     R S       G       L       U     U O     O N N   N     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     RRRRRR   SSSSS  G  GGGG L       U     U O     O N  N  N     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           R   R         S G     G L       U     U O     O N   N N     \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E           R    R       S  G     G L        U   U   O   O  N    NN     \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     R     R SSSSS    GGGGG  LLLLLLL   UUU     OOO   N     N \n",
    "#    ===================================================================================================================================\n",
    "\n",
    "        RSG1000_hist = RSGluon1000_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_RSGluon1000')\n",
    "        RSG1000_hist.scale(RSGluon1000_sf2016) #scaled according to luminosity  \n",
    "        \n",
    "#    ===========================================================================================\n",
    "#    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M     \n",
    "#    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           D   D   MM   MM     \n",
    "#    N N   N O     O R     R M M M M  A   A  L          I        Z   E           D    D  M M M M     \n",
    "#    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     D     D M  M  M     \n",
    "#    N   N N O     O R   R   M     M A     A L          I      Z     E           D    D  M     M     \n",
    "#    N    NN  O   O  R    R  M     M A     A L          I     Z      E           D   D   M     M     \n",
    "#    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M\n",
    "#    ===========================================================================================\n",
    "        \n",
    "        DM1000_hist = DM1000_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_DM1000')\n",
    "        DM1000_hist.scale(DM1000_sf2016) #scaled according to luminosity\n",
    "            \n",
    "#    ===========================================================================\n",
    "#    M     M    A    K     K EEEEEEE     PPPPPP  L         OOO   TTTTTTT   SSSSS     \n",
    "#    MM   MM   A A   K   K   E           P     P L        O   O     T     S          \n",
    "#    M M M M  A   A  K K     E           P     P L       O     O    T    S           \n",
    "#    M  M  M  AAAAA  KKk     EEEEEEE     PPPPPP  L       O     O    T     SSSSS      \n",
    "#    M     M A     A K  K    E           P       L       O     O    T          S     \n",
    "#    M     M A     A K   K   E           P       L        O   O     T         S      \n",
    "#    M     M A     A K   K   EEEEEEE     P       LLLLLLL   OOO      T    SSSSS \n",
    "#    ===========================================================================\n",
    "\n",
    "        MC_hist = TTbar_hist.copy()\n",
    "        MC_hist.add(QCD_hist)\n",
    "        \n",
    "        # ---- Extract both the data and MC events and from histograms ---- #\n",
    "        if ihist == 'SDmass':\n",
    "            NtotalMC = np.sum(MC_hist.integrate('jetmass').values())\n",
    "            NtotalData = np.sum(Data_hist.integrate('jetmass').values())\n",
    "        else:\n",
    "            NtotalMC = np.sum(MC_hist.integrate(ihist).values())\n",
    "            NtotalData = np.sum(Data_hist.integrate(ihist).values())\n",
    "        NtotalMC = [k for k in NtotalMC.values()]\n",
    "        NtotalData = [l for l in NtotalData.values()]\n",
    "        \n",
    "        # ---- Normalize the total MC histogram directly to the data (for aesthetic purposes only!) ---- #\n",
    "        # -------- Unweighted simulation of the background alone greatly overestimates ------- #\n",
    "        if NtotalMC[0] > 0.:\n",
    "            MC_hist.scale(NtotalData[0]/NtotalMC[0])\n",
    "            # TTbar_hist.scale(NtotalData[0]/NtotalMC[0])\n",
    "        else:\n",
    "            MC_hist.scale(0.)\n",
    "            # TTbar_hist.scale(0.)\n",
    "\n",
    "        #---- Plot Data ----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        hist.plot1d(Data_hist, ax=ax, clear=False, \n",
    "                    error_opts=data_err_opts)\n",
    "        \n",
    "        #---- Plot Total MC (simulated QCD + SM ttbar background)----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        hist.plot1d(MC_hist, ax=ax, clear=False,\n",
    "                    fill_opts=stack_background_opts, error_opts=stack_error_opts)\n",
    "        \n",
    "        #---- Plot TTbar MC for comparison ---- #\n",
    "        #-----------------------------------------------------------------#    \n",
    "        hist.plot1d(TTbar_hist, ax=ax, clear=False,\n",
    "                    fill_opts=stack_ttbar_opts, error_opts=stack_error_opts)\n",
    "        \n",
    "        #---- Plot RSG MC for comparison ---- #\n",
    "        #-----------------------------------------------------------------#   \n",
    "        hist.plot1d(RSG1000_hist, ax=ax, clear=False,\n",
    "                    line_opts=line_rsg1000_opts, error_opts=stack_error_opts, legend_opts=legend_labels)\n",
    "        \n",
    "        \n",
    "        #---- Plot DMM MC for comparison ----#\n",
    "        #-----------------------------------------------------------------#\n",
    "        hist.plot1d(DM1000_hist, ax=ax, clear=False,\n",
    "                    line_opts=line_dm1000_opts, error_opts=stack_error_opts, legend_opts=legend_labels)\n",
    "        \n",
    "        ax.set_ylim(bottom=0.1)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel('Events')\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_title(title)\n",
    "        leg = ax.legend(labels=[r'QCD Sim. Bkg', r'$t\\bar{t}$ Sim.', r'RSKK Gluon $1TeV$ Sim.', r'DM Med. $1TeV$ Sim.', r'Data'])\n",
    "        \n",
    "        \n",
    "        #---- Plot Ratio ----#\n",
    "        hist.plotratio(num = Data_hist, denom = MC_hist, ax = rax,\n",
    "                       error_opts={'marker': '.', 'markersize': 10., 'color': 'k', 'elinewidth': 1},\n",
    "                       unc = 'num')\n",
    "        rax.set_ylabel('Data/MC')\n",
    "        rax.axhline(y=1, color='k', linestyle=':')\n",
    "        rax.set_ylim(0,2)\n",
    "        \n",
    "        if ihist == 'ttbarmass':\n",
    "            rax.set_xlim(700,5000)\n",
    "        if ihist == 'jetpt':\n",
    "            rax.set_xlim(400,3000)\n",
    "        if ihist == 'jeteta':\n",
    "            rax.set_xlim(-3,3)\n",
    "        if ihist == 'tau32':\n",
    "            rax.set_xlim(0,1.2)\n",
    "\n",
    "        #---- Labeling ----#\n",
    "        Lint = str(Lum2016*.001) # Integrated Luminosity\n",
    "        lumi = plt.text(1.15, 1.07, Lint[:6] + \" fb$^{-1}$\",\n",
    "                fontsize=16,\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='top',\n",
    "                transform=ax.transAxes\n",
    "               )\n",
    "#         plt.savefig(SaveDirectory+filename, bbox_inches=\"tight\")\n",
    "        # print(SaveDirectory+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for dataset,output in Datasets.items():\n",
    "# # SaveDirectory = maindirectory + '/PreliminaryAnalysisPlots/' + ihist + '/NormalizedToLuminosity/' # split histograms into subdirectories\n",
    "# # DoesDirectoryExist(SaveDirectory) # no need to create the directory several times if it exists already\n",
    "\n",
    "# ihist = 'ttbarmass'\n",
    "# for icat in list_of_cats: \n",
    "#     plt.rcParams.update({\n",
    "#     'font.size': 14,\n",
    "#     'axes.titlesize': 18,\n",
    "#     'axes.labelsize': 18,\n",
    "#     'xtick.labelsize': 12,\n",
    "#     'ytick.labelsize': 12\n",
    "#     })\n",
    "#     fig, (ax, rax) = plt.subplots(\n",
    "#         nrows=2,\n",
    "#         ncols=1,\n",
    "#         figsize=(7,7),\n",
    "#         gridspec_kw={\"height_ratios\": (3, 1)},\n",
    "#         sharex=True\n",
    "#     )\n",
    "#     fig.subplots_adjust(hspace=.07)\n",
    "#     title = ihist + '  ' + icat\n",
    "#     #filename = ihist + '_' + icat + '_LinearScale.' + 'png'\n",
    "#     filename = ihist + '_' + icat + '.' + 'png'\n",
    "#     legend_labels = {'labels':['QCD Bkg (Sim.)', r'$t\\bar{t}$ Sim.', r'RSKK Gluon $1TeV$ Sim.', r'DM Med. $1TeV$ Sim.', 'Data', '_nolegend_', '_nolegend_', '_nolegend_'],\n",
    "#                      'loc': 'upper right',\n",
    "#                      'fontsize': 'xx-small'}\n",
    "\n",
    "# #         ttbar_sf2016 = ttbar_xs*Lum2016*ttbar_BR/TTbar_unweighted['cutflow'][icat]\n",
    "# #         qcd_sf2016 = qcd_xs*Lum2016/QCD_unweighted['cutflow'][icat]\n",
    "# #         RSGluon1000_sf2016 = RSGluon1000_xs*Lum2016/RSGluon1000_unweighted['cutflow'][icat]\n",
    "\n",
    "\n",
    "# #    ===================================================================================================================\n",
    "# #    DDDD       A    TTTTTTT    A        H     H IIIIIII   SSSSS TTTTTTT   OOO   GGGGGGG RRRRRR     A    M     M   SSSSS     \n",
    "# #    D   D     A A      T      A A       H     H    I     S         T     O   O  G       R     R   A A   MM   MM  S          \n",
    "# #    D    D   A   A     T     A   A      H     H    I    S          T    O     O G       R     R  A   A  M M M M S           \n",
    "# #    D     D  AAAAA     T     AAAAA      HHHHHHH    I     SSSSS     T    O     O G  GGGG RRRRRR   AAAAA  M  M  M  SSSSS      \n",
    "# #    D    D  A     A    T    A     A     H     H    I          S    T    O     O G     G R   R   A     A M     M       S     \n",
    "# #    D   D   A     A    T    A     A     H     H    I         S     T     O   O  G     G R    R  A     A M     M      S      \n",
    "# #    DDDD    A     A    T    A     A     H     H IIIIIII SSSSS      T      OOO    GGGGG  R     R A     A M     M SSSSS\n",
    "# #    ===================================================================================================================\n",
    "\n",
    "#     Data_hist = JetHT2016_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'JetHT2016_Data')\n",
    "#     Data_hist.scale(Nevts_sf2016) #scale according to number of events in dataset\n",
    "\n",
    "# #    ===================================================================================================\n",
    "# #    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE       QQQ     CCCC  DDDD        \n",
    "# #    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E            Q   Q   C      D   D       \n",
    "# #    N N   N O     O R     R M M M M  A   A  L          I        Z   E           Q     Q C       D    D      \n",
    "# #    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     Q     Q C       D     D     \n",
    "# #    N   N N O     O R   R   M     M A     A L          I      Z     E           Q   Q Q C       D    D      \n",
    "# #    N    NN  O   O  R    R  M     M A     A L          I     Z      E            Q   Q   C      D   D       \n",
    "# #    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE       QQQ Q   CCCC  DDDD\n",
    "# #    ===================================================================================================\n",
    "\n",
    "#     QCD_hist = QCD_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_QCD')\n",
    "#     QCD_hist.scale(qcd_sf2016) #scaled according to luminosity\n",
    "\n",
    "# #    ===================================================================================================================\n",
    "# #    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     TTTTTTT TTTTTTT BBBBBB     A    RRRRRR      \n",
    "# #    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E              T       T    B     B   A A   R     R     \n",
    "# #    N N   N O     O R     R M M M M  A   A  L          I        Z   E              T       T    B     B  A   A  R     R     \n",
    "# #    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE        T       T    BBBBBB   AAAAA  RRRRRR      \n",
    "# #    N   N N O     O R   R   M     M A     A L          I      Z     E              T       T    B     B A     A R   R       \n",
    "# #    N    NN  O   O  R    R  M     M A     A L          I     Z      E              T       T    B     B A     A R    R      \n",
    "# #    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE        T       T    BBBBBB  A     A R     R \n",
    "# #    ===================================================================================================================\n",
    "\n",
    "#     TTbar_hist = TTbar_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_TTbar')\n",
    "#     TTbar_hist.scale(ttbar_sf2016) #scaled according to luminosity\n",
    "\n",
    "# #    ===================================================================================================================================\n",
    "# #    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     RRRRRR    SSSSS GGGGGGG L       U     U   OOO   N     N     \n",
    "# #    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           R     R  S      G       L       U     U  O   O  NN    N     \n",
    "# #    N N   N O     O R     R M M M M  A   A  L          I        Z   E           R     R S       G       L       U     U O     O N N   N     \n",
    "# #    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     RRRRRR   SSSSS  G  GGGG L       U     U O     O N  N  N     \n",
    "# #    N   N N O     O R   R   M     M A     A L          I      Z     E           R   R         S G     G L       U     U O     O N   N N     \n",
    "# #    N    NN  O   O  R    R  M     M A     A L          I     Z      E           R    R       S  G     G L        U   U   O   O  N    NN     \n",
    "# #    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     R     R SSSSS    GGGGG  LLLLLLL   UUU     OOO   N     N \n",
    "# #    ===================================================================================================================================\n",
    "\n",
    "#     RSG1000_hist = RSGluon1000_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_RSGluon1000')\n",
    "#     RSG1000_hist.scale(RSGluon1000_sf2016) #scaled according to luminosity  \n",
    "\n",
    "# #    ===========================================================================================\n",
    "# #    N     N   OOO   RRRRRR  M     M    A    L       IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M     \n",
    "# #    NN    N  O   O  R     R MM   MM   A A   L          I         Z  E           D   D   MM   MM     \n",
    "# #    N N   N O     O R     R M M M M  A   A  L          I        Z   E           D    D  M M M M     \n",
    "# #    N  N  N O     O RRRRRR  M  M  M  AAAAA  L          I       Z    EEEEEEE     D     D M  M  M     \n",
    "# #    N   N N O     O R   R   M     M A     A L          I      Z     E           D    D  M     M     \n",
    "# #    N    NN  O   O  R    R  M     M A     A L          I     Z      E           D   D   M     M     \n",
    "# #    N     N   OOO   R     R M     M A     A LLLLLLL IIIIIII ZZZZZZZ EEEEEEE     DDDD    M     M\n",
    "# #    ===========================================================================================\n",
    "\n",
    "#     DM1000_hist = DM1000_unweighted[ihist].integrate('anacat', icat).integrate('dataset', 'UL16postVFP_DM1000')\n",
    "#     DM1000_hist.scale(DM1000_sf2016) #scaled according to luminosity\n",
    "\n",
    "# #    ===========================================================================\n",
    "# #    M     M    A    K     K EEEEEEE     PPPPPP  L         OOO   TTTTTTT   SSSSS     \n",
    "# #    MM   MM   A A   K   K   E           P     P L        O   O     T     S          \n",
    "# #    M M M M  A   A  K K     E           P     P L       O     O    T    S           \n",
    "# #    M  M  M  AAAAA  KKk     EEEEEEE     PPPPPP  L       O     O    T     SSSSS      \n",
    "# #    M     M A     A K  K    E           P       L       O     O    T          S     \n",
    "# #    M     M A     A K   K   E           P       L        O   O     T         S      \n",
    "# #    M     M A     A K   K   EEEEEEE     P       LLLLLLL   OOO      T    SSSSS \n",
    "# #    ===========================================================================\n",
    "\n",
    "#     MC_hist = TTbar_hist.copy()\n",
    "#     MC_hist.add(QCD_hist)\n",
    "#     # ---- Extract both the data and MC events and from histograms ---- #\n",
    "#     if ihist == 'SDmass':\n",
    "#         NtotalMC = np.sum(MC_hist.integrate('jetmass').values())\n",
    "#         NtotalData = np.sum(Data_hist.integrate('jetmass').values())\n",
    "#     else:\n",
    "#         NtotalMC = np.sum(MC_hist.integrate(ihist).values())\n",
    "#         NtotalData = np.sum(Data_hist.integrate(ihist).values())\n",
    "#     NtotalMC = [k for k in NtotalMC.values()]\n",
    "#     NtotalData = [l for l in NtotalData.values()]\n",
    "\n",
    "#     # ---- Normalize the total MC histogram directly to the data (for aesthetic purposes only!) ---- #\n",
    "#     # -------- Unweighted simulation of the background alone greatly underestimates the data ------- #\n",
    "#     if NtotalMC[0] > 0.:\n",
    "#         MC_hist.scale(NtotalData[0]/NtotalMC[0])\n",
    "#     else:\n",
    "#         MC_hist.scale(0.)\n",
    "\n",
    "\n",
    "#     #---- Plot Data ----#\n",
    "#     #-----------------------------------------------------------------#\n",
    "#     hist.plot1d(Data_hist, ax=ax, clear=False, \n",
    "#                 error_opts=data_err_opts)\n",
    "\n",
    "#     #---- Plot Total MC (simulated QCD + SM ttbar background)----#\n",
    "#     #-----------------------------------------------------------------#\n",
    "#     hist.plot1d(MC_hist, ax=ax, clear=False,\n",
    "#                 fill_opts=stack_background_opts, error_opts=stack_error_opts)\n",
    "\n",
    "#     #---- Plot TTbar MC for comparison ---- #\n",
    "#     #-----------------------------------------------------------------#    \n",
    "#     hist.plot1d(TTbar_hist, ax=ax, clear=False,\n",
    "#                 fill_opts=stack_ttbar_opts, error_opts=stack_error_opts)\n",
    "\n",
    "#     #---- Plot RSG MC for comparison ---- #\n",
    "#     #-----------------------------------------------------------------#   \n",
    "#     hist.plot1d(RSG1000_hist, ax=ax, clear=False,\n",
    "#                 line_opts=line_rsg1000_opts, error_opts=stack_error_opts, legend_opts=legend_labels)\n",
    "\n",
    "\n",
    "#     #---- Plot DMM MC for comparison ----#\n",
    "#     #-----------------------------------------------------------------#\n",
    "#     hist.plot1d(DM1000_hist, ax=ax, clear=False,\n",
    "#                 line_opts=line_dm1000_opts, error_opts=stack_error_opts, legend_opts=legend_labels)\n",
    "\n",
    "#     ax.set_ylim(bottom=0.1)\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_ylabel('Events')\n",
    "#     ax.set_xlabel(None)\n",
    "#     ax.set_title(title)\n",
    "#     leg = ax.legend(labels=[r'QCD Sim. Bkg', r'$t\\bar{t}$ Sim.', r'RSKK Gluon $1TeV$ Sim.', r'DM Med. $1TeV$ Sim.', r'Data'])\n",
    "\n",
    "\n",
    "#     #---- Plot Ratio ----#\n",
    "#     hist.plotratio(num = Data_hist, denom = MC_hist, ax = rax,\n",
    "#                    error_opts={'marker': '.', 'markersize': 10., 'color': 'k', 'elinewidth': 1},\n",
    "#                    unc = 'num')\n",
    "#     rax.set_ylabel('Data/MC')\n",
    "#     rax.axhline(y=1, color='k', linestyle=':')\n",
    "#     rax.set_ylim(0,2)\n",
    "\n",
    "#     if ihist == 'ttbarmass':\n",
    "#         rax.set_xlim(700,5000)\n",
    "#     if ihist == 'jetpt':\n",
    "#         rax.set_xlim(400,3000)\n",
    "#     if ihist == 'jeteta':\n",
    "#         rax.set_xlim(-3,3)\n",
    "#     if ihist == 'tau32':\n",
    "#         rax.set_xlim(0,1.2)\n",
    "\n",
    "#     #---- Labeling ----#\n",
    "#     Lint = str(Lum2016*.001) # Integrated Luminosity\n",
    "#     lumi = plt.text(1.15, 1.07, Lint[:6] + \" fb$^{-1}$\",\n",
    "#             fontsize=16,\n",
    "#             horizontalalignment='right',\n",
    "#             verticalalignment='top',\n",
    "#             transform=ax.transAxes\n",
    "#            )\n",
    "# #         plt.savefig(SaveDirectory+filename, bbox_inches=\"tight\")\n",
    "# #         print(SaveDirectory+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

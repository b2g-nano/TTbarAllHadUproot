{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResProcessor` Notebook for an all hadronic $t\\bar{t}$ analysis: \n",
    "This notebook contains the processor necessary for analysis and is to be imported into the `TTbarResCoffeaOutputs` module.  To import it, one can ensure that this module can be ran here by executing the notebook.  If everything executes with no errors, one can create a .py file of this module by uncommenting and running the last cell in tis notebook.  That .py file is the module that is imported to create Coffea output files.\n",
    "\n",
    "   1. Make the mistag rate in the \"anti-tag\" selection region,\n",
    "   1. Later apply that mistag rate and the mod-mass procedure to the single-tag (pre-tag) selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag (pret) selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 950$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n",
    "# Quick Reference for Tag Region Definitions:\n",
    "- An antitag and t-tagged probe pair region; numerator value of mistag [region used for closure test] (Probet)\n",
    "- An antitag [and any probe pair] region; denominator value; [region used for mistag weights] (at)\n",
    "- t-tagged jet0 region [region used for data-driven background estimate] (pret)\n",
    "- No tops tagged (0t)\n",
    "- Exclusively one jet is top tagged (1t)\n",
    "- At least one jet is top tagged ['inclusive' tagger; >=1t] (1t+2t)\n",
    "- Both jets are top tagged (2t)\n",
    "- Either no tag or at least one tag ['all inclusive' tagger; >=0t] (0t+1t+2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy.stats as ss\n",
    "from coffea import hist, processor, nanoevents\n",
    "from coffea import util\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import awkward as ak\n",
    "#from coffea.nanoevents.methods import nanoaod\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents.methods import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ak.behavior.update(nanoaod.behavior)\n",
    "ak.behavior.update(candidate.behavior)\n",
    "ak.behavior.update(vector.behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`manual_bins` is set up to define the bin sizes the user wants for the mistag rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_bins = [400, 500, 600, 800, 1000, 1500, 2000, 3000, 7000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All histograms that one wishes to be included in the Coffea output files is to be defined and filled in this processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, prng=RandomState(1234567890), htCut=950., minMSD=105., maxMSD=210.,\n",
    "                 tau32Cut=0.65, ak8PtMin=400., bdisc=0.8484,\n",
    "                 writePredDist=True,isData=True,year=2019, UseLookUpTables=False, lu=None, \n",
    "                 ModMass=False, RandomDebugMode=False):\n",
    "        \n",
    "        self.prng = prng\n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        self.UseLookUpTables = UseLookUpTables\n",
    "        self.ModMass = ModMass\n",
    "        self.RandomDebugMode = RandomDebugMode\n",
    "        self.lu = lu # Look Up Tables\n",
    "        \n",
    "        self.ttagcats = [\"Probet\", \"at\", \"pret\", \"0t\", \"1t\", \"1t+2t\", \"2t\", \"0t+1t+2t\"] #anti-tag+probe, anti-tag, pre-tag, 0, 1, >=1, 2 ttags, any t-tag\n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        # Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "        self.anacats = [ t+b+y for t,b,y in itertools.product( self.ttagcats, self.btagcats, self.ycats) ]\n",
    "        #print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 5000)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "        jeteta_axis = hist.Bin(\"jeteta\", r\"Jet $\\eta$\", 50, -5, 5)\n",
    "        jetphi_axis = hist.Bin(\"jetphi\", r\"Jet $\\phi$\", 50, -np.pi, np.pi)\n",
    "        jety_axis = hist.Bin(\"jety\", r\"Jet $y$\", 50, -3, 3)\n",
    "        jetdy_axis = hist.Bin(\"jetdy\", r\"Jet $\\Delta y$\", 50, 0, 5)\n",
    "        manual_axis = hist.Bin(\"jetp\", r\"Jet Momentum [GeV]\", manual_bins)\n",
    "        tagger_axis = hist.Bin(\"tagger\", r\"deepTag\", 50, 0, 1)\n",
    "        tau32_axis = hist.Bin(\"tau32\", r\"$\\tau_3/\\tau_2$\", 50, 0, 2)\n",
    "        \n",
    "        subjetmass_axis = hist.Bin(\"subjetmass\", r\"SubJet $m$ [GeV]\", 50, 0, 500)\n",
    "        subjetpt_axis = hist.Bin(\"subjetpt\", r\"SubJet $p_{T}$ [GeV]\", 50, 0, 2000)\n",
    "        subjeteta_axis = hist.Bin(\"subjeteta\", r\"SubJet $\\eta$\", 50, -4, 4)\n",
    "        subjetphi_axis = hist.Bin(\"subjetphi\", r\"SubJet $\\phi$\", 50, -np.pi, np.pi)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            \n",
    "            'jetmass':         hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'SDmass':          hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'SDmass_precat':   hist.Hist(\"Counts\", dataset_axis, jetpt_axis, jetmass_axis),\n",
    "            \n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'jeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jeteta_axis),\n",
    "            'jetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jetphi_axis),\n",
    "            \n",
    "            'probept':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'probep':    hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            \n",
    "            'jety':      hist.Hist(\"Counts\", dataset_axis, cats_axis, jety_axis),\n",
    "            'jetdy':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetdy_axis),\n",
    "            \n",
    "            'deepTag_TvsQCD':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tagger_axis),\n",
    "            'deepTagMD_TvsQCD': hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tagger_axis),\n",
    "            \n",
    "            'tau32':          hist.Hist(\"Counts\", dataset_axis, cats_axis, tau32_axis),\n",
    "            'tau32_2D':       hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tau32_axis),\n",
    "            'tau32_precat': hist.Hist(\"Counts\", dataset_axis, jetpt_axis, tau32_axis),\n",
    "            \n",
    "            'subjetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetmass_axis),\n",
    "            'subjetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetpt_axis),\n",
    "            'subjeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjeteta_axis),\n",
    "            'subjetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetphi_axis),\n",
    "            \n",
    "            'numerator':   hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            'denominator': hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            \n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "            \n",
    "        })\n",
    "\n",
    "            \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, events):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        # ---- Define dataset ---- #\n",
    "        dataset = events.metadata['dataset']\n",
    "        \n",
    "        # ---- Get triggers from Dataset_info ---- #\n",
    "        #triggers = [itrig for itrig in Dataset_info if 'HLT_PFHT' in itrig]\n",
    "        #AK8triggers = [itrig for itrig in Dataset_info if 'HLT_AK8PFHT' in itrig]\n",
    "\n",
    "        # ---- Find numeric values in trigger strings ---- #\n",
    "        #triggers_cut1 = [sub.split('PFHT')[1] for sub in triggers] # Remove string characters from left of number\n",
    "        #triggers_cut2 = [sub.split('_')[0] for sub in triggers_cut1] # Remove string characters from right of number\n",
    "        #isTriggerValue = [val.isnumeric() for val in triggers_cut2] # Boolean -> if string is only a number\n",
    "        #triggers_cut2 = np.where(isTriggerValue, triggers_cut2, 0) # If string is not a number, replace with 0\n",
    "        #triggers_vals = [int(val) for val in triggers_cut2] # Convert string numbers to integers\n",
    "        \n",
    "        #AK8triggers_cut1 = [sub.split('HT')[1] for sub in AK8triggers]\n",
    "        #AK8triggers_cut2 = [sub.split('_')[0] for sub in AK8triggers_cut1]\n",
    "        #isAK8TriggerValue = [val.isnumeric() for val in AK8triggers_cut2]\n",
    "        #AK8triggers_cut2 = np.where(isAK8TriggerValue, AK8triggers_cut2, 0)\n",
    "        #AK8triggers_vals = [int(val) for val in AK8triggers_cut2]\n",
    "        \n",
    "        # ---- Find Largest and Second Largest Value ---- #\n",
    "        #triggers_vals.sort(reverse = True)\n",
    "        #AK8triggers_vals.sort(reverse = True)\n",
    "        \n",
    "        #triggers_vals1 = str(triggers_vals[0])\n",
    "        #triggers_vals2 = str(triggers_vals[1])\n",
    "        #AK8triggers_vals1 = str(AK8triggers_vals[0])\n",
    "        #AK8triggers_vals2 = str(AK8triggers_vals[1])\n",
    "        \n",
    "        # ---- Define strings for the selected triggers ---- #\n",
    "        #HLT_trig1_str = [itrig for itrig in triggers if (triggers_vals1) in itrig][0]\n",
    "        #HLT_trig2_str = [itrig for itrig in triggers if (triggers_vals2) in itrig][0]\n",
    "        #HLT_AK8_trig1_str = [itrig for itrig in AK8triggers if (AK8triggers_vals1) in itrig][0]\n",
    "        #HLT_AK8_trig2_str = [itrig for itrig in AK8triggers if (AK8triggers_vals2) in itrig][0]\n",
    "        \n",
    "        # ---- Define HLT triggers to be used ---- #\n",
    "        #HLT_trig1 = df[HLT_trig1_str]\n",
    "        #HLT_trig2 = df[HLT_trig2_str]\n",
    "        #HLT_AK8_trig1 = df[HLT_AK8_trig1_str]\n",
    "        #HLT_AK8_trig2 = df[HLT_AK8_trig2_str]\n",
    "       \n",
    "        \n",
    "        # ---- Define AK8 Jets as FatJets ---- #\n",
    "        #FatJets = events.FatJet # Everything should already be defined in here.  example) df['FatJet_pt] -> events.FatJet.pt\n",
    "        FatJets = ak.zip({\n",
    "            \"nFatJet\": events.nFatJet,\n",
    "            \"pt\": events.FatJet_pt,\n",
    "            \"eta\": events.FatJet_eta,\n",
    "            \"phi\": events.FatJet_phi,\n",
    "            \"mass\": events.FatJet_mass,\n",
    "            \"area\": events.FatJet_area,\n",
    "            \"msoftdrop\": events.FatJet_msoftdrop,\n",
    "            \"jetId\": events.FatJet_jetId,\n",
    "            \"tau1\": events.FatJet_tau1,\n",
    "            \"tau2\": events.FatJet_tau2,\n",
    "            \"tau3\": events.FatJet_tau3,\n",
    "            \"tau4\": events.FatJet_tau4,\n",
    "            \"n3b1\": events.FatJet_n3b1,\n",
    "            \"btagDeepB\": events.FatJet_btagDeepB,\n",
    "            \"btagCSVV2\": events.FatJet_btagCSVV2,\n",
    "            \"deepTag_TvsQCD\": events.FatJet_deepTag_TvsQCD,\n",
    "            \"deepTagMD_TvsQCD\": events.FatJet_deepTagMD_TvsQCD,\n",
    "            \"subJetIdx1\": events.FatJet_subJetIdx1,\n",
    "            \"subJetIdx2\": events.FatJet_subJetIdx2,\n",
    "            \"p4\": ak.zip({\n",
    "                \"pt\": events.FatJet_pt,\n",
    "                \"eta\": events.FatJet_eta,\n",
    "                \"phi\": events.FatJet_phi,\n",
    "                \"mass\": events.FatJet_mass,\n",
    "                }, with_name=\"PtEtaPhiMLorentzVector\"),\n",
    "            })\n",
    "\n",
    "        # ---- Define AK4 jets as Jets ---- #\n",
    "        #Jets = events.Jet\n",
    "        Jets = ak.zip({\n",
    "            \"pt\": events.Jet_pt,\n",
    "            \"eta\": events.Jet_eta,\n",
    "            \"phi\": events.Jet_phi,\n",
    "            \"mass\": events.Jet_mass,\n",
    "            \"area\": events.Jet_area,\n",
    "            \"p4\": ak.zip({\n",
    "                \"pt\": events.Jet_pt,\n",
    "                \"eta\": events.Jet_eta,\n",
    "                \"phi\": events.Jet_phi,\n",
    "                \"mass\": events.Jet_mass,\n",
    "                }, with_name=\"PtEtaPhiMLorentzVector\"),\n",
    "            })\n",
    "\n",
    "        # ---- Define SubJets ---- #\n",
    "        #SubJets = events.SubJet\n",
    "        SubJets = ak.zip({\n",
    "            \"pt\": events.SubJet_pt,\n",
    "            \"eta\": events.SubJet_eta,\n",
    "            \"phi\": events.SubJet_phi,\n",
    "            \"mass\": events.SubJet_mass,\n",
    "            \"btagDeepB\": events.SubJet_btagDeepB,\n",
    "            \"btagCSVV2\": events.SubJet_btagCSVV2,\n",
    "            \"p4\": ak.zip({\n",
    "                \"pt\": events.SubJet_pt,\n",
    "                \"eta\": events.SubJet_eta,\n",
    "                \"phi\": events.SubJet_phi,\n",
    "                \"mass\": events.SubJet_mass,\n",
    "                }, with_name=\"PtEtaPhiMLorentzVector\"),\n",
    "            })\n",
    "        \n",
    "        # ---- Get event weights from dataset ---- #\n",
    "        if 'JetHT' in dataset: # If data is used...\n",
    "            evtweights = np.ones(ak.to_awkward0(FatJets).size) # set all \"data weights\" to one\n",
    "        else: # if Monte Carlo dataset is used...\n",
    "            evtweights = events.Generator_weight\n",
    "        # ---- Show all events ---- #\n",
    "        output['cutflow']['all events'] += ak.to_awkward0(FatJets).size\n",
    "\n",
    "        # ---- Apply Trigger(s) ---- #\n",
    "        #FatJets = FatJets[HLT_AK8_trig1]\n",
    "        #evtweights = evtweights[HLT_AK8_trig1]\n",
    "        #Jets = Jets[HLT_AK8_trig1]\n",
    "        #SubJets = SubJets[HLT_AK8_trig1]\n",
    "        \n",
    "        # ---- Jets that satisfy Jet ID ---- #\n",
    "        jet_id = (FatJets.jetId > 0) # Loose jet ID\n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += ak.to_awkward0(jet_id).any().sum()\n",
    "        \n",
    "        # ---- Apply pT Cut and Rapidity Window ---- #\n",
    "        FatJets_rapidity = .5*np.log( (FatJets.p4.energy + FatJets.p4.pz)/(FatJets.p4.energy - FatJets.p4.pz) )\n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets_rapidity) < 2.4)\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += ak.to_awkward0(jetkincut_index).any().sum()\n",
    "        \n",
    "        # ---- Find two AK8 Jets ---- #\n",
    "        twoFatJetsKin = (ak.num(FatJets, axis=-1) == 2)\n",
    "        FatJets = FatJets[twoFatJetsKin]\n",
    "        evtweights = evtweights[twoFatJetsKin]\n",
    "        Jets = Jets[twoFatJetsKin]\n",
    "        SubJets = SubJets[twoFatJetsKin]\n",
    "        output['cutflow']['two FatJets and jet kin'] += ak.to_awkward0(twoFatJetsKin).sum()\n",
    "        \n",
    "        # ---- Apply HT Cut ---- #\n",
    "        hT = ak.to_awkward0(Jets.pt).sum()\n",
    "        passhT = (hT > self.htCut)\n",
    "        evtweights = evtweights[passhT]\n",
    "        FatJets = FatJets[passhT]\n",
    "        SubJets = SubJets[passhT]\n",
    "        \n",
    "        # ---- Randomly Assign AK8 Jets as TTbar Candidates 0 and 1 --- #\n",
    "        if self.RandomDebugMode == True: # 'Sudo' randomizer for consistent results\n",
    "            highPhi = FatJets.phi[:,0] > FatJets.phi[:,1]\n",
    "            highRandIndex = np.where(highPhi, 0, 1)\n",
    "            index = ak.unflatten( np.ones(len(FatJets), dtype='i'), highRandIndex )\n",
    "        else: # Truly randomize\n",
    "            index = ak.unflatten( np.ones(len(FatJets), dtype='i'), self.prng.randint(2, size=len(FatJets)) )\n",
    "        \n",
    "        jet0 = FatJets[index] #J0\n",
    "        jet1 = FatJets[1 - index] #J1\n",
    "        \n",
    "        ttbarcands = ak.cartesian([jet0, jet1])\n",
    "        \n",
    "        \"\"\" NOTE that ak.cartesian gives a shape with one more layer than FatJets \"\"\"\n",
    "        # ---- Make sure we have at least 1 TTbar candidate pair and re-broadcast releveant arrays  ---- #\n",
    "        oneTTbar = (ak.num(ttbarcands, axis=-1) >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += ak.to_awkward0(oneTTbar).sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "        SubJets = SubJets[oneTTbar]\n",
    "         \n",
    "        # ---- Apply Delta Phi Cut for Back to Back Topology ---- #\n",
    "        \"\"\" NOTE: Should find function for this; avoids 2pi problem \"\"\"\n",
    "        dPhiCut = ttbarcands.slot0.p4.delta_phi(ttbarcands.slot1.p4) > 2.1\n",
    "        dPhiCut = ak.flatten(dPhiCut)\n",
    "        output['cutflow']['dPhi > 2.1'] += ak.to_awkward0(dPhiCut).sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut] \n",
    "        SubJets = SubJets[dPhiCut] \n",
    "        \n",
    "        # ---- Identify subjets according to subjet ID ---- #\n",
    "        hasSubjets0 = ((ttbarcands.slot0.subJetIdx1 > -1) & (ttbarcands.slot0.subJetIdx2 > -1))\n",
    "        hasSubjets1 = ((ttbarcands.slot1.subJetIdx1 > -1) & (ttbarcands.slot1.subJetIdx2 > -1))\n",
    "        GoodSubjets = ak.flatten(((hasSubjets0) & (hasSubjets1)))\n",
    "   \n",
    "        ttbarcands = ttbarcands[GoodSubjets]\n",
    "        \n",
    "        SubJets = SubJets[GoodSubjets]\n",
    "        evtweights = evtweights[GoodSubjets]\n",
    "       \n",
    "        SubJet01 = SubJets[ttbarcands.slot0.subJetIdx1] # FatJet i0 with subjet 1\n",
    "        SubJet02 = SubJets[ttbarcands.slot0.subJetIdx2] # FatJet i0 with subjet 2\n",
    "        SubJet11 = SubJets[ttbarcands.slot1.subJetIdx1] # FatJet i1 with subjet 1\n",
    "        SubJet12 = SubJets[ttbarcands.slot1.subJetIdx2] # FatJet i1 with subjet 2\n",
    "        \n",
    "        # ---- Define Rapidity Regions ---- #\n",
    "        #i0_p = ttbarcands.i0.pt*np.cosh( ttbarcands.i0.eta ) # 3-momentum magnitude\n",
    "        #i1_p = ttbarcands.i1.pt*np.cosh( ttbarcands.i1.eta ) # 3-momentum magnitude\n",
    "        #i0_energy = np.sqrt( ttbarcands.i0.mass**2 + i0_p**2 )\n",
    "        #i1_energy = np.sqrt( ttbarcands.i1.mass**2 + i1_p**2 )\n",
    "        #i0_pz = ttbarcands.i0.pt*np.sinh( ttbarcands.i0.eta )\n",
    "        #i1_pz = ttbarcands.i1.pt*np.sinh( ttbarcands.i1.eta )\n",
    "        s0_energy = ttbarcands.slot0.p4.energy\n",
    "        s1_energy = ttbarcands.slot1.p4.energy\n",
    "        s0_pz = ttbarcands.slot0.p4.pz\n",
    "        s1_pz = ttbarcands.slot1.p4.pz\n",
    "        ttbarcands_s0_rapidity = 0.5*np.log( (s0_energy+s0_pz)/(s0_energy-s0_pz) ) # rapidity as function of eta\n",
    "        ttbarcands_s1_rapidity = 0.5*np.log( (s1_energy+s1_pz)/(s1_energy-s1_pz) ) # rapidity as function of eta\n",
    "        cen = np.abs(ttbarcands_s0_rapidity - ttbarcands_s1_rapidity) < 1.0\n",
    "        fwd = (~cen)\n",
    "        \n",
    "        # ---- CMS Top Tagger Version 2 (SD and Tau32 Cuts) ---- #\n",
    "        tau32_s0 = np.where(ttbarcands.slot0.tau2>0,ttbarcands.slot0.tau3/ttbarcands.slot0.tau2, 0 )\n",
    "        tau32_s1 = np.where(ttbarcands.slot1.tau2>0,ttbarcands.slot1.tau3/ttbarcands.slot1.tau2, 0 )\n",
    "        taucut_s0 = tau32_s0 < self.tau32Cut\n",
    "        taucut_s1 = tau32_s1 < self.tau32Cut\n",
    "        mcut_s0 = (self.minMSD < ttbarcands.slot0.msoftdrop) & (ttbarcands.slot0.msoftdrop < self.maxMSD) \n",
    "        mcut_s1 = (self.minMSD < ttbarcands.slot1.msoftdrop) & (ttbarcands.slot1.msoftdrop < self.maxMSD) \n",
    "\n",
    "        ttag_s0 = (taucut_s0) & (mcut_s0)\n",
    "        ttag_s1 = (taucut_s1) & (mcut_s1)\n",
    "        \n",
    "        # ---- Define \"Top Tag\" Regions ---- #\n",
    "        antitag = (~taucut_s0) & (mcut_s0) #Probe will always be ttbarcands.i1 (at)\n",
    "        antitag_probe = np.logical_and(antitag, ttag_s1) #Found an antitag and ttagged probe pair for mistag rate (Probet)\n",
    "        pretag =  ttag_s0 # Only jet0 (pret)\n",
    "        ttag0 =   (~ttag_s0) & (~ttag_s1) # No tops tagged (0t)\n",
    "        ttag1 =   ttag_s0 ^ ttag_s1 # Exclusively one top tagged (1t)\n",
    "        ttagI =   ttag_s0 | ttag_s1 # At least one top tagged ('I' for 'inclusive' tagger; >=1t; 1t+2t)\n",
    "        ttag2 =   ttag_s0 & ttag_s1 # Both jets top tagged (2t)\n",
    "        Alltags = ttag0 | ttagI #Either no tag or at least one tag (0t+1t+2t)\n",
    "        \n",
    "        # ---- Pick FatJet that passes btag cut based on its subjet with the highest btag value ---- #\n",
    "        btag_s0 = ( np.maximum(SubJet01.btagCSVV2 , SubJet02.btagCSVV2) > self.bdisc )\n",
    "        btag_s1 = ( np.maximum(SubJet11.btagCSVV2 , SubJet12.btagCSVV2) > self.bdisc )\n",
    "        \n",
    "        # --- Define \"B Tag\" Regions ---- #\n",
    "        btag0 = (~btag_s0) & (~btag_s1) #(0b)\n",
    "        btag1 = btag_s0 ^ btag_s1 #(1b)\n",
    "        btag2 = btag_s0 & btag_s1 #(2b)\n",
    "        \n",
    "        # ---- Get Analysis Categories ---- # \n",
    "        # ---- They are (central, forward) cross (0b,1b,2b) cross (Probet,at,0t,1t,>=1t,2t) ---- #\n",
    "        regs = [cen,fwd]\n",
    "        btags = [btag0,btag1,btag2]\n",
    "        ttags = [antitag_probe,antitag,pretag,ttag0,ttag1,ttagI,ttag2,Alltags]\n",
    "        cats = [ ak.to_awkward0(ak.flatten(t&b&y)) for t,b,y in itertools.product( ttags, btags, regs) ]\n",
    "        labels_and_categories = dict(zip( self.anacats, cats ))\n",
    "        #print(labels_and_categories)\n",
    "        \n",
    "        # ---- Variables for Kinematic Histograms ---- #\n",
    "        # ---- \"slot0\" is the control jet, \"slot1\" is the probe jet ---- #\n",
    "        jetpt = ak.flatten(ttbarcands.slot1.pt)\n",
    "        jeteta = ak.flatten(ttbarcands.slot1.eta)\n",
    "        jetphi = ak.flatten(ttbarcands.slot1.phi)\n",
    "        jetmass = ak.flatten(ttbarcands.slot1.mass)\n",
    "        SDmass = ak.flatten(ttbarcands.slot1.msoftdrop)\n",
    "        Tau32 = ak.flatten((ttbarcands.slot1.tau3/ttbarcands.slot1.tau2))\n",
    "\n",
    "        \"\"\" Add 4-vectors and get its total mass \"\"\"\n",
    "        ttbarp4sum = ttbarcands.slot0.p4.add(ttbarcands.slot1.p4)\n",
    "        ttbarmass = ak.flatten(ttbarp4sum.mass)\n",
    "        \n",
    "        \"\"\" Use previously defined definitions for rapidity (until/unless better method is found) \"\"\"\n",
    "        jety = ak.flatten(ttbarcands_s0_rapidity)\n",
    "        jetdy = np.abs(ak.flatten(ttbarcands_s0_rapidity) - ak.flatten(ttbarcands_s1_rapidity))\n",
    "\n",
    "        # ---- Variables for Deep Tagger Analysis ---- #\n",
    "        deepTag = ak.flatten(ttbarcands.slot1.deepTag_TvsQCD)\n",
    "        deepTagMD = ak.flatten(ttbarcands.slot1.deepTagMD_TvsQCD)\n",
    "        \n",
    "        weights = evtweights\n",
    "\n",
    "        # ---- Define the SumW2 for MC Datasets ---- #\n",
    "        output['cutflow']['sumw'] += np.sum(weights)\n",
    "        output['cutflow']['sumw2'] += np.sum(weights**2)\n",
    "        \n",
    "        # ---- Define Momentum p of probe jet as the Mistag Rate variable; M(p) ---- #\n",
    "        # ---- Transverse Momentum pT can also be used instead; M(pT) ---- #\n",
    "        pT = ak.flatten(ttbarcands.slot1.pt)\n",
    "        pz = ak.flatten(ttbarcands.slot1.p4.pz)\n",
    "        p = np.absolute(np.sqrt(pT**2 + pz**2))\n",
    "        \n",
    "        # ---- Define the Numerator and Denominator for Mistag Rate ---- #\n",
    "        numerator = np.where(antitag_probe, p, -1) # If no antitag and tagged probe, move event to useless bin\n",
    "        denominator = np.where(antitag, p, -1) # If no antitag, move event to useless bin\n",
    "        numerator = ak.flatten(numerator)\n",
    "        denominator = ak.flatten(denominator)\n",
    "        \n",
    "        df = pd.DataFrame({\"momentum\":p}) # Used for finding values in LookUp Tables\n",
    "        \n",
    "        for ilabel,icat in labels_and_categories.items():\n",
    "            ### ------------------------------------ Mistag Scaling ------------------------------------ ###\n",
    "            if self.UseLookUpTables == True:\n",
    "                # ---- Weight ttbar M.C. and data by mistag from data (corresponding to its year) ---- #\n",
    "                if 'TTbar_' in dataset:\n",
    "                    file_df = self.lu['JetHT' + dataset[-4:] + '_Data']['at' + str(ilabel[-5:])] #Pick out proper JetHT year mistag for TTbar sim.\n",
    "                elif dataset == 'TTbar':\n",
    "                    file_df = self.lu['JetHT']['at' + str(ilabel[-5:])] # All JetHT years mistag for TTbar sim.\n",
    "                else:\n",
    "                    file_df = self.lu[dataset]['at' + str(ilabel[-5:])] # get mistag (lookup) filename for 'at'\n",
    "                \n",
    "                bin_widths = file_df['p'].values # collect bins as written in .csv file\n",
    "                mtr = file_df['M(p)'].values # collect mistag rate as function of p as written in file\n",
    "                wgts = mtr # Define weights based on mistag rates\n",
    "                \n",
    "                BinKeys = np.arange(bin_widths.size) # Use as label for BinNumber column in the new dataframe\n",
    "                \n",
    "                Bins = np.array(manual_bins)\n",
    "                \n",
    "                df['BinWidth'] = pd.cut(np.asarray(p), bins=Bins) # new dataframe column\n",
    "                df['BinNumber'] = pd.cut(np.asarray(p), bins=Bins, labels=BinKeys)\n",
    "                \n",
    "                BinNumber = df['BinNumber'].values # Collect the Bin Numbers into a numpy array\n",
    "                BinNumber = BinNumber.astype('int64') # Insures the bin numbers are integers\n",
    "            \n",
    "                WeightMatching = wgts[BinNumber] # Match 'wgts' with corresponding p bin using the bin number\n",
    "                Weights = weights*WeightMatching # Include 'wgts' with the previously defined 'weights'\n",
    "            else:\n",
    "                Weights = weights # No mistag rates, no change to weights\n",
    "                \n",
    "            ###---------------------------------------------------------------------------------------------###\n",
    "            ### ----------------------------------- Mod-mass Procedure ------------------------------------ ###\n",
    "            if self.ModMass == True:\n",
    "                QCD_unweighted = util.load('CoffeaOutputs/UnweightedOutputs/TTbarResCoffea_QCD_unweighted_output_futures_3-10-21_trial.coffea') \n",
    "    \n",
    "                # ---- Extract event counts from QCD MC hist in signal region ---- #\n",
    "                QCD_hist = QCD_unweighted['jetmass'].integrate('anacat', '2t' + str(ilabel[-5:])).integrate('dataset', 'QCD')\n",
    "                data = QCD_hist.values() # Dictionary of values\n",
    "                QCD_data = [i for i in data.values()][0] # place every element of the dictionary into a numpy array\n",
    "\n",
    "                # ---- Re-create Bins from QCD_hist as Numpy Array ---- #\n",
    "                bins = np.arange(510) #Re-make bins from the jetmass_axis starting with the appropriate range\n",
    "                QCD_bins = bins[::10] #Finish re-making bins by insuring exactly 50 bins like the jetmass_axis\n",
    "\n",
    "                # ---- Define Mod Mass Distribution ---- #\n",
    "                ModMass_hist_dist = ss.rv_histogram([QCD_data,QCD_bins])\n",
    "                jet1_modp4 = copy.copy(jet1.p4) #J1's Lorentz four vector that can be safely modified\n",
    "                jet1_modp4[\"fMass\"] = ModMass_hist_dist.rvs(size=ak.to_awkward0(jet1_modp4).size) #Replace J1's mass with random value of mass from mm hist\n",
    "                #ttbarcands_modmass = jet0.p4.cross(jet1_modp4) #J0's four vector x modified J1's four vector\n",
    "                ttbarcands_modmass = ak.cartesian([jet0.p4, jet1_modp4])\n",
    "\n",
    "                # ---- Apply Necessary Selections to new modmass version ---- #\n",
    "                ttbarcands_modmass = ttbarcands_modmass[oneTTbar]\n",
    "                ttbarcands_modmass = ttbarcands_modmass[dPhiCut]\n",
    "                ttbarcands_modmass = ttbarcands_modmass[GoodSubjets]\n",
    "                \n",
    "                # ---- Manually sum the modmass p4 candidates (Coffea technicality) ---- #\n",
    "                #ttbarcands_modmass_p4_sum = (ttbarcands_modmass.i0 + ttbarcands_modmass.i1)\n",
    "                ttbarcands_modmassp4sum = ttbarcands.slot0.p4.add(ttbarcands.slot1.p4)\n",
    "                \n",
    "                # ---- Re-define Mass Variables for ModMass Procedure (pt, eta, phi are redundant to change) ---- #\n",
    "                #ttbarmass = ttbarcands_modmass_p4_sum.flatten().mass\n",
    "                #jetmass = ttbarcands_modmass.i1.mass.flatten()\n",
    "                ttbarmass = ak.flatten(ttbarcands_modmassp4sum.mass)\n",
    "                jetmass = ak.flatten(ttbarcands_modmass.slot1.mass)\n",
    "            ###---------------------------------------------------------------------------------------------###\n",
    "            output['cutflow'][ilabel] += np.sum(icat)\n",
    "          \n",
    "            output['ttbarmass'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                ttbarmass = ak.to_numpy(ttbarmass[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jetpt'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetpt = ak.to_numpy(jetpt[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['probept'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetpt = ak.to_numpy(pT[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['probep'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetp = ak.to_numpy(p[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jeteta'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jeteta = ak.to_numpy(jeteta[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jetphi'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetphi = ak.to_numpy(jetphi[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jety'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jety = ak.to_numpy(jety[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jetdy'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetdy = ak.to_numpy(jetdy[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['numerator'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetp = ak.to_numpy(numerator[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['denominator'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                jetp = ak.to_numpy(denominator[icat]),\n",
    "                                weight = ak.to_numpy(Weights[icat]))\n",
    "            output['jetmass'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                   jetmass = ak.to_numpy(jetmass[icat]),\n",
    "                                   weight = ak.to_numpy(Weights[icat]))\n",
    "            output['SDmass'].fill(dataset = dataset, anacat = ilabel, \n",
    "                                   jetmass = ak.to_numpy(SDmass[icat]),\n",
    "                                   weight = ak.to_numpy(Weights[icat]))\n",
    "            output['tau32'].fill(dataset = dataset, anacat = ilabel,\n",
    "                                          tau32 = ak.to_numpy(Tau32[icat]),\n",
    "                                          weight = ak.to_numpy(Weights[icat]))\n",
    "            output['tau32_2D'].fill(dataset = dataset, anacat = ilabel,\n",
    "                                          jetpt = ak.to_numpy(pT[icat]),\n",
    "                                          tau32 = ak.to_numpy(Tau32[icat]),\n",
    "                                          weight = ak.to_numpy(Weights[icat]))\n",
    "            output['deepTag_TvsQCD'].fill(dataset = dataset, anacat = ilabel,\n",
    "                                          jetpt = ak.to_numpy(pT[icat]),\n",
    "                                          tagger = ak.to_numpy(deepTag[icat]),\n",
    "                                          weight = ak.to_numpy(Weights[icat]))\n",
    "            output['deepTagMD_TvsQCD'].fill(dataset = dataset, anacat = ilabel,\n",
    "                                            jetpt = ak.to_numpy(pT[icat]),\n",
    "                                            tagger = ak.to_numpy(deepTagMD[icat]),\n",
    "                                            weight = ak.to_numpy(Weights[icat]))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script TTbarResProcessor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

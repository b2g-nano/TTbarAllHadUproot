{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResProcessor` Notebook for an all hadronic $t\\bar{t}$ analysis: \n",
    "This notebook contains the processor necessary for analysis and is to be imported into the `TTbarResCoffeaOutputs` module.  To import it, one can ensure that this module can be ran here by executing the notebook.  If everything executes with no errors, one can create a .py file of this module by uncommenting and running the last cell in tis notebook.  That .py file is the module that is imported to create Coffea output files.\n",
    "\n",
    "   1. Make the mistag rate in the \"anti-tag\" selection region,\n",
    "   1. Later apply that mistag rate and the mod-mass procedure to the single-tag (pre-tag) selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag (pret) selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 950$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n",
    "# Quick Reference for Tag Region Definitions:\n",
    "- An antitag and t-tagged probe pair region; numerator value of mistag [region used for closure test] (Probet)\n",
    "- An antitag [and any probe pair] region; denominator value; [region used for mistag weights] (at)\n",
    "- t-tagged jet0 region [region used for data-driven background estimate] (pret)\n",
    "- No tops tagged (0t)\n",
    "- Exclusively one jet is top tagged (1t)\n",
    "- At least one jet is top tagged ['inclusive' tagger; >=1t] (1t+2t)\n",
    "- Both jets are top tagged (2t)\n",
    "- Either no tag or at least one tag ['all inclusive' tagger; >=0t] (0t+1t+2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy.stats as ss\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea import util\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`manual_bins` is set up to define the bin sizes the user wants for the mistag rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_bins = [400, 500, 600, 800, 1000, 1500, 2000, 3000, 7000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All histograms that one wishes to be included in the Coffea output files is to be defined and filled in this processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, prng, htCut=950., minMSD=105., maxMSD=210., tau32Cut=0.65, ak8PtMin=400., bdisc=0.8484,\n",
    "                writePredDist=True,isData=True,year=2019, UseLookUpTables=False, lu=None, \n",
    "                ModMass=False, RandomDebugMode=False):\n",
    "        \n",
    "        self.prng = prng\n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        self.UseLookUpTables = UseLookUpTables\n",
    "        self.ModMass = ModMass\n",
    "        self.RandomDebugMode = RandomDebugMode\n",
    "        self.lu = lu # Look Up Tables\n",
    "        \n",
    "        self.ttagcats = [\"Probet\", \"at\", \"pret\", \"0t\", \"1t\", \"1t+2t\", \"2t\", \"0t+1t+2t\"] #anti-tag+probe, anti-tag, pre-tag, 0, 1, >=1, 2 ttags, any t-tag\n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        # Combine categories like \"1t0bcen\", \"pret2bfwd\", etc:\n",
    "        self.anacats = [ t+b+y for t,b,y in itertools.product( self.ttagcats, self.btagcats, self.ycats) ]\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 5000)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "        jeteta_axis = hist.Bin(\"jeteta\", r\"Jet $\\eta$\", 50, -5, 5)\n",
    "        jetphi_axis = hist.Bin(\"jetphi\", r\"Jet $\\phi$\", 50, -np.pi, np.pi)\n",
    "        jety_axis = hist.Bin(\"jety\", r\"Jet $y$\", 50, -3, 3)\n",
    "        jetdy_axis = hist.Bin(\"jetdy\", r\"Jet $\\Delta y$\", 50, 0, 5)\n",
    "        manual_axis = hist.Bin(\"jetp\", r\"Jet Momentum [GeV]\", manual_bins)\n",
    "        tagger_axis = hist.Bin(\"tagger\", r\"deepTag\", 50, 0, 1)\n",
    "        tau32_axis = hist.Bin(\"tau32\", r\"$\\tau_3/\\tau_2$\", 50, 0, 2)\n",
    "        \n",
    "        subjetmass_axis = hist.Bin(\"subjetmass\", r\"SubJet $m$ [GeV]\", 50, 0, 500)\n",
    "        subjetpt_axis = hist.Bin(\"subjetpt\", r\"SubJet $p_{T}$ [GeV]\", 50, 0, 2000)\n",
    "        subjeteta_axis = hist.Bin(\"subjeteta\", r\"SubJet $\\eta$\", 50, -4, 4)\n",
    "        subjetphi_axis = hist.Bin(\"subjetphi\", r\"SubJet $\\phi$\", 50, -np.pi, np.pi)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            \n",
    "            'jetmass':         hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'SDmass':          hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'SDmass_precat':   hist.Hist(\"Counts\", dataset_axis, jetpt_axis, jetmass_axis),\n",
    "            \n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'jeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jeteta_axis),\n",
    "            'jetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jetphi_axis),\n",
    "            \n",
    "            'probept':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'probep':    hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            \n",
    "            'jety':      hist.Hist(\"Counts\", dataset_axis, cats_axis, jety_axis),\n",
    "            'jetdy':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetdy_axis),\n",
    "            \n",
    "            'deepTag_TvsQCD':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tagger_axis),\n",
    "            'deepTagMD_TvsQCD': hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tagger_axis),\n",
    "            \n",
    "            'tau32':          hist.Hist(\"Counts\", dataset_axis, cats_axis, tau32_axis),\n",
    "            'tau32_2D':       hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis, tau32_axis),\n",
    "            'tau32_precat': hist.Hist(\"Counts\", dataset_axis, jetpt_axis, tau32_axis),\n",
    "            \n",
    "            'subjetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetmass_axis),\n",
    "            'subjetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetpt_axis),\n",
    "            'subjeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjeteta_axis),\n",
    "            'subjetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetphi_axis),\n",
    "            \n",
    "            'numerator':   hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            'denominator': hist.Hist(\"Counts\", dataset_axis, cats_axis, manual_axis),\n",
    "            \n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "            \n",
    "        })\n",
    "\n",
    "            \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        # ---- Define dataset ---- #\n",
    "        dataset = df['dataset'] #coffea.processor.LazyDataFrame\n",
    "        Dataset_info = df.available #list of available columns in LazyDataFrame object (Similar to 'Events->Show()' command in ROOT)\n",
    "        \n",
    "        # ---- Get triggers from Dataset_info ---- #\n",
    "        #triggers = [itrig for itrig in Dataset_info if 'HLT_PFHT' in itrig]\n",
    "        #AK8triggers = [itrig for itrig in Dataset_info if 'HLT_AK8PFHT' in itrig]\n",
    "\n",
    "        # ---- Find numeric values in trigger strings ---- #\n",
    "        #triggers_cut1 = [sub.split('PFHT')[1] for sub in triggers] # Remove string characters from left of number\n",
    "        #triggers_cut2 = [sub.split('_')[0] for sub in triggers_cut1] # Remove string characters from right of number\n",
    "        #isTriggerValue = [val.isnumeric() for val in triggers_cut2] # Boolean -> if string is only a number\n",
    "        #triggers_cut2 = np.where(isTriggerValue, triggers_cut2, 0) # If string is not a number, replace with 0\n",
    "        #triggers_vals = [int(val) for val in triggers_cut2] # Convert string numbers to integers\n",
    "        \n",
    "        #AK8triggers_cut1 = [sub.split('HT')[1] for sub in AK8triggers]\n",
    "        #AK8triggers_cut2 = [sub.split('_')[0] for sub in AK8triggers_cut1]\n",
    "        #isAK8TriggerValue = [val.isnumeric() for val in AK8triggers_cut2]\n",
    "        #AK8triggers_cut2 = np.where(isAK8TriggerValue, AK8triggers_cut2, 0)\n",
    "        #AK8triggers_vals = [int(val) for val in AK8triggers_cut2]\n",
    "        \n",
    "        # ---- Find Largest and Second Largest Value ---- #\n",
    "        #triggers_vals.sort(reverse = True)\n",
    "        #AK8triggers_vals.sort(reverse = True)\n",
    "        \n",
    "        #triggers_vals1 = str(triggers_vals[0])\n",
    "        #triggers_vals2 = str(triggers_vals[1])\n",
    "        #AK8triggers_vals1 = str(AK8triggers_vals[0])\n",
    "        #AK8triggers_vals2 = str(AK8triggers_vals[1])\n",
    "        \n",
    "        # ---- Define strings for the selected triggers ---- #\n",
    "        #HLT_trig1_str = [itrig for itrig in triggers if (triggers_vals1) in itrig][0]\n",
    "        #HLT_trig2_str = [itrig for itrig in triggers if (triggers_vals2) in itrig][0]\n",
    "        #HLT_AK8_trig1_str = [itrig for itrig in AK8triggers if (AK8triggers_vals1) in itrig][0]\n",
    "        #HLT_AK8_trig2_str = [itrig for itrig in AK8triggers if (AK8triggers_vals2) in itrig][0]\n",
    "        \n",
    "        # ---- Define HLT triggers to be used ---- #\n",
    "        #HLT_trig1 = df[HLT_trig1_str]\n",
    "        #HLT_trig2 = df[HLT_trig2_str]\n",
    "        #HLT_AK8_trig1 = df[HLT_AK8_trig1_str]\n",
    "        #HLT_AK8_trig2 = df[HLT_AK8_trig2_str]\n",
    "       \n",
    "        \n",
    "        # ---- Define AK8 Jets as FatJets ---- #\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            area=df['FatJet_area'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            tau1=df['FatJet_tau1'],\n",
    "            tau2=df['FatJet_tau2'],\n",
    "            tau3=df['FatJet_tau3'],\n",
    "            tau4=df['FatJet_tau4'],\n",
    "            n3b1=df['FatJet_n3b1'],\n",
    "            btagDeepB=df['FatJet_btagDeepB'],\n",
    "            btagCSVV2=df['FatJet_btagCSVV2'],\n",
    "            deepTag_TvsQCD=df['FatJet_deepTag_TvsQCD'],\n",
    "            deepTagMD_TvsQCD=df['FatJet_deepTagMD_TvsQCD'],\n",
    "            subJetIdx1=df['FatJet_subJetIdx1'],\n",
    "            subJetIdx2=df['FatJet_subJetIdx2']\n",
    "            )\n",
    "        \n",
    "        # ---- Define AK4 jets as Jets ---- #\n",
    "        Jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'],\n",
    "            eta=df['Jet_eta'],\n",
    "            phi=df['Jet_phi'],\n",
    "            mass=df['Jet_mass'],\n",
    "            area=df['Jet_area']\n",
    "            )\n",
    "        # ---- Define SubJets ---- #\n",
    "        SubJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nSubJet'],\n",
    "            pt=df['SubJet_pt'],\n",
    "            eta=df['SubJet_eta'],\n",
    "            phi=df['SubJet_phi'],\n",
    "            mass=df['SubJet_mass'],\n",
    "            btagDeepB=df['SubJet_btagDeepB'],\n",
    "            btagCSVV2=df['SubJet_btagCSVV2']\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # ---- Get event weights from dataset ---- #\n",
    "        if 'JetHT' in dataset: # If data is used...\n",
    "            evtweights = np.ones(FatJets.size) # set all \"data weights\" to one\n",
    "        else: # if Monte Carlo dataset is used...\n",
    "            evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        \n",
    "        # ---- Show all events ---- #\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "        \n",
    "        # ---- Apply Trigger(s) ---- #\n",
    "        #FatJets = FatJets[HLT_AK8_trig1]\n",
    "        #evtweights = evtweights[HLT_AK8_trig1]\n",
    "        #Jets = Jets[HLT_AK8_trig1]\n",
    "        #SubJets = SubJets[HLT_AK8_trig1]\n",
    "        \n",
    "        # ---- Jets that satisfy Jet ID ---- #\n",
    "        jet_id = (FatJets.jetId > 0) # Loose jet ID\n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        # ---- Apply pT Cut and Rapidity Window ---- #\n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets.p4.rapidity) < 2.4)\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += jetkincut_index.any().sum()\n",
    "        \n",
    "        # ---- Find two AK8 Jets ---- #\n",
    "        twoFatJetsKin = (FatJets.counts == 2)\n",
    "        FatJets = FatJets[twoFatJetsKin]\n",
    "        evtweights = evtweights[twoFatJetsKin]\n",
    "        Jets = Jets[twoFatJetsKin]\n",
    "        SubJets = SubJets[twoFatJetsKin]\n",
    "        output['cutflow']['two FatJets and jet kin'] += twoFatJetsKin.sum()\n",
    "        \n",
    "        # ---- Apply HT Cut ---- #\n",
    "        hT = Jets.pt.sum()\n",
    "        passhT = (hT > self.htCut)\n",
    "        evtweights = evtweights[passhT]\n",
    "        FatJets = FatJets[passhT]\n",
    "        SubJets = SubJets[passhT]\n",
    "        \n",
    "        # ---- Randomly Assign AK8 Jets as TTbar Candidates 0 and 1 --- #\n",
    "        if self.RandomDebugMode == True: # 'Sudo' randomizer for consistent results\n",
    "            highPhi = FatJets.phi[:,0] > FatJets.phi[:,1]\n",
    "            highRandIndex = np.where(highPhi, 0, 1)\n",
    "            index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), highRandIndex )\n",
    "        else: # Truly randomize\n",
    "            index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), prng.randint(2, size=len(FatJets)))\n",
    "        jet0 = FatJets[index] #J0\n",
    "        jet1 = FatJets[1 - index] #J1\n",
    "        \n",
    "        ttbarcands = jet0.cross(jet1) #FatJets[:,0:2].distincts()\n",
    "    \n",
    "        # ---- Make sure we have at least 1 TTbar candidate pair and re-broadcast releveant arrays  ---- #\n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "        SubJets = SubJets[oneTTbar]\n",
    "         \n",
    "        # ---- Apply Delta Phi Cut for Back to Back Topology ---- #\n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut] \n",
    "        SubJets = SubJets[dPhiCut] \n",
    "        \n",
    "        # ---- Identify subjets according to subjet ID ---- #\n",
    "        hasSubjets0 = ((ttbarcands.i0.subJetIdx1 > -1) & (ttbarcands.i0.subJetIdx2 > -1))\n",
    "        hasSubjets1 = ((ttbarcands.i1.subJetIdx1 > -1) & (ttbarcands.i1.subJetIdx2 > -1))\n",
    "        GoodSubjets = ((hasSubjets0) & (hasSubjets1)).flatten()\n",
    "   \n",
    "        ttbarcands = ttbarcands[GoodSubjets]\n",
    "        \n",
    "        SubJets = SubJets[GoodSubjets]\n",
    "        evtweights = evtweights[GoodSubjets]\n",
    "       \n",
    "        SubJet01 = SubJets[ttbarcands.i0.subJetIdx1] # FatJet i0 with subjet 1\n",
    "        SubJet02 = SubJets[ttbarcands.i0.subJetIdx2] # FatJet i0 with subjet 2\n",
    "        SubJet11 = SubJets[ttbarcands.i1.subJetIdx1] # FatJet i1 with subjet 1\n",
    "        SubJet12 = SubJets[ttbarcands.i1.subJetIdx2] # FatJet i1 with subjet 2\n",
    "        \n",
    "        # ---- Define Rapidity Regions ---- #\n",
    "        cen = np.abs(ttbarcands.i0.p4.rapidity - ttbarcands.i1.p4.rapidity) < 1.0\n",
    "        fwd = (~cen)\n",
    "        \n",
    "        # ---- CMS Top Tagger Version 2 (SD and Tau32 Cuts) ---- #\n",
    "        tau32_i0 = np.where(ttbarcands.i0.tau2>0,ttbarcands.i0.tau3/ttbarcands.i0.tau2, 0 )\n",
    "        tau32_i1 = np.where(ttbarcands.i1.tau2>0,ttbarcands.i1.tau3/ttbarcands.i1.tau2, 0 )\n",
    "        taucut_i0 = tau32_i0 < self.tau32Cut\n",
    "        taucut_i1 = tau32_i1 < self.tau32Cut\n",
    "        mcut_i0 = (self.minMSD < ttbarcands.i0.msoftdrop) & (ttbarcands.i0.msoftdrop < self.maxMSD) \n",
    "        mcut_i1 = (self.minMSD < ttbarcands.i1.msoftdrop) & (ttbarcands.i1.msoftdrop < self.maxMSD) \n",
    "\n",
    "        ttag_i0 = (taucut_i0) & (mcut_i0)\n",
    "        ttag_i1 = (taucut_i1) & (mcut_i1)\n",
    "        \n",
    "        # ---- Define \"Top Tag\" Regions ---- #\n",
    "        antitag = (~taucut_i0) & (mcut_i0) #Probe will always be ttbarcands.i1 (at)\n",
    "        antitag_probe = np.logical_and(antitag, ttag_i1) #Found an antitag and ttagged probe pair for mistag rate (Probet)\n",
    "        pretag =  ttag_i0 # Only jet0 (pret)\n",
    "        ttag0 =   (~ttag_i0) & (~ttag_i1) # No tops tagged (0t)\n",
    "        ttag1 =   ttag_i0 ^ ttag_i1 # Exclusively one top tagged (1t)\n",
    "        ttagI =   ttag_i0 | ttag_i1 # At least one top tagged ('I' for 'inclusive' tagger; >=1t; 1t+2t)\n",
    "        ttag2 =   ttag_i0 & ttag_i1 # Both jets top tagged (2t)\n",
    "        Alltags = ttag0 | ttagI #Either no tag or at least one tag (0t+1t+2t)\n",
    "        \n",
    "        # ---- Pick FatJet that passes btag cut based on its subjet with the highest btag value ---- # \n",
    "        btag_i0 = ( np.maximum(SubJet01.btagCSVV2 , SubJet02.btagCSVV2) > self.bdisc )\n",
    "        btag_i1 = ( np.maximum(SubJet11.btagCSVV2 , SubJet12.btagCSVV2) > self.bdisc )\n",
    "        \n",
    "        # --- Define \"B Tag\" Regions ---- #\n",
    "        btag0 = (~btag_i0) & (~btag_i1) #(0b)\n",
    "        btag1 = btag_i0 ^ btag_i1 #(1b)\n",
    "        btag2 = btag_i0 & btag_i1 #(2b)\n",
    "        \n",
    "        # ---- Get Analysis Categories ---- # \n",
    "        # ---- They are (central, forward) cross (0b,1b,2b) cross (Probet,at,0t,1t,>=1t,2t) ---- #\n",
    "        regs = [cen,fwd]\n",
    "        btags = [btag0,btag1,btag2]\n",
    "        ttags = [antitag_probe,antitag,pretag,ttag0,ttag1,ttagI,ttag2,Alltags]\n",
    "        cats = [ (t&b&y).flatten() for t,b,y in itertools.product( ttags, btags, regs) ]\n",
    "        labels_and_categories = dict(zip( self.anacats, cats ))\n",
    "        \n",
    "        # ---- Variables for Kinematic Histograms ---- #\n",
    "        # ---- \"i0\" is the control jet, \"i1\" is the probe jet ---- #\n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()\n",
    "        jetpt = ttbarcands.i1.pt.flatten()\n",
    "        jeteta = ttbarcands.i1.eta.flatten()\n",
    "        jetphi = ttbarcands.i1.phi.flatten()\n",
    "        jety = ttbarcands.i1.p4.rapidity.flatten()\n",
    "        jetmass = ttbarcands.i1.p4.mass.flatten()\n",
    "        SDmass = ttbarcands.i1.msoftdrop.flatten()\n",
    "        jetdy = np.abs(ttbarcands.i0.p4.rapidity.flatten() - ttbarcands.i1.p4.rapidity.flatten())\n",
    "        Tau32 = (ttbarcands.i1.tau3/ttbarcands.i1.tau2).flatten()\n",
    "        # ---- Variables for Deep Tagger Analysis ---- #\n",
    "        deepTag = ttbarcands.i1.deepTag_TvsQCD.flatten()\n",
    "        deepTagMD = ttbarcands.i1.deepTagMD_TvsQCD.flatten()\n",
    "        \n",
    "        weights = evtweights.flatten()\n",
    "        \n",
    "        # ---- Define the SumW2 for MC Datasets ---- #\n",
    "        output['cutflow']['sumw'] += np.sum(weights)\n",
    "        output['cutflow']['sumw2'] += np.sum(weights**2)\n",
    "        \n",
    "        # ---- Define Momentum p of probe jet as the Mistag Rate variable; M(p) ---- #\n",
    "        # ---- Transverse Momentum pT can also be used instead; M(pT) ---- #\n",
    "        pT = ttbarcands.i1.pt.flatten()\n",
    "        eta = ttbarcands.i1.eta.flatten()\n",
    "        pz = np.sinh(eta)*pT\n",
    "        p = np.absolute(np.sqrt(pT**2 + pz**2))\n",
    "        \n",
    "        # ---- Define the Numerator and Denominator for Mistag Rate ---- #\n",
    "        numerator = np.where(antitag_probe, p, -1) # If no antitag and tagged probe, move event to useless bin\n",
    "        denominator = np.where(antitag, p, -1) # If no antitag, move event to useless bin\n",
    "        \n",
    "        df = pd.DataFrame({\"momentum\":p}) # Used for finding values in LookUp Tables\n",
    "        \n",
    "        for ilabel,icat in labels_and_categories.items():\n",
    "            ### ------------------------------------ Mistag Scaling ------------------------------------ ###\n",
    "            if self.UseLookUpTables == True:\n",
    "                # ---- Weight ttbar M.C. and data by mistag from data (corresponding to its year) ---- #\n",
    "                if 'TTbar_' in dataset:\n",
    "                    file_df = self.lu['JetHT' + dataset[-4:] + '_Data']['at' + str(ilabel[-5:])] #Pick out proper JetHT year mistag for TTbar sim.\n",
    "                elif dataset == 'TTbar':\n",
    "                    file_df = self.lu['JetHT']['at' + str(ilabel[-5:])] # All JetHT years mistag for TTbar sim.\n",
    "                else:\n",
    "                    file_df = self.lu[dataset]['at' + str(ilabel[-5:])] # get mistag (lookup) filename for 'at'\n",
    "                \n",
    "                bin_widths = file_df['p'].values # collect bins as written in .csv file\n",
    "                mtr = file_df['M(p)'].values # collect mistag rate as function of p as written in file\n",
    "                wgts = mtr # Define weights based on mistag rates\n",
    "                \n",
    "                BinKeys = np.arange(bin_widths.size) # Use as label for BinNumber column in the new dataframe\n",
    "                \n",
    "                #Bins = pd.interval_range(start=0, periods=100, freq=100, closed='left') # Recreate the momentum bins from file_df as something readable for pd.cut()\n",
    "                Bins = np.array(manual_bins)\n",
    "                \n",
    "                df['BinWidth'] = pd.cut(p, bins=Bins) # new dataframe column\n",
    "                df['BinNumber'] = pd.cut(p, bins=Bins, labels=BinKeys)\n",
    "                \n",
    "                BinNumber = df['BinNumber'].values # Collect the Bin Numbers into a numpy array\n",
    "                BinNumber = BinNumber.astype('int64') # Insures the bin numbers are integers\n",
    "            \n",
    "                WeightMatching = wgts[BinNumber] # Match 'wgts' with corresponding p bin using the bin number\n",
    "                Weights = weights*WeightMatching # Include 'wgts' with the previously defined 'weights'\n",
    "            else:\n",
    "                Weights = weights # No mistag rates, no change to weights\n",
    "            ###---------------------------------------------------------------------------------------------###\n",
    "            ### ----------------------------------- Mod-mass Procedure ------------------------------------ ###\n",
    "            if self.ModMass == True:\n",
    "                QCD_unweighted = util.load('TTbarResCoffea_QCD_unweighted_output.coffea')\n",
    "    \n",
    "                # ---- Extract event counts from QCD MC hist in signal region ---- #\n",
    "                QCD_hist = QCD_unweighted['jetmass'].integrate('anacat', '2t' + str(ilabel[-5:])).integrate('dataset', 'QCD')\n",
    "                data = QCD_hist.values() # Dictionary of values\n",
    "                QCD_data = [i for i in data.values()][0] # place every element of the dictionary into a numpy array\n",
    "\n",
    "                # ---- Re-create Bins from QCD_hist as Numpy Array ---- #\n",
    "                bins = np.arange(510) #Re-make bins from the jetmass_axis starting with the appropriate range\n",
    "                QCD_bins = bins[::10] #Finish re-making bins by insuring exactly 50 bins like the jetmass_axis\n",
    "\n",
    "                # ---- Define Mod Mass Distribution ---- #\n",
    "                ModMass_hist_dist = ss.rv_histogram([QCD_data,QCD_bins])\n",
    "                jet1_modp4 = copy.copy(jet1.p4) #J1's Lorentz four vector that can be safely modified\n",
    "                jet1_modp4[\"fMass\"] = ModMass_hist_dist.rvs(size=jet1_modp4.size) #Replace J1's mass with random value of mass from mm hist\n",
    "                ttbarcands_modmass = jet0.p4.cross(jet1_modp4) #J0's four vector x modified J1's four vector\n",
    "\n",
    "                # ---- Apply Necessary Selections to new modmass version ---- #\n",
    "                ttbarcands_modmass = ttbarcands_modmass[oneTTbar]\n",
    "                ttbarcands_modmass = ttbarcands_modmass[dPhiCut]\n",
    "                ttbarcands_modmass = ttbarcands_modmass[GoodSubjets]\n",
    "                \n",
    "                # ---- Manually sum the modmass p4 candidates (Coffea technicality) ---- #\n",
    "                ttbarcands_modmass_p4_sum = (ttbarcands_modmass.i0 + ttbarcands_modmass.i1)\n",
    "                \n",
    "                # ---- Re-define Mass Variables for ModMass Procedure (pt, eta, phi are redundant to change) ---- #\n",
    "                ttbarmass = ttbarcands_modmass_p4_sum.flatten().mass\n",
    "                jetmass = ttbarcands_modmass.i1.mass.flatten()\n",
    "            ###---------------------------------------------------------------------------------------------###\n",
    "            output['cutflow'][ilabel] += np.sum(icat)\n",
    "          \n",
    "            output['ttbarmass'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                ttbarmass=ttbarmass[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetpt'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetpt=jetpt[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['probept'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetpt=pT[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['probep'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetp=p[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jeteta'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jeteta=jeteta[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetphi'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetphi=jetphi[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jety'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jety=jety[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetdy'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetdy=jetdy[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['numerator'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetp=numerator[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['denominator'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetp=denominator[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetmass'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                   jetmass=jetmass[icat],\n",
    "                                   weight=Weights[icat])\n",
    "            output['SDmass'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                   jetmass=SDmass[icat],\n",
    "                                   weight=Weights[icat])\n",
    "            output['tau32'].fill(dataset=dataset, anacat=ilabel,\n",
    "                                          tau32=Tau32[icat],\n",
    "                                          weight=Weights[icat])\n",
    "            output['tau32_2D'].fill(dataset=dataset, anacat=ilabel,\n",
    "                                          jetpt=pT[icat],\n",
    "                                          tau32=Tau32[icat],\n",
    "                                          weight=Weights[icat])\n",
    "            output['deepTag_TvsQCD'].fill(dataset=dataset, anacat=ilabel,\n",
    "                                          jetpt=pT[icat],\n",
    "                                          tagger=deepTag[icat],\n",
    "                                          weight=Weights[icat])\n",
    "            output['deepTagMD_TvsQCD'].fill(dataset=dataset, anacat=ilabel,\n",
    "                                            jetpt=pT[icat],\n",
    "                                            tagger=deepTagMD[icat],\n",
    "                                            weight=Weights[icat])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script TTbarResProcessor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffeaOutputs` Notebook to produce Coffea output files for an all hadronic $t\\bar{t}$ analysis.  The outputs will be found in the corresponding **CoffeaOutputs** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import scipy.stats as ss\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea import util\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from columnservice.client import ColumnClient\n",
    "#cc = ColumnClient(\"coffea-dask.fnal.gov\")\n",
    "#client = cc.get_dask()\n",
    "\n",
    "#from distributed import Client\n",
    "#client = Client('coffea-dask.fnal.gov:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from columnservice.client import FileManager\n",
    "#FileManager.open_file(TTbarResProcessor.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of 2/1/21, I haven't found a way to import the other modules defined in this current directory while running the uproot job with `processor.dask_executor`.  Any attempt to do so, the coffea processor will not recognize the module(s) as being imported properly due to how `cloudpickle` is currently implemented.  A solution (or a workaround) is being sought, but in the meantime, `processor.futures_executor` works just fine!\n",
    "\n",
    "One possible fix for this is to find some importing method that is found in the `columnservice.client` tools.  Needs a deeper look...\n",
    "\n",
    "If time is of the essence, one can copy and paste the cells from these modules in place of the `import` statements below to run with dask. Otherwise, run this notebook as is and grab some popcorn while Coffea works its magic :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTbarResProcessor import TTbarResProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filesets import filesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "outputs_unweighted = {}\n",
    "\n",
    "seed = 1234577890\n",
    "prng = RandomState(seed)\n",
    "Chunk = [100000, 10] # [chunksize, maxchunks]\n",
    "\n",
    "for name,files in filesets.items(): \n",
    "    \n",
    "\n",
    "    print(name)\n",
    "    output = processor.run_uproot_job({name:files},\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=TTbarResProcessor(UseLookUpTables=False,\n",
    "                                                                           ModMass=False,\n",
    "                                                                           RandomDebugMode=True,\n",
    "                                                                           prng=prng),\n",
    "                                      #executor=processor.dask_executor,\n",
    "                                      #executor=processor.iterative_executor,\n",
    "                                      executor=processor.futures_executor,\n",
    "                                      executor_args={\n",
    "                                          #'client': client, \n",
    "                                          'nano':False, \n",
    "                                          'flatten':True, \n",
    "                                          'skipbadfiles':False,\n",
    "                                          'workers': 2},\n",
    "                                      chunksize=Chunk[0], maxchunks=Chunk[1]\n",
    "                                     )\n",
    "\n",
    "    elapsed = time.time() - tstart\n",
    "    outputs_unweighted[name] = output\n",
    "    print(output)\n",
    "    #util.save(output, 'CoffeaOutputs/UnweightedOutputs/TTbarResCoffea_' + name + '_unweighted_output_partial_2021_dask_run.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name,output in outputs_unweighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the `TTbarResLookUpTables` module by simply importing it.  If it works, it will print out varies pandas dataframes with information about the mistag rates and finally print the `luts` multi-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TTbarResLookUpTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import that multi-dictionary `luts`, as it is needed for the processor to create output files.  These new output files will have the necessary datasets weighted by their corresponding mistag rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTbarResLookUpTables import luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filesets import filesets_forweights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the necessary files have been included in the `TTbarResLookUpTables` process before running the next processor, as the mistag procedure is found within that module.  For details about the categories used to write the mistag procedure, refer to the `TTbarResProcessor` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Runs Processor, Weights Datasets with Corresponding Mistag Weight, Implements Mass Modification Procedure \"\"\"\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "seed = 1234577890\n",
    "outputs_weighted = {}\n",
    "prng = RandomState(seed)\n",
    "Chunk = [100000, 10] # [chunksize, maxchunks]\n",
    "\n",
    "for name,files in filesets_forweights.items(): \n",
    "    \n",
    "\n",
    "    print(name)\n",
    "    output = processor.run_uproot_job({name:files},\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=TTbarResProcessor(UseLookUpTables=True,\n",
    "                                                                           ModMass = True,\n",
    "                                                                           RandomDebugMode = False,\n",
    "                                                                           lu=luts,\n",
    "                                                                           prng=prng),\n",
    "                                      #executor=processor.dask_executor,\n",
    "                                      #executor=processor.iterative_executor,\n",
    "                                      executor=processor.futures_executor,\n",
    "                                      executor_args={\n",
    "                                          #'client': client, \n",
    "                                          'nano':False, \n",
    "                                          'flatten':True, \n",
    "                                          'skipbadfiles':False,\n",
    "                                          'workers': 2},\n",
    "                                      chunksize=Chunk[0], maxchunks=Chunk[1]\n",
    "                                     )\n",
    "\n",
    "    elapsed = time.time() - tstart\n",
    "    outputs_weighted[name] = output\n",
    "    print(output)\n",
    "    #util.save(output, 'CoffeaOutputs/WeightedModMassOutputs/TTbarResCoffea_' + name + '_ModMass_weighted_output_partial_2021_dask_run.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name,output in outputs_weighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

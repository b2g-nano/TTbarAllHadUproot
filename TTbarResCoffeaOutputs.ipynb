{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffeaOutputs` Notebook to produce Coffea output files for an all hadronic $t\\bar{t}$ analysis, should one choose not to run the .py script with condor.  The outputs will be found in the corresponding **CoffeaOutputs** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import scipy.stats as ss\n",
    "from coffea import hist, processor, nanoevents, util\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents import NanoAODSchema, BaseSchema\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.behavior.update(candidate.behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from columnservice.client import ColumnClient\n",
    "#cc = ColumnClient(\"coffea-dask.fnal.gov\")\n",
    "#client = cc.get_dask()\n",
    "\n",
    "#from distributed import Client\n",
    "#client = Client('coffea-dask.fnal.gov:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from columnservice.client import FileManager\n",
    "#FileManager.open_file(TTbarResProcessor.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook mimicks the script except for the subtle changes in imports.  \n",
    "\n",
    "Notice how we import the processor from `TTbarResProcessor_nb.py` where the `_nb` shows we are looking in a slightly modified version of the `TTbarResProcessor.py` script.  This is because this coffea notebook is ran from within the **TTbarAllHadUproot** directory, rather than outside of it to communicate with the **lpc_dask** like the script version (`TTbarResCoffeaOutputs.py`) requires.\n",
    "\n",
    "Similar logic is demonstrated whenever you come across `<filename>_nb` or `<filename>_nb.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTbarResProcessor_nb import TTbarResProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filesets_nb import filesets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are already 'unweighted' coffea output files available that you wish to use, either for demonstration, quickly getting to the step of importing lookup tables, testing/weighting these files, etc..., you can simply load them in from the directory **CoffeaOutputs/UnweightedOutputs/** (or wherever you decide to get the coffea outputs from).\n",
    "\n",
    "Change the following switch to `True` to load the premaid files.  Switch to `False` to use `processor.run_uproot_job` to generate new files. \n",
    "\n",
    "If making your own files, be sure to choose the name they are saved as in \n",
    "`util.save(output, 'Whatever_Name_You_Want.coffea')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoadingUnweightedFiles = False\n",
    "# -- include another switch for using dask here later... -- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "outputs_unweighted = {}\n",
    "\n",
    "seed = 1234577890\n",
    "prng = RandomState(seed)\n",
    "Chunk = [100000, 10] # [chunksize, maxchunks]\n",
    "\n",
    "for name,files in filesets.items(): \n",
    "    if not LoadingUnweightedFiles:        \n",
    "        print('Processing', name)\n",
    "        output = processor.run_uproot_job({name:files},\n",
    "                                          treename='Events',\n",
    "                                          processor_instance=TTbarResProcessor(UseLookUpTables=False,\n",
    "                                                                               ModMass=False, \n",
    "                                                                               RandomDebugMode=False,\n",
    "                                                                               prng=prng),\n",
    "                                          #executor=processor.dask_executor,\n",
    "                                          #executor=processor.iterative_executor,\n",
    "                                          executor=processor.futures_executor,\n",
    "                                          executor_args={\n",
    "                                              #'client': client,\n",
    "                                              'skipbadfiles':False,\n",
    "                                              'schema': BaseSchema, #NanoAODSchema,\n",
    "                                              'workers': 2},\n",
    "                                          chunksize=Chunk[0], maxchunks=Chunk[1]\n",
    "        \t\t\t\t)\n",
    "\n",
    "        elapsed = time.time() - tstart\n",
    "        outputs_unweighted[name] = output\n",
    "        print(output)\n",
    "        #util.save(output, 'CoffeaOutputs/UnweightedOutputs/TTbarResCoffea_' + name + '_unweighted_output_futures_3-24-21_btagSF_trial.coffea')\n",
    "\n",
    "    else:\n",
    "        output = util.load('CoffeaOutputs/UnweightedOutputs/TTbarResCoffea_' + name + '_unweighted_output_futures_3-10-21_trial.coffea')\n",
    "\n",
    "        outputs_unweighted[name] = output\n",
    "        print(name + ' unweighted output loaded')\n",
    "        elapsed = time.time() - tstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name,output in outputs_unweighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the `TTbarResLookUpTables` module by simply importing it.  If it works, it will print out varies pandas dataframes with information about the mistag rates and finally print the `luts` multi-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TTbarResLookUpTables_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import that multi-dictionary `luts`, as it is needed for the processor to create output files.  These new output files will have the necessary datasets weighted by their corresponding mistag rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OnlyCreateLookupTables = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTbarResLookUpTables_nb import luts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the necessary files have been included in the `TTbarResLookUpTables_nb` process before running the next processor, as the mistag procedure is found within that module.  For details about the categories used to write the mistag procedure, refer to the `TTbarResProcessor` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filesets_nb import filesets_forweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "seed = 1234577890\n",
    "outputs_weighted = {}\n",
    "prng = RandomState(seed)\n",
    "Chunk = [100000, 100] # [chunksize, maxchunks]\n",
    "\n",
    "for name,files in filesets_forweights.items(): \n",
    "    \n",
    "    if not OnlyCreateLookupTables:\n",
    "        print(name)\n",
    "        output = processor.run_uproot_job({name:files},\n",
    "                                          treename='Events',\n",
    "                                          processor_instance=TTbarResProcessor(UseLookUpTables=True,\n",
    "                                                                               ModMass = True,\n",
    "                                                                               RandomDebugMode = False,\n",
    "                                                                               CalcEff_MC=False,\n",
    "                                                                               lu=luts,\n",
    "                                                                               prng=prng),\n",
    "                                          #executor=processor.dask_executor,\n",
    "                                          #executor=processor.iterative_executor,\n",
    "                                          executor=processor.futures_executor,\n",
    "                                          executor_args={\n",
    "                                              'client': client, \n",
    "                                              'skipbadfiles':False,\n",
    "                                              'schema': BaseSchema, #NanoAODSchema,\n",
    "                                              'workers': 2},\n",
    "                                          chunksize=Chunk[0], maxchunks=Chunk[1]\n",
    "        )\n",
    "\t\n",
    "        elapsed = time.time() - tstart\n",
    "        outputs_weighted[name] = output\n",
    "        print(output)\n",
    "        util.save(output, 'CoffeaOutputs/WeightedModMassOutputs/TTbarResCoffea_' + name + '_ModMass_weighted_output_futures_3-24-21_btagSF_trial.coffea')\n",
    "\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not OnlyCreateLookupTables:\n",
    "    for name,output in outputs_weighted.items(): \n",
    "        print(\"-------Unweighted \" + name + \"--------\")\n",
    "        for i,j in output['cutflow'].items():        \n",
    "            print( '%20s : %12d' % (i,j) )\n",
    "else:\n",
    "    print('We\\'re done here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

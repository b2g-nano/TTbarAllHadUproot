{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffea` Notebook to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "This module must be run twice: \n",
    "   1. Make the mistag rate in the \"anti-tag and probe\" selection \n",
    "and the expectation in the signal region from MC,\n",
    "   1. Applies that mistag rate and the mod-mass procedure to the single-tag selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 1100$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrootdstr = 'root://cmsxrootd.fnal.gov//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdfilename = 'flatqcd.txt'\n",
    "with open(qcdfilename) as f:\n",
    "    qcdfiles = [xrootdstr + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbarfilename = 'TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8.txt'\n",
    "with open(ttbarfilename) as f:\n",
    "    ttbarfiles = [xrootdstr + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "client = Client('coffea-dask.fnal.gov:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, htCut=1100., minMSD=105., maxMSD=210., tau32Cut=0.7, ak8PtMin=400., bdisc=0.7,\n",
    "                writePredDist=True,isData=True,year=2019):\n",
    "        \n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        \n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        # Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "        self.anacats = [ b+y for b,y in itertools.product( self.btagcats, self.ycats) ]\n",
    "        self.anacats += ['pretag']\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        ht_axis = hist.Bin(\"h_ak4ht\", r\"AK4 Jet H_{T} [GeV]\", 50, 0, 5000)\n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 5000)\n",
    "        jetn3b1_axis = hist.Bin(\"n3b1\", r\"Jet N3\", 50, 0, 1)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "        \n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'h_ak4ht'  : hist.Hist(\"Counts\", dataset_axis, cats_axis, ht_axis),\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            'jetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        \n",
    "        #dataset = events.metadata['dataset']\n",
    "        dataset = df['dataset']\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            tau1=df['FatJet_tau1'],\n",
    "            tau2=df['FatJet_tau2'],\n",
    "            tau3=df['FatJet_tau3'],\n",
    "            tau4=df['FatJet_tau4'],\n",
    "            n3b1=df['FatJet_n3b1'],\n",
    "            btagDeepB=df['FatJet_btagDeepB']\n",
    "            )\n",
    "        \n",
    "        #weight = JaggedArray.fromcounts(\n",
    "        #    np.ones_like(df['Generator_binvar'],dtype=int),\n",
    "        #    df['Generator_weight']\n",
    "        #)\n",
    "        evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "\n",
    "        twoFatJets = (FatJets.counts >= 2)\n",
    "        FatJets = FatJets[twoFatJets]\n",
    "        output['cutflow']['two FatJets'] += twoFatJets.sum()\n",
    "        \n",
    "        jet_id = (FatJets.jetId > 0)\n",
    "        \n",
    "        #print(\"jet_id[:,0]\", jet_id[:,0])          \n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets.eta) < 2.5)\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += jetkincut_index.any().sum()\n",
    "        \n",
    "        evtweights = evtweights[twoFatJets]\n",
    "        ttbarcands = FatJets[:,0:2].distincts()\n",
    "\n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "\n",
    "        \n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut]\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='pretag', \n",
    "                            ttbarmass=ttbarcands.p4.sum().mass.flatten(),\n",
    "                            weight=evtweights.flatten())\n",
    "        \n",
    "        # Now get the analysis categories. \n",
    "        # They are (central, forward)   cross   (0b,1b,>=2b)\n",
    "        cen = abs(ttbarcands.i0.p4.y - ttbarcands.i1.p4.y) < 1.0\n",
    "        fwd = np.logical_not(cen)\n",
    "        \n",
    "        btag_i0 = (ttbarcands.i0.btagDeepB > 0.7)\n",
    "        btag_i1 = (ttbarcands.i1.btagDeepB > 0.7)\n",
    "        \n",
    "        btag0 = np.logical_not(btag_i0) & np.logical_not(btag_i1)\n",
    "        btag1 = btag_i0 ^ btag_i1\n",
    "        btag2 = btag_i0 & btag_i1\n",
    "        \n",
    "        cat0 = (cen & btag0).flatten()\n",
    "        cat1 = (fwd & btag0).flatten()\n",
    "        cat2 = (cen & btag1).flatten()\n",
    "        cat3 = (fwd & btag1).flatten()\n",
    "        cat4 = (cen & btag2).flatten()\n",
    "        cat5 = (fwd & btag2).flatten()\n",
    "        \n",
    "        output['cutflow']['0bcen'] += cat0.sum()\n",
    "        output['cutflow']['0bfwd'] += cat1.sum()\n",
    "        output['cutflow']['1bcen'] += cat2.sum()\n",
    "        output['cutflow']['1bfwd'] += cat3.sum()\n",
    "        output['cutflow']['2bcen'] += cat4.sum()\n",
    "        output['cutflow']['2bfwd'] += cat5.sum()\n",
    "        \n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()    \n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='0bcen', \n",
    "                            ttbarmass=ttbarmass[cat0],\n",
    "                            weight=evtweights[cat0].flatten())\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='0bfwd', \n",
    "                            ttbarmass=ttbarmass[cat1],\n",
    "                            weight=evtweights[cat1].flatten())\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='1bcen', \n",
    "                            ttbarmass=ttbarmass[cat2],\n",
    "                            weight=evtweights[cat2].flatten())\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='1bfwd', \n",
    "                            ttbarmass=ttbarmass[cat3],\n",
    "                            weight=evtweights[cat3].flatten())\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='2bcen', \n",
    "                            ttbarmass=ttbarmass[cat4],\n",
    "                            weight=evtweights[cat4].flatten())\n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='2bfwd', \n",
    "                            ttbarmass=ttbarmass[cat5],\n",
    "                            weight=evtweights[cat5].flatten())\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd', 'pretag']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3d643df8794a4a8f8ecb7b2fbf4a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing', max=128.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0819934ca0274eefac49b6d1ac79796b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing', max=2854.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "fileset = {\n",
    "    'TTbar':ttbarfiles\n",
    "    #'QCD':qcdfiles # QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8\n",
    "    #'ZZ to 4mu': [\n",
    "    #    'data/ZZTo4mu.root'\n",
    "    #]\n",
    "}\n",
    "\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTbarResProcessor(),\n",
    "                                  #executor=processor.dask_executor,\n",
    "                                  executor=processor.iterative_executor,\n",
    "                                  executor_args={'client': client, 'nano':False, 'flatten':True, 'workers': 4},\n",
    "                                  chunksize=50000\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fill_opts = {'alpha': 0.8, 'edgecolor':(0,0,0,.5)}\n",
    "stack_error_opts = {'label':'Stat. Unc.', 'hatch':'///', 'facecolor':'none', 'edgecolor':(0,0,0,.5), 'linewidth': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = hist.plotgrid(output['ttbarmass'], row=\"anacat\", overlay=\"dataset\", stack=True,\n",
    "                                  #fill_opts=stack_fill_opts,\n",
    "                                  #error_opts=stack_error_opts,\n",
    "                                 )\n",
    "plt.yscale(\"log\")\n",
    "for iax in ax.flatten():\n",
    "    iax.autoscale(axis='y')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events/s:\", output['cutflow']['all events']/elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in output['cutflow'].items():\n",
    "    print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mapping = {\n",
    "#    'QCD': ['QCD'],\n",
    "#}\n",
    "#output['ttbarmass'].group(\"dataset\", hist.Cat(\"dataset\", \"dataset\"), mapping)\n",
    "#hist_noDS = output['ttbarmass_pretag'].integrate('dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

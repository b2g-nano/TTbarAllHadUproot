{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffea` Notebook to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "This module must be run twice: \n",
    "   1. Make the mistag rate in the \"anti-tag and probe\" selection \n",
    "and the expectation in the signal region from MC,\n",
    "   1. Applies that mistag rate and the mod-mass procedure to the single-tag selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 1100$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea import util\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrootdstr1 = 'root://cmseos.fnal.gov//'\n",
    "xrootdstr2 = 'root://cmsxrootd.fnal.gov//'\n",
    "xrootdstr3 = 'root://cmsxrootd-site.fnal.gov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdfilename = 'QCD.txt'\n",
    "with open(qcdfilename) as f:\n",
    "    qcdfiles = [xrootdstr2 + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbarfilename = 'TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8.txt'\n",
    "with open(ttbarfilename) as f:\n",
    "    ttbarfiles = [xrootdstr1 + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetdatafilename = 'JetHT_Data.txt'\n",
    "with open(jetdatafilename) as f:\n",
    "    jetdatafiles = [xrootdstr2 + s.strip() for s in f.readlines() if \"/store/data/Run2017\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "client = Client('coffea-dask.fnal.gov:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, htCut=1100., minMSD=105., maxMSD=210., tau32Cut=0.7, ak8PtMin=400., bdisc=0.7,\n",
    "                writePredDist=True,isData=True,year=2019, UseLookUpTables=False,\n",
    "                lu = None):\n",
    "        \n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        self.UseLookUpTables = UseLookUpTables\n",
    "        self.lu = lu\n",
    "        \n",
    "        self.ttagcats = [\"at\", \"0t\", \"1t\", \"2t\"] #anti-tag, 0, 1, >=2 ttags\n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        # Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "        self.anacats = [ t+b+y for t,b,y in itertools.product( self.ttagcats, self.btagcats, self.ycats) ]\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 2000)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "        jeteta_axis = hist.Bin(\"jeteta\", r\"Jet $\\eta$\", 50, -4, 4)\n",
    "        jetphi_axis = hist.Bin(\"jetphi\", r\"Jet $\\phi$\", 50, -3.14, 3.14)\n",
    "        jety_axis = hist.Bin(\"jety\", r\"Jet $y$\", 50, -3, 3)\n",
    "        jetdy_axis = hist.Bin(\"jetdy\", r\"Jet $\\Delta y$\", 50, 0, 3)\n",
    "        jetp_axis = hist.Bin(\"jetp\", r\"Jet $p$ [GeV]\", 50, 0, 5000)\n",
    "        \n",
    "        subjetmass_axis = hist.Bin(\"subjetmass\", r\"SubJet $m$ [GeV]\", 50, 0, 500)\n",
    "        subjetpt_axis = hist.Bin(\"subjetpt\", r\"SubJet $p_{T}$ [GeV]\", 50, 0, 2000)\n",
    "        subjeteta_axis = hist.Bin(\"subjeteta\", r\"SubJet $\\eta$\", 50, -4, 4)\n",
    "        subjetphi_axis = hist.Bin(\"subjetphi\", r\"SubJet $\\phi$\", 50, -3.14, 3.14)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            'jetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'jeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jeteta_axis),\n",
    "            'jetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, jetphi_axis),\n",
    "            'jety':      hist.Hist(\"Counts\", dataset_axis, cats_axis, jety_axis),\n",
    "            'jetdy':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetdy_axis),\n",
    "            \n",
    "            'subjetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetmass_axis),\n",
    "            'subjetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetpt_axis),\n",
    "            'subjeteta':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjeteta_axis),\n",
    "            'subjetphi':    hist.Hist(\"Counts\", dataset_axis, cats_axis, subjetphi_axis),\n",
    "            \n",
    "            'numerator': hist.Hist(\"Counts\", dataset_axis, cats_axis, jetp_axis),\n",
    "            'denominator': hist.Hist(\"Counts\", dataset_axis, cats_axis, jetp_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "            \n",
    "        })\n",
    "\n",
    "            \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        #dataset = events.metadata['dataset']\n",
    "        dataset = df['dataset']\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            tau1=df['FatJet_tau1'],\n",
    "            tau2=df['FatJet_tau2'],\n",
    "            tau3=df['FatJet_tau3'],\n",
    "            tau4=df['FatJet_tau4'],\n",
    "            n3b1=df['FatJet_n3b1'],\n",
    "            btagDeepB=df['FatJet_btagDeepB'],\n",
    "            deepTag_TvsQCD=df['FatJet_deepTag_TvsQCD'],\n",
    "            deepTagMD_TvsQCD=df['FatJet_deepTagMD_TvsQCD']\n",
    "            )\n",
    "        # ---- Define Jets ---- #\n",
    "        Jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nSubJet'],\n",
    "            pt=df['Jet_pt'],\n",
    "            eta=df['Jet_eta'],\n",
    "            phi=df['Jet_phi'],\n",
    "            mass=df['Jet_mass']\n",
    "            )\n",
    "        \n",
    "        # ---- Get event weights from dataset ---- #\n",
    "        if 'JetHT' in dataset: # If data is used...\n",
    "            evtweights = np.ones(FatJets.size) # set all \"data weights\" to one\n",
    "        else: # if Monte Carlo dataset is used...\n",
    "            evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        \n",
    "        # ---- Show all events ---- #\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "        \n",
    "        # ---- Show all events according to which dataset it used ---- #\n",
    "        if 'TTbar' in dataset:\n",
    "            output['cutflow']['all ttbar events'] += FatJets.size\n",
    "            output['cutflow']['number of ttbar sets'] += 1\n",
    "        elif 'QCD' in dataset:\n",
    "            output['cutflow']['all qcd events'] += FatJets.size\n",
    "            output['cutflow']['number of qcd sets'] += 1\n",
    "        elif 'JetHT' in dataset:\n",
    "            output['cutflow']['all JetHT events'] += FatJets.size\n",
    "            output['cutflow']['number of JetHT sets'] += 1\n",
    "        else:\n",
    "            print('\\ndataset not found\\n')\n",
    "        \n",
    "        # ---- Apply HT Cut ---- #\n",
    "        hT = Jets.pt.sum()\n",
    "        passhT = (hT > self.htCut)\n",
    "        evtweights = evtweights[passhT]\n",
    "        FatJets = FatJets[passhT]\n",
    "        \n",
    "        # ---- FatJets Info ---- #\n",
    "        oneFatJet = (FatJets.counts >= 1) # at least one fat jet\n",
    "        FatJets = FatJets[oneFatJet]\n",
    "        evtweights = evtweights[oneFatJet]\n",
    "        output['cutflow']['one FatJets'] += oneFatJet.sum()\n",
    "        \n",
    "        twoFatJets = (FatJets.counts >= 2)\n",
    "        FatJets = FatJets[twoFatJets]\n",
    "        evtweights = evtweights[twoFatJets]\n",
    "        output['cutflow']['two FatJets'] += twoFatJets.sum()\n",
    "\n",
    "        jet_id = (FatJets.jetId > 0)\n",
    "        \n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets.eta) < 2.5) # eta cut here\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += jetkincut_index.any().sum()\n",
    "\n",
    "        twoFatJetsKin = (FatJets.counts >= 2) # Whats the difference from twoFatJets ?\n",
    "        FatJets = FatJets[twoFatJetsKin]\n",
    "        evtweights = evtweights[twoFatJetsKin]\n",
    "        output['cutflow']['two FatJets and jet kin'] += twoFatJetsKin.sum()\n",
    "        \n",
    "        # ---- Randomly Select AK8 Jet as TTbar Candidate --- #\n",
    "        index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), np.random.randint(2, size=len(FatJets)))\n",
    "        jet0 = FatJets[index]\n",
    "        jet1 = FatJets[1 - index]\n",
    "        \n",
    "        ttbarcands = jet0.cross(jet1) #FatJets[:,0:2].distincts()\n",
    "        \n",
    "        # ---- Look for more than one TTbar candidate and re-broadcast releveant arrays  ---- #\n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "         \n",
    "        # ---- Apply Delta Phi Cut ---- #\n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut] \n",
    "        \n",
    "        \n",
    "        # ---- Get Analysis Categories ---- # \n",
    "        # ---- They are (central, forward)   cross   (0b,1b,>=2b) ---- #\n",
    "        cen = np.abs(ttbarcands.i0.p4.rapidity - ttbarcands.i1.p4.rapidity) < 1.0\n",
    "        fwd = (~cen)\n",
    "        tau32_i0 = np.where(ttbarcands.i0.tau2>0,ttbarcands.i0.tau3/ttbarcands.i0.tau2, 0 )\n",
    "        tau32_i1 = np.where(ttbarcands.i1.tau2>0,ttbarcands.i1.tau3/ttbarcands.i1.tau2, 0 )\n",
    "        taucut_i0 = tau32_i0 < self.tau32Cut\n",
    "        taucut_i1 = tau32_i1 < self.tau32Cut\n",
    "        mcut_i0 = (self.minMSD < ttbarcands.i0.msoftdrop) & (ttbarcands.i0.msoftdrop < self.maxMSD) \n",
    "        mcut_i1 = (self.minMSD < ttbarcands.i1.msoftdrop) & (ttbarcands.i1.msoftdrop < self.maxMSD) \n",
    "\n",
    "        ttag_i0 = (taucut_i0) & (mcut_i0)\n",
    "        ttag_i1 = (taucut_i1) & (mcut_i1)\n",
    "        antitag = (~taucut_i0) & (mcut_i0) #Probe will always be ttbarcands.i1\n",
    "        ttag0 = (~ttag_i0) & (~ttag_i1)\n",
    "        ttag1 = ttag_i0 ^ ttag_i1\n",
    "        ttag2 = ttag_i0 & ttag_i1\n",
    "\n",
    "        btag_i0 = (ttbarcands.i0.btagDeepB > self.bdisc)\n",
    "        btag_i1 = (ttbarcands.i1.btagDeepB > self.bdisc)\n",
    "        \n",
    "        btag0 = (~btag_i0) & (~btag_i1)\n",
    "        btag1 = btag_i0 ^ btag_i1\n",
    "        btag2 = btag_i0 & btag_i1\n",
    "        \n",
    "        antitag_probe = np.logical_and(antitag, ttag_i1) #Found an antitag and ttagged probe pair for mistag rate\n",
    "      \n",
    "        regs = [cen,fwd]\n",
    "        btags = [btag0,btag1,btag2]\n",
    "        ttags = [antitag,ttag0,ttag1,ttag2]\n",
    "        cats = [ (t&b&y).flatten() for t,b,y in itertools.product( ttags, btags, regs) ]\n",
    "        \n",
    "        labels_and_categories = dict(zip( self.anacats, cats ))\n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()\n",
    "        jetpt = ttbarcands.pt.flatten()\n",
    "        #print('Jet pt = ', jetpt)\n",
    "        jeteta = ttbarcands.eta.flatten()\n",
    "        jetphi = ttbarcands.phi.flatten()\n",
    "        jety = ttbarcands.p4.rapidity.flatten()\n",
    "        jetdy = np.abs(ttbarcands.i0.p4.rapidity.flatten() - ttbarcands.i1.p4.rapidity.flatten())\n",
    "        \n",
    "        weights = evtweights.flatten()\n",
    "        #weights[weights < 0] = 0\n",
    "        \n",
    "        # ---- Define the SumW2 for MC Datasets ---- #\n",
    "        if 'TTbar' in dataset:\n",
    "            output['cutflow']['ttbar sumw'] += np.sum(weights)\n",
    "            output['cutflow']['ttbar sumw2'] += np.sum(weights**2)\n",
    "        if 'QCD' in dataset:\n",
    "            output['cutflow']['qcd sumw'] += np.sum(weights)\n",
    "            output['cutflow']['qcd sumw2'] += np.sum(weights**2)\n",
    "        \n",
    "        # ---- Define Momentum p of probe jet as the Mistag Rate variable; M(p) ---- #\n",
    "        # ---- Transverse Momentum pT can also be used instead; M(pT) ---- #\n",
    "        pT = ttbarcands.i1.pt.flatten()\n",
    "        eta = ttbarcands.i1.eta.flatten()\n",
    "        pz = np.sinh(eta)*pT\n",
    "        p = np.absolute(np.sqrt(pT**2 + pz**2))\n",
    "        \n",
    "        # ---- Define the Numerator and Denominator for Mistag Rate ---- #\n",
    "        numerator = np.where(antitag_probe, p, -9999) # If no antitag and tagged probe, move event to useless bin\n",
    "        denominator = np.where(antitag, p, -9999) # If no antitag, move event to useless bin\n",
    "        \n",
    "        df = pd.DataFrame({\"momentum\":p}) # Used for finding values in LookUp Tables\n",
    "        \n",
    "        for ilabel,icat in labels_and_categories.items():\n",
    "            ### ------------------------------------ Mistag Scaling ------------------------------------ ###\n",
    "            if self.UseLookUpTables == True:\n",
    "                filename = self.lu + '_at' + str(ilabel[2:]) + '.csv' # get mistag/lookup filename\n",
    "                file_df = pd.read_csv(filename) # read in values from lookup table\n",
    "                bin_widths = file_df['p'].values # collect bins as written in .csv file\n",
    "                mtr = file_df['M(p)'].values # collect mistag rate as function of p as written in file\n",
    "                wgts = 1.0 - mtr # Define weights based on mistag rates\n",
    "                \n",
    "                BinKey = np.arange(bin_widths.size) # Use as label for BinNumber column in the new dataframe\n",
    "                Bins = np.arange(bin_widths.size+1)*100. # Temporary definition of bins as floats\n",
    "                P = np.where(p>5000., 5000., p) # Avoids momentum larger than the allowed bin size; caps the momentum\n",
    "                df['BinWidth'] = pd.cut(P, bins=Bins) # new dataframe column\n",
    "                df['BinNumber'] = pd.cut(P, bins=Bins, labels=BinKey) # new dataframe column\n",
    "                \n",
    "                BinNumber = df['BinNumber'].values # Collect the Bin Numbers into a numpy array\n",
    "                BinNumber = BinNumber.astype('int64') # Insures the bin numbers are integers\n",
    "            \n",
    "                WeightMatching = wgts[BinNumber] # Match 'wgts' with corresponding p bin using the bin number\n",
    "                Weights = weights*WeightMatching # Include 'wgts' with the previously defined 'weights'\n",
    "            else:\n",
    "                Weights = weights # No mistag rates, no change to weights\n",
    "            ###---------------------------------------------------------------------------------------------###\n",
    "            output['cutflow'][ilabel] += np.sum(icat)\n",
    "          \n",
    "            output['ttbarmass'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                ttbarmass=ttbarmass[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetpt'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetpt=jetpt[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jeteta'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jeteta=jeteta[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetphi'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetphi=jetphi[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jety'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jety=jety[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['jetdy'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetdy=jetdy[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['numerator'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetp=numerator[icat],\n",
    "                                weight=Weights[icat])\n",
    "            output['denominator'].fill(dataset=dataset, anacat=ilabel, \n",
    "                                jetp=denominator[icat],\n",
    "                                weight=Weights[icat])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "filesets = {\n",
    "    'QCD':qcdfiles,\n",
    "    'TTbar':ttbarfiles,\n",
    "    'JetHT':jetdatafiles\n",
    "}\n",
    "\n",
    "outputs_unweighted = {}\n",
    "\n",
    "for name,files in filesets.items(): \n",
    "\n",
    "    print(name)\n",
    "    output = processor.run_uproot_job({name:files},\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=TTbarResProcessor(UseLookUpTables=False),\n",
    "                                      #executor=processor.dask_executor,\n",
    "                                      #executor=processor.iterative_executor,\n",
    "                                      executor=processor.futures_executor,\n",
    "                                      executor_args={\n",
    "                                          'client': client, \n",
    "                                          'nano':False, \n",
    "                                          'flatten':True, \n",
    "                                          'skipbadfiles':True,\n",
    "                                          'workers': 7}\n",
    "                                      #chunksize=50000, maxchunks=50\n",
    "                                     )\n",
    "\n",
    "    elapsed = time.time() - tstart\n",
    "    outputs_unweighted[name] = output\n",
    "    print(output)\n",
    "    print(elapsed)\n",
    "    util.save(output, 'TTbarResCoffea_' + name + '_unweighted_output.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,output in outputs_unweighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(mypath):\n",
    "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
    "\n",
    "    from errno import EEXIST\n",
    "    from os import makedirs,path\n",
    "\n",
    "    try:\n",
    "        makedirs(mypath)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == EEXIST and path.isdir(mypath):\n",
    "            pass\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoesDirectoryExist(mypath): #extra precaution (Probably overkill...)\n",
    "    '''Checks to see if Directory exists before running mkdir_p'''\n",
    "    import os.path\n",
    "    from os import path\n",
    "    \n",
    "    if path.exists(mypath):\n",
    "        pass\n",
    "    else:\n",
    "        mkdir_p(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re # regular expressions\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- Reiterate categories ---- #\n",
    "ttagcats = [\"at\", \"0t\", \"1t\", \"2t\"]\n",
    "btagcats = [\"0b\", \"1b\", \"2b\"]\n",
    "ycats = ['cen', 'fwd']\n",
    "\n",
    "list_of_cats = [ t+b+y for t,b,y in itertools.product( ttagcats, btagcats, ycats) ]\n",
    "\n",
    "# ---- List the Histograms Here ---- #\n",
    "list_of_hists = ('ttbarmass', 'jetpt', 'jeteta', 'jetphi',\n",
    "                 'numerator', 'denominator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindirectory = os.getcwd() # change accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" ---------------- CREATES MISTAG PLOTS ---------------- \"\"\"\n",
    "# ---- Only Use This Cell When LookUp Tables Are Not In Use (i.e. UseLookUpTables = False) ---- #\n",
    "\n",
    "SaveDirectory = maindirectory + '/MistagPlots/'\n",
    "DoesDirectoryExist(SaveDirectory) # no need to create the directory several times\n",
    "print(SaveDirectory)\n",
    "for iset in filesets:\n",
    "    for icat in list_of_cats:\n",
    "        print(iset)\n",
    "        print(icat)\n",
    "        title = iset + ' mistag ' + icat\n",
    "        filename = 'mistag_' + iset + '_' + icat + '.' + 'png'\n",
    "        print(outputs_unweighted[iset]['numerator'])\n",
    "        Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat', icat).integrate('dataset', iset)\n",
    "        Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat', icat).integrate('dataset', iset)\n",
    "        print(Numerator)\n",
    "        print(Denominator)\n",
    "        mistag = hist.plotratio(num = Numerator, denom = Denominator,\n",
    "                                error_opts={'marker': '.', 'markersize': 10., 'color': 'k', 'elinewidth': 1},\n",
    "                                unc = 'num')\n",
    "        plt.title(title)\n",
    "        plt.ylim(bottom = 0, top = 1.0)\n",
    "        plt.savefig(SaveDirectory+filename, bbox_inches=\"tight\")\n",
    "        print(filename + ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ---------------- LOOK UP TABLE ---------------- \"\"\"\n",
    "# ---- Only Use This Cell When LookUp Tables Are Not In Use (i.e. UseLookUpTables = False) ---- #\n",
    "\n",
    "SaveDirectory = maindirectory + '/LookupTables/'\n",
    "DoesDirectoryExist(SaveDirectory)\n",
    "for iset in filesets:\n",
    "    print('\\t\\tfileset: ' + iset + '\\n*****************************************************\\n')\n",
    "    for icat in list_of_cats:\n",
    "        title = iset + ' mistag ' + icat\n",
    "        filename = 'mistag_' + iset + '_' + icat + '.' + 'csv'\n",
    "        \n",
    "        Numerator = outputs_unweighted[iset]['numerator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "        Denominator = outputs_unweighted[iset]['denominator'].integrate('anacat',icat).integrate('dataset',iset)\n",
    "        \n",
    "        N_vals = Numerator.values()[()]\n",
    "        D_vals = Denominator.values()[()]\n",
    "    \n",
    "        mistag_vals = np.where(D_vals > 0, N_vals / D_vals, 0)\n",
    "        \n",
    "        p_vals = [] # Momentum values\n",
    "        for iden in Numerator.identifiers('jetp'):\n",
    "            p_vals.append(iden)\n",
    "        \n",
    "        print('fileset:  ' + iset)\n",
    "        print('category: ' + icat)\n",
    "        print('________________________________________________\\n')\n",
    "\n",
    "        d = {'p': p_vals, 'M(p)': mistag_vals}\n",
    "        \n",
    "        df = pd.DataFrame(data=d)\n",
    "        \n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "            print(df)\n",
    "        print('\\n')\n",
    "        \n",
    "        df.to_csv(SaveDirectory+filename) # use later to collect bins and weights for re-scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events/s:\", output['cutflow']['all events']/elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "fileset = {\n",
    "    'JetHT':jetdatafiles\n",
    "}\n",
    "\n",
    "outputs_weighted = {}\n",
    "\n",
    "lut = SaveDirectory + 'mistag_JetHT'\n",
    "\n",
    "output_weighted = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTbarResProcessor(UseLookUpTables=True, lu=lut),\n",
    "                                  #executor=processor.dask_executor,\n",
    "                                  #executor=processor.iterative_executor,\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={\n",
    "                                      'client': client, \n",
    "                                      'nano':False, \n",
    "                                      'flatten':True, \n",
    "                                      'skipbadfiles':False,\n",
    "                                      'workers': 7},\n",
    "                                  #chunksize=50000, maxchunks=50\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "outputs_weighted['JetHT'] = output_weighted\n",
    "print(output_weighted)\n",
    "print(elapsed)\n",
    "util.save(output, 'TTbarResCoffea_weighted_JetHT_output.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,output in outputs_weighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49d5c05",
   "metadata": {},
   "source": [
    "## 1) script to scale all histograms in coffea files\n",
    "- saved in outputs/scale/\n",
    "- also scales the cutflow dictionary\n",
    "## 2) adds the scaled files from multiple years.\n",
    "- the histograms in the files must all have the same axes\n",
    "## 3) makes root files for 2DAlphabet\n",
    "- inclusive or split into regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "from coffea import util\n",
    "import itertools\n",
    "import os, sys\n",
    "import glob\n",
    "import copy\n",
    "import uproot\n",
    "\n",
    "sys.path.append('../python/')\n",
    "import functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.makeSaveDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad61b6",
   "metadata": {},
   "source": [
    "### analysis categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2293a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = functions.getLabelMap()\n",
    "label_to_int = {label: i for i, label in label_map.items()}\n",
    "signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "pretag_cats = [ i for label, i in label_to_int.items() if 'pre' in label]\n",
    "antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "\n",
    "\n",
    "\n",
    "print('------ analysis category map --------')\n",
    "for i, lab in label_map.items():\n",
    "    print(f'{i}: {lab}')\n",
    "print('-------------------------------------')\n",
    "\n",
    "\n",
    "print('\\n\\n------ coffea file content --------')\n",
    "\n",
    "for hname in functions.loadCoffeaFile().keys():\n",
    "    print(hname)\n",
    "print('-------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b9816",
   "metadata": {},
   "source": [
    "## 1) Scale histograms in IOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e95aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coffeafiles = functions.getCoffeaFilenames()\n",
    "\n",
    "datasets = ['QCD', 'TTbar', 'JetHT', 'RSGluon']\n",
    "datasets = ['JetHT']\n",
    "\n",
    "hasBkgEst = True\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "filetype = 'weighted' if hasBkgEst else 'unweighted'\n",
    "\n",
    "IOV = '2016'\n",
    "for ds in datasets:\n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "\n",
    "        coffeafiles[ds][filetype][IOV].keys()\n",
    "        sections = coffeafiles[ds][filetype][IOV].keys()\n",
    "\n",
    "        files = []\n",
    "\n",
    "\n",
    "        for s in sections:\n",
    "\n",
    "            filename = coffeafiles[ds][filetype][IOV][s]\n",
    "            original_file = util.load(filename)\n",
    "\n",
    "            file = copy.deepcopy(original_file)\n",
    "\n",
    "            if 'JetHT' in ds:\n",
    "\n",
    "                files.append(file)\n",
    "\n",
    "            else:\n",
    "\n",
    "                factor = toptag_sf**2 if 'TTbar' in ds else 1.0\n",
    "                sf = functions.lumi[IOV] * functions.xs[ds][s] * factor / file['cutflow']['sumw']\n",
    "\n",
    "                for key in file.keys():\n",
    "\n",
    "                    if 'hist' in str(type(file[key])):\n",
    "                        file[key] = file[key] * sf\n",
    "\n",
    "                    elif 'cutflow' in key:\n",
    "                        for cut in file[key].keys():\n",
    "                            file[key][cut] = file[key][cut] * sf\n",
    "\n",
    "\n",
    "\n",
    "                files.append(file)\n",
    "\n",
    "                if 'RSGluon' in ds or 'ZPrime' in ds:\n",
    "\n",
    "                    util.save(file, f'../outputs/scale/{ds}{s}_{IOV}.coffea')\n",
    "                    print(f'saving ../outputs/scale/{ds}{s}_{IOV}.coffea')\n",
    "\n",
    "\n",
    "        if 'RSGluon' not in ds and 'ZPrime' not in ds:\n",
    "\n",
    "            file = files[0]\n",
    "\n",
    "            for f in files[1:]:\n",
    "                for key in file.keys():\n",
    "\n",
    "                    if 'hist' in str(type(file[key])):\n",
    "                        file[key] = file[key] + f[key]\n",
    "\n",
    "                    elif 'cutflow' in key:\n",
    "                        for cut in f[key].keys():\n",
    "                            f[key][cut] = f[key][cut] + file[key][cut]\n",
    "\n",
    "            savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "            util.save(file, savefilename)\n",
    "            print(f'saving {savefilename}')\n",
    "\n",
    "    except:\n",
    "\n",
    "        filename = coffeafiles[ds][filetype][IOV]\n",
    "        original_file = util.load(filename)\n",
    "        file = copy.deepcopy(original_file)\n",
    "\n",
    "\n",
    "        sf = functions.lumi[IOV] * functions.xs[ds] / file['cutflow']['sumw']\n",
    "\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "                file[key] = file[key] * sf\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "\n",
    "                for cut in file[key].keys():\n",
    "\n",
    "                    file[key][cut] = file[key][cut] * sf\n",
    "\n",
    "        savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "        util.save(file, savefilename)\n",
    "        print(f'saving {savefilename}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498ead3",
   "metadata": {},
   "source": [
    "## 2.1) Combine JetHT files (blinded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOVs = ['2016APV', '2016']#, '2017', '2018']\n",
    "\n",
    "\n",
    "hasBkgEst = True\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "files = []\n",
    "for IOV in IOVs:\n",
    "\n",
    "    file = util.load(f'../outputs/scale/JetHT_{IOV}{bkgest_str}.coffea')\n",
    "    files.append(file)\n",
    "    \n",
    "systs = 'nominal'#, 'pileupDown', 'pileupUp', 'prefiringDown', 'prefiringUp', 'pdfDown', 'pdfUp', 'btagDown', 'btagUp', 'jesDown', 'jesUp', 'jerDown', 'jerUp']\n",
    "file = files[0]\n",
    "for f in files[1:]:\n",
    "    for key in file.keys():\n",
    "\n",
    "        if 'hist' in str(type(file[key])):\n",
    "            \n",
    "            file[key] = file[key] + f[key]            \n",
    "\n",
    "        elif 'cutflow' in key:\n",
    "            for cut in f[key].keys():\n",
    "                f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "# savefilename = f'../outputs/scale/JetHT_blinded.coffea'\n",
    "\n",
    "if hasBkgEst:\n",
    "    savefilename = f'../outputs/scale/NTMJ_2016all_unblinded.coffea'\n",
    "    \n",
    "else:\n",
    "    savefilename = f'../outputs/scale/JetHT_2016all_unblinded.coffea'\n",
    "\n",
    "\n",
    "util.save(file, savefilename)\n",
    "print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492b8f7",
   "metadata": {},
   "source": [
    "## 2.2) Combine MC files (for plotting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOVs = ['2016APV', '2016', '2017', '2018']\n",
    "datasets = ['QCD', 'TTbar', 'RSGluon']\n",
    "\n",
    "files = []\n",
    "\n",
    "\n",
    "# all all RSGluon samples\n",
    "datasets += ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "for ds in datasets:\n",
    "\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_all.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7b5e8",
   "metadata": {},
   "source": [
    "## 2.3) Combine 2016noAPV and 2016APV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158f64b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IOVs = ['2016', '2016APV']\n",
    "datasets = ['JetHT']#, 'TTbar']\n",
    "\n",
    "\n",
    "hasBkgEst = True\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "\n",
    "# add all RSGluon samples\n",
    "datasets += ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "for ds in datasets:\n",
    "    \n",
    "    files = []\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "\n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_2016all{bkgest_str}.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027a0d8",
   "metadata": {},
   "source": [
    "## 3) Make root files for 2DAlphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag', 'prefiring']\n",
    "syst_labels = ['nominal']\n",
    "for s in systematics:\n",
    "    if not 'nominal' in s:\n",
    "        syst_labels.append(s+'Down')\n",
    "        syst_labels.append(s+'Up')\n",
    "        \n",
    "print(syst_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840945aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016all'\n",
    "\n",
    "dataOnly = False\n",
    "inclusive = True\n",
    "\n",
    "if inclusive:\n",
    "    \n",
    "    cats, cat_labels = [''], ['']\n",
    "    \n",
    "else:\n",
    "\n",
    "    cats = ['0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd']\n",
    "    cat_labels = ['cen0b', 'fwd0b', 'cen1b', 'fwd1b', 'cen2b', 'fwd2b']\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "savefileheader = '../outputs/twodalphabet/TTbarAllHad{}_'.format(year.replace('20', ''))\n",
    "                                                                \n",
    "fdata  = uproot.recreate(savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    fttbar = uproot.recreate(savefileheader+'TTbar.root')\n",
    "    f1000  = uproot.recreate(savefileheader+'signalRSGluon1000.root')\n",
    "    f1500  = uproot.recreate(savefileheader+'signalRSGluon1500.root')\n",
    "    f2000  = uproot.recreate(savefileheader+'signalRSGluon2000.root')\n",
    "    f2500  = uproot.recreate(savefileheader+'signalRSGluon2500.root')\n",
    "    f3000  = uproot.recreate(savefileheader+'signalRSGluon3000.root')\n",
    "    f3500  = uproot.recreate(savefileheader+'signalRSGluon3500.root')\n",
    "    f4000  = uproot.recreate(savefileheader+'signalRSGluon4000.root')\n",
    "    f4500  = uproot.recreate(savefileheader+'signalRSGluon4500.root')\n",
    "    f5000  = uproot.recreate(savefileheader+'signalRSGluon5000.root')\n",
    "\n",
    "\n",
    "for cat, catname in zip(cats, cat_labels):\n",
    "    \n",
    "    if inclusive:\n",
    "        \n",
    "        signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "        antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "        sum_axes = ['anacat']\n",
    "\n",
    "    else :\n",
    "        \n",
    "        signal_cats = label_to_int['2t'+cat]\n",
    "        antitag_cats = label_to_int['at'+cat]\n",
    "        sum_axes = []\n",
    "    \n",
    "    for syst in syst_labels:\n",
    "        print(syst, cat)\n",
    "\n",
    "        integrate_pass = {'anacat':signal_cats, 'systematic': syst}\n",
    "        integrate_fail = {'anacat':antitag_cats, 'systematic': syst}\n",
    "\n",
    "        systname = syst.upper()[:-2] + 'up' if 'Up' in syst else syst.upper()[:-4] + 'down'\n",
    "\n",
    "        if 'nominal' in syst:\n",
    "\n",
    "            systname = ''\n",
    "            hdata_pass = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hdata_fail = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            fdata[\"MttvsMt\"+catname+\"Pass\"+systname] = hdata_pass\n",
    "            fdata[\"MttvsMt\"+catname+\"Fail\"+systname] = hdata_fail\n",
    "\n",
    "        if not dataOnly:\n",
    "\n",
    "            hRSGluon1000_pass = functions.getHist2('mtt_vs_mt', 'RSGluon1000', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon1500_pass = functions.getHist2('mtt_vs_mt', 'RSGluon1500', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon2000_pass = functions.getHist2('mtt_vs_mt', 'RSGluon2000', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon2500_pass = functions.getHist2('mtt_vs_mt', 'RSGluon2500', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon3000_pass = functions.getHist2('mtt_vs_mt', 'RSGluon3000', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon3500_pass = functions.getHist2('mtt_vs_mt', 'RSGluon3500', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon4000_pass = functions.getHist2('mtt_vs_mt', 'RSGluon4000', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon4500_pass = functions.getHist2('mtt_vs_mt', 'RSGluon4500', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            hRSGluon5000_pass = functions.getHist2('mtt_vs_mt', 'RSGluon5000', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "\n",
    "            hRSGluon1000_fail = functions.getHist2('mtt_vs_mt', 'RSGluon1000', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon1500_fail = functions.getHist2('mtt_vs_mt', 'RSGluon1500', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon2000_fail = functions.getHist2('mtt_vs_mt', 'RSGluon2000', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon2500_fail = functions.getHist2('mtt_vs_mt', 'RSGluon2500', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon3000_fail = functions.getHist2('mtt_vs_mt', 'RSGluon3000', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon3500_fail = functions.getHist2('mtt_vs_mt', 'RSGluon3500', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon4000_fail = functions.getHist2('mtt_vs_mt', 'RSGluon4000', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon4500_fail = functions.getHist2('mtt_vs_mt', 'RSGluon4500', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "            hRSGluon5000_fail = functions.getHist2('mtt_vs_mt', 'RSGluon5000', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            httbar_pass = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "            httbar_fail = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "\n",
    "            # save hists\n",
    "\n",
    "            fttbar[\"MttvsMt\"+catname+\"Pass\"+systname] = httbar_pass\n",
    "            fttbar[\"MttvsMt\"+catname+\"Fail\"+systname] = httbar_fail\n",
    "\n",
    "            f1000[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon1000_pass\n",
    "            f1500[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon1500_pass\n",
    "            f2000[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon2000_pass\n",
    "            f2500[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon2500_pass\n",
    "            f3000[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon3000_pass\n",
    "            f3500[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon3500_pass\n",
    "            f4000[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon4000_pass\n",
    "            f4500[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon4500_pass\n",
    "            f5000[\"MttvsMt\"+catname+\"Pass\"+systname] = hRSGluon5000_pass\n",
    "\n",
    "            f1000[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon1000_fail\n",
    "            f1500[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon1500_fail\n",
    "            f2000[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon2000_fail\n",
    "            f2500[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon2500_fail\n",
    "            f3000[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon3000_fail\n",
    "            f3500[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon3500_fail\n",
    "            f4000[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon4000_fail\n",
    "            f4500[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon4500_fail\n",
    "            f5000[\"MttvsMt\"+catname+\"Fail\"+systname] = hRSGluon5000_fail\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fdata.close()\n",
    "                                                                \n",
    "print('saving '+savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    fttbar.close()\n",
    "    f1000.close()\n",
    "    f1500.close()\n",
    "    f2000.close()\n",
    "    f2500.close()\n",
    "    f3000.close()\n",
    "    f3500.close()\n",
    "    f4000.close()\n",
    "    f4500.close()\n",
    "    f5000.close()\n",
    "    \n",
    "    print('saving '+savefileheader+'TTbar.root')\n",
    "    print('saving '+savefileheader+'RSGluon1000.root')\n",
    "    print('saving '+savefileheader+'RSGluon1500.root')   \n",
    "    print('saving '+savefileheader+'RSGluon2000.root')\n",
    "    print('saving '+savefileheader+'RSGluon2500.root')\n",
    "    print('saving '+savefileheader+'RSGluon3000.root')                                                                  \n",
    "    print('saving '+savefileheader+'RSGluon3500.root')\n",
    "    print('saving '+savefileheader+'RSGluon4000.root')\n",
    "    print('saving '+savefileheader+'RSGluon4500.root')   \n",
    "    print('saving '+savefileheader+'RSGluon5000.root')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81487bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

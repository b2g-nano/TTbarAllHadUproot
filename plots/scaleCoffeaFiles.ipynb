{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49d5c05",
   "metadata": {},
   "source": [
    "## 1) script to scale all histograms in coffea files\n",
    "- saved in outputs/scale/\n",
    "- also scales the cutflow dictionary\n",
    "## 2) adds the scaled files from multiple years.\n",
    "- the histograms in the files must all have the same axes\n",
    "## 3) makes root files for 2DAlphabet\n",
    "- inclusive or split into regions\n",
    "## 4) makes root files for combine\n",
    "- for the previous analysis methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b7c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "from coffea import util\n",
    "import itertools\n",
    "import os, sys\n",
    "import glob\n",
    "import copy\n",
    "import uproot\n",
    "import time\n",
    "\n",
    "sys.path.append('../python/')\n",
    "import functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01159053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QCD': 1370.0,\n",
       " 'TTbar': {'700to1000': 76.605096, '1000toInf': 20.5777424},\n",
       " 'RSGluon': {'1000': 1.0,\n",
       "  '1500': 1.0,\n",
       "  '2000': 1.0,\n",
       "  '2500': 1.0,\n",
       "  '3000': 1.0,\n",
       "  '3500': 1.0,\n",
       "  '4000': 1.0,\n",
       "  '4500': 1.0,\n",
       "  '5000': 1.0,\n",
       "  '5500': 1.0,\n",
       "  '6000': 1.0},\n",
       " 'ZPrime1': {'1000': 1.0,\n",
       "  '1200': 1.0,\n",
       "  '1400': 1.0,\n",
       "  '1600': 1.0,\n",
       "  '1800': 1.0,\n",
       "  '2000': 1.0,\n",
       "  '2500': 1.0,\n",
       "  '3000': 1.0,\n",
       "  '3500': 1.0,\n",
       "  '4000': 1.0,\n",
       "  '4500': 1.0},\n",
       " 'ZPrime10': {'1000': 1.0,\n",
       "  '1200': 1.0,\n",
       "  '1400': 1.0,\n",
       "  '1600': 1.0,\n",
       "  '1800': 1.0,\n",
       "  '2000': 1.0,\n",
       "  '2500': 1.0,\n",
       "  '3000': 1.0,\n",
       "  '3500': 1.0,\n",
       "  '4000': 1.0,\n",
       "  '4500': 1.0,\n",
       "  '5000': 1.0,\n",
       "  '6000': 1.0,\n",
       "  '7000': 1.0},\n",
       " 'ZPrime30': {'1000': 1.0,\n",
       "  '1200': 1.0,\n",
       "  '1400': 1.0,\n",
       "  '1600': 1.0,\n",
       "  '1800': 1.0,\n",
       "  '2000': 1.0,\n",
       "  '2500': 1.0,\n",
       "  '3000': 1.0,\n",
       "  '3500': 1.0,\n",
       "  '4000': 1.0,\n",
       "  '4500': 1.0,\n",
       "  '5000': 1.0,\n",
       "  '6000': 1.0,\n",
       "  '7000': 1.0},\n",
       " 'ZPrimeDM': {'1000': 1.0,\n",
       "  '1500': 1.0,\n",
       "  '2000': 1.0,\n",
       "  '2500': 1.0,\n",
       "  '3000': 1.0,\n",
       "  '3500': 1.0,\n",
       "  '4000': 1.0,\n",
       "  '4500': 1.0,\n",
       "  '5000': 1.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8bd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = {\n",
    "    '2016': 6613811 + 120688407 + 124050331,\n",
    "    '2016APV': 9726665 + 133752091 + 46495988 + 73330042 + 69219288 + 41564915,\n",
    "    '2017': 96264601 + 46145204 + 89630771 + 115429972,\n",
    "    '2018': 171484635 + 78255208 + 70027804 + 356976276,\n",
    "    \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5869d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016': 251352549, '2016APV': 374088989, '2017': 347470548, '2018': 676743923}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.makeSaveDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad61b6",
   "metadata": {},
   "source": [
    "### analysis categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2293a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ analysis category map --------\n",
      "0: at0bcen\n",
      "1: at0bfwd\n",
      "2: at1bcen\n",
      "3: at1bfwd\n",
      "4: at2bcen\n",
      "5: at2bfwd\n",
      "6: pret0bcen\n",
      "7: pret0bfwd\n",
      "8: pret1bcen\n",
      "9: pret1bfwd\n",
      "10: pret2bcen\n",
      "11: pret2bfwd\n",
      "12: 2t0bcen\n",
      "13: 2t0bfwd\n",
      "14: 2t1bcen\n",
      "15: 2t1bfwd\n",
      "16: 2t2bcen\n",
      "17: 2t2bfwd\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "------ coffea file content --------\n",
      "ttbarmass\n",
      "numerator\n",
      "denominator\n",
      "jetmass\n",
      "jetmsd\n",
      "jetpt\n",
      "jeteta\n",
      "jetphi\n",
      "jetp\n",
      "mtt_vs_mt\n",
      "deepak8_over_jetp\n",
      "tau32_over_jetp\n",
      "bdisc_over_jetpt\n",
      "cutflow\n",
      "weights\n",
      "systematics\n",
      "analysisCategories\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "label_map = functions.getLabelMap()\n",
    "label_to_int = {label: i for i, label in label_map.items()}\n",
    "signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "pretag_cats = [ i for label, i in label_to_int.items() if 'pre' in label]\n",
    "antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "\n",
    "\n",
    "\n",
    "print('------ analysis category map --------')\n",
    "for i, lab in label_map.items():\n",
    "    print(f'{i}: {lab}')\n",
    "print('-------------------------------------')\n",
    "\n",
    "\n",
    "print('\\n\\n------ coffea file content --------')\n",
    "\n",
    "for hname in functions.loadCoffeaFile().keys():\n",
    "    print(hname)\n",
    "print('-------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f615b6e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coffeafiles = functions.getCoffeaFilenames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b9816",
   "metadata": {},
   "source": [
    "## 1) Scale histograms in IOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e95aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IOVs = [\n",
    "#     '2016APV',\n",
    "#     '2016',\n",
    "    '2017', \n",
    "#     '2018'\n",
    "]\n",
    "\n",
    "for IOV in IOVs:\n",
    "    \n",
    "    coffeafiles = functions.getCoffeaFilenames()\n",
    "\n",
    "    datasets = [\n",
    "#         'QCD',\n",
    "        'TTbar', \n",
    "        'JetHT', \n",
    "        'RSGluon', \n",
    "        'ZPrime1', \n",
    "        'ZPrime10', \n",
    "        'ZPrime30', \n",
    "        'ZPrimeDM'\n",
    "    ]\n",
    "    \n",
    "\n",
    "    hasBkgEst = False\n",
    "    blind = False #False if '2016' in IOV else True\n",
    "\n",
    "\n",
    "    bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "    blind_str = '_blind' if blind else ''\n",
    "    filetype = 'weighted' if hasBkgEst else 'unweighted'\n",
    "\n",
    "    lumifactor = 0.1 if blind else 1.0\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            coffeafiles[ds][filetype][IOV].keys()\n",
    "            sections = coffeafiles[ds][filetype][IOV].keys()\n",
    "\n",
    "            files = []\n",
    "\n",
    "\n",
    "            for s in sections:\n",
    "\n",
    "                filename = coffeafiles[ds][filetype][IOV][s]\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 filename = filename.replace('outputs/', 'local/history/loose/coffea/')\n",
    "                filename = filename.replace('outputs/', 'outputs/')\n",
    "\n",
    "\n",
    "                if 'JetHT' in ds and blind:\n",
    "                    filename = filename.replace('.coffea', '_blind.coffea')\n",
    "                                \n",
    "                original_file = util.load(filename)\n",
    "\n",
    "                file = copy.deepcopy(original_file)\n",
    "\n",
    "                if 'JetHT' in ds:\n",
    "\n",
    "                    files.append(file)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    factor = 1.0 #functions.toptag_sf**2 if 'TTbar' in ds else 1.0\n",
    "                    sf = functions.lumi[IOV] * lumifactor * functions.xs[ds][s] * factor / file['cutflow']['sumw']\n",
    "                    sf_events = functions.lumi[IOV] * lumifactor * functions.xs[ds][s] / file['cutflow']['all events']\n",
    "                    \n",
    "                    for key in file.keys():\n",
    "\n",
    "                        if 'hist' in str(type(file[key])):\n",
    "                            file[key] = file[key] * sf\n",
    "\n",
    "                        elif 'accumulator' in str(type(file[key])):\n",
    "                            for cut in file[key].keys():\n",
    "                                file[key][cut] = file[key][cut] * sf_events\n",
    "\n",
    "\n",
    "\n",
    "                    files.append(file)\n",
    "\n",
    "                    if 'RSGluon' in ds: \n",
    "\n",
    "                        util.save(file, f'../outputs/scale/{ds}{s}_{IOV}{blind_str}.coffea')\n",
    "                        print(f'saving ../outputs/scale/{ds}{s}_{IOV}{blind_str}.coffea')\n",
    "\n",
    "                    elif 'ZPrime' in ds:\n",
    "\n",
    "                        util.save(file, f'../outputs/scale/ZPrime{s}_{ds.replace(\"ZPrime\",\"\")}_{IOV}{blind_str}.coffea')\n",
    "                        print(f'saving ../outputs/scale/ZPrime{s}_{ds.replace(\"ZPrime\",\"\")}_{IOV}{blind_str}.coffea')\n",
    "\n",
    "\n",
    "            if 'RSGluon' not in ds and 'ZPrime' not in ds:\n",
    "\n",
    "                file = files[0]\n",
    "\n",
    "                for f in files[1:]:\n",
    "                    for key in file.keys():\n",
    "\n",
    "                        if 'hist' in str(type(file[key])):\n",
    "                            file[key] = file[key] + f[key]\n",
    "                            \n",
    "                        elif 'accumulator' in str(type(file[key])):\n",
    "                            for cut in f[key].keys():\n",
    "                                f[key][cut] = f[key][cut] + file[key][cut]\n",
    "\n",
    "                savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}{blind_str}.coffea'\n",
    "                util.save(file, savefilename)\n",
    "                print(f'saving {savefilename}')\n",
    "\n",
    "        except:\n",
    "\n",
    "            filename = coffeafiles[ds][filetype][IOV]\n",
    "            original_file = util.load(filename)\n",
    "            file = copy.deepcopy(original_file)\n",
    "\n",
    "\n",
    "            sf = functions.lumi[IOV] * lumifactor * functions.xs[ds] / file['cutflow']['sumw']\n",
    "            sf_events = functions.lumi[IOV] * lumifactor * functions.xs[ds] / file['cutflow']['all events']\n",
    "\n",
    "\n",
    "            for key in file.keys():\n",
    "                \n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] * sf\n",
    "\n",
    "                elif 'accumulator' in str(type(file[key])):\n",
    "\n",
    "                    for cut in file[key].keys():\n",
    "\n",
    "                        file[key][cut] = file[key][cut] * sf_events\n",
    "\n",
    "            savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}{blind_str}.coffea'\n",
    "            util.save(file, savefilename)\n",
    "            print(f'saving {savefilename}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17389dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.load('../outputs/scale/JetHT_2018.coffea')['jeteta'][{'anacat':sum, 'systematic':'nominal'}].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1004dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n16apv = [\n",
    "        \n",
    "          9726665,\n",
    "        133752091,\n",
    "         46495988,\n",
    "         73330042,\n",
    "         69219288,\n",
    "         41564915\n",
    "]\n",
    "\n",
    "n16 = [\n",
    "        \n",
    "          6613811,\n",
    "        120688407,\n",
    "        124050331 ]\n",
    "\n",
    "n17 = [\n",
    "        \n",
    "         63043590,\n",
    "         96264601,\n",
    "         46145204,\n",
    "         89630771,\n",
    "        115429972,\n",
    "]\n",
    "        \n",
    "n18 =[        171484635,\n",
    "         78255208,\n",
    "         70027804,\n",
    "        356976276\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f597531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(n16apv))\n",
    "print(np.sum(n16))\n",
    "print(np.sum(n16) + np.sum(n16apv))\n",
    "print(np.sum(n17))\n",
    "print(np.sum(n18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498ead3",
   "metadata": {},
   "source": [
    "## 2.1) Combine JetHT files (blinded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOVs = ['2016APV', '2016']#, '2017', '2018']\n",
    "\n",
    "\n",
    "hasBkgEst = True\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "files = []\n",
    "for IOV in IOVs:\n",
    "\n",
    "    file = util.load(f'../outputs/scale/JetHT_{IOV}{bkgest_str}.coffea')\n",
    "    files.append(file)\n",
    "    \n",
    "systs = ['nominal', 'pileupDown', 'pileupUp', 'prefiringDown', 'prefiringUp', 'pdfDown', 'pdfUp', 'btagDown', 'btagUp', 'jesDown', 'jesUp', 'jerDown', 'jerUp']\n",
    "file = files[0]\n",
    "for f in files[1:]:\n",
    "    for key in file.keys():\n",
    "\n",
    "        if 'hist' in str(type(file[key])):\n",
    "            \n",
    "            file[key] = file[key] + f[key]            \n",
    "\n",
    "        elif 'cutflow' in key:\n",
    "            for cut in f[key].keys():\n",
    "                f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "# savefilename = f'../outputs/scale/JetHT_blinded.coffea'\n",
    "\n",
    "if hasBkgEst:\n",
    "    savefilename = f'../outputs/scale/NTMJ_2016all_unblinded.coffea'\n",
    "    \n",
    "else:\n",
    "    savefilename = f'../outputs/scale/JetHT_2016all_unblinded.coffea'\n",
    "\n",
    "\n",
    "util.save(file, savefilename)\n",
    "print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492b8f7",
   "metadata": {},
   "source": [
    "## 2.2) Combine MC files (for plotting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IOVs = ['2016', '2016APV', '2017', '2018']\n",
    "# datasets = ['TTbar', 'QCD', 'JetHT']\n",
    "\n",
    "\n",
    "hasBkgEst = False\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "\n",
    "# add all signal samples\n",
    "datasets = ['RSGluon2000']\n",
    "# datasets = ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "# datasets += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "# datasets += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "# datasets += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "for ds in datasets:\n",
    "    \n",
    "    files = []\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "                \n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_all.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7b5e8",
   "metadata": {},
   "source": [
    "## 2.3) Combine 2016noAPV and 2016APV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6158f64b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ../outputs/scale/RSGluon1000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon1500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon2000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon2500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon3000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon3500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon4000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon4500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon5000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon5500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon6000_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1200_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1400_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1600_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1800_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2500_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3500_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4500_1_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1200_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1400_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1600_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1800_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2500_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3500_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4500_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime5000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime6000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime7000_10_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1200_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1400_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1600_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1800_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2500_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3500_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4500_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime5000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime6000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime7000_30_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime1500_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime2500_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime3500_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime4500_DM_2016all.coffea\n",
      "saving ../outputs/scale/ZPrime5000_DM_2016all.coffea\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "IOVs = ['2016', '2016APV']\n",
    "datasets = ['TTbar', 'QCD', 'JetHT']\n",
    "\n",
    "\n",
    "hasBkgEst = False\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "\n",
    "# add all signal samples\n",
    "datasets = ['RSGluon'+str(int(b*100)) for b in [10,15,20,25,30,35,40,45,50,55,60]]\n",
    "datasets += ['ZPrime'+str(int(b*100))+'_1' for b in [10,12,14,16,18,20,25,30,35,40,45]]\n",
    "datasets += ['ZPrime'+str(int(b*100))+'_10' for b in [10,12,14,16,18,20,25,30,35,40,45,50,60,70]]\n",
    "datasets += ['ZPrime'+str(int(b*100))+'_30' for b in [10,12,14,16,18,20,25,30,35,40,45,50,60,70]]\n",
    "datasets += ['ZPrime'+str(int(b*100))+'_DM' for b in [10,15,20,25,30,35,40,45,50]]\n",
    "\n",
    "for ds in datasets:\n",
    "    \n",
    "    files = []\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "\n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_2016all{bkgest_str}.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee29a26",
   "metadata": {},
   "source": [
    "## 2.4) Scale JetHT files if running over subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc855dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOVs = [\n",
    "#     '2016APV',\n",
    "#     '2016',\n",
    "#     '2017', \n",
    "    '2018'\n",
    "]\n",
    "\n",
    "for IOV in IOVs:\n",
    "    \n",
    "    coffeafiles = functions.getCoffeaFilenames()\n",
    "\n",
    "    datasets = [ 'JetHT' ]\n",
    "    \n",
    "\n",
    "    hasBkgEst = False\n",
    "    blind = False #False if '2016' in IOV else True\n",
    "\n",
    "\n",
    "    bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "    filetype = 'weighted' if hasBkgEst else 'unweighted'\n",
    "\n",
    "    lumifactor = 0.1 if blind else 1.0\n",
    "\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "        sections = coffeafiles[ds][filetype][IOV].keys()\n",
    "\n",
    "        files = []\n",
    "\n",
    "\n",
    "        for s in sections:\n",
    "\n",
    "            filename = coffeafiles[ds][filetype][IOV][s]\n",
    "            original_file = util.load(filename)\n",
    "\n",
    "            file = copy.deepcopy(original_file)\n",
    "\n",
    "            sf = data_events[IOV] / file['cutflow']['all events']\n",
    "\n",
    "            for key in file.keys():\n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] * sf\n",
    "\n",
    "                elif 'cutflow' in key:\n",
    "                    for cut in file[key].keys():\n",
    "                        file[key][cut] = file[key][cut] * sf\n",
    "\n",
    "\n",
    "\n",
    "                files.append(file)\n",
    "\n",
    "\n",
    "        file = files[0]\n",
    "\n",
    "        for f in files[1:]:\n",
    "            for key in file.keys():\n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] + f[key]\n",
    "\n",
    "                elif 'cutflow' in key:\n",
    "                    for cut in f[key].keys():\n",
    "                        f[key][cut] = f[key][cut] + file[key][cut]\n",
    "\n",
    "        savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "        util.save(file, savefilename)\n",
    "        print(f'saving {savefilename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027a0d8",
   "metadata": {},
   "source": [
    "## 3) Make root files for 2DAlphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016all'\n",
    "systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag', 'prefiring']\n",
    "if '2018' in year: systematics[-1] = 'hem'\n",
    "    \n",
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840945aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "\n",
    "year = '2017'\n",
    "\n",
    "\n",
    "\n",
    "systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag', 'prefiring']\n",
    "syst_labels = ['nominal']\n",
    "if '2018' in year: \n",
    "    systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag']\n",
    "\n",
    "for s in systematics:\n",
    "    if not 'nominal' in s and not 'hem' in s:\n",
    "        syst_labels.append(s+'Down')\n",
    "        syst_labels.append(s+'Up')\n",
    "        \n",
    "print(syst_labels)\n",
    "\n",
    "\n",
    "dataOnly = False\n",
    "inclusive = False\n",
    "\n",
    "if inclusive:\n",
    "    \n",
    "    cats, cat_labels = [''], ['']\n",
    "    \n",
    "else:\n",
    "\n",
    "    cats = ['', '0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd']\n",
    "    cat_labels = ['', 'cen0b', 'fwd0b', 'cen1b', 'fwd1b', 'cen2b', 'fwd2b']\n",
    "\n",
    "\n",
    "# signals = ['RSGluon2000']\n",
    "signals = ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "signals += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "signals += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "signals += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "signals += ['ZPrime'+str(int(b*100))+'_1' for b in [10,12,14,18,20,25,30,35,40,45]]\n",
    "\n",
    "\n",
    "\n",
    "savefileheader = '../outputs/combine/categories/TTbarAllHad{}_'.format(year.replace('20', '').replace('all',''))\n",
    "                                                                \n",
    "fdata  = uproot.recreate(savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar = uproot.recreate(savefileheader+'TTbar.root')\n",
    "    sigfiles = [uproot.recreate(savefileheader+'signal'+sig+'.root') for sig in signals ]\n",
    "\n",
    "for cat, catname in zip(cats, cat_labels):\n",
    "    \n",
    "    if cat == '':\n",
    "        \n",
    "        signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "        antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "        sum_axes = ['anacat']\n",
    "\n",
    "    else :\n",
    "        \n",
    "        signal_cats = label_to_int['2t'+cat]\n",
    "        antitag_cats = label_to_int['at'+cat]\n",
    "        sum_axes = []\n",
    "    \n",
    "    for syst in syst_labels:\n",
    "        print(syst, cat)\n",
    "\n",
    "        integrate_pass = {'anacat':signal_cats, 'systematic': syst}\n",
    "#         integrate_fail = {'anacat':antitag_cats, 'systematic': syst}\n",
    "\n",
    "        systname = syst.upper()[:-2] + 'up' if 'Up' in syst else syst.upper()[:-4] + 'down'\n",
    "\n",
    "        if 'nominal' in syst:\n",
    "\n",
    "            systname = ''\n",
    "            hdata_pass = functions.getHist2('ttbarmass', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             hdata_fail = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            fdata[\"data_obs_\"+catname+systname] = hdata_pass\n",
    "#             fdata[\"MttvsMt\"+catname+\"Fail\"+systname] = hdata_fail\n",
    "\n",
    "        if not dataOnly:\n",
    "            \n",
    "            sig_pass = [functions.getHist2('ttbarmass', sig, year, sum_axes=sum_axes, integrate_axes=integrate_pass) for sig in signals]\n",
    "#             sig_fail = [functions.getHist2('mtt_vs_mt', sig, year, sum_axes=sum_axes, integrate_axes=integrate_fail) for sig in signals]\n",
    "\n",
    "            httbar_pass = functions.getHist2('ttbarmass', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             httbar_fail = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "\n",
    "            # save hists\n",
    "\n",
    "            fttbar[\"ttbar_\"+catname+systname] = httbar_pass\n",
    "#             fttbar[\"MttvsMt\"+catname+\"Fail\"+systname] = httbar_fail\n",
    "            \n",
    "            \n",
    "            for i, file in enumerate(sigfiles):\n",
    "#                 print('signal'+str(i)+'_'+catname+systname)\n",
    "                file['ttbarmass_'+catname+systname] = sig_pass[i]\n",
    "#                 file[\"MttvsMt\"+catname+\"Fail\"+systname] = sig_fail[i]\n",
    "\n",
    "\n",
    "fdata.close()\n",
    "                                                                \n",
    "print('saving '+savefileheader+'Data_unblinded.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar.close()\n",
    "    for file in sigfiles:\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "\n",
    "    \n",
    "    print('saving '+savefileheader+'TTbar.root')\n",
    "    \n",
    "    for sig in signals:\n",
    "        print('saving '+savefileheader+sig+'.root')\n",
    "\n",
    "        \n",
    "        \n",
    "tic = time.time()\n",
    "print()\n",
    "functions.printTime(tic-toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a74a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a307c84",
   "metadata": {},
   "source": [
    "## 4) Make root files for combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016all'\n",
    "\n",
    "dataOnly = False\n",
    "inclusive = False\n",
    "\n",
    "if inclusive:\n",
    "    \n",
    "    cats, cat_labels = [''], ['']\n",
    "    \n",
    "else:\n",
    "\n",
    "    cats = ['0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd']\n",
    "    cat_labels = ['cen0b', 'fwd0b', 'cen1b', 'fwd1b', 'cen2b', 'fwd2b']\n",
    "\n",
    "\n",
    "signals = []\n",
    "signals = ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "signals += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "signals += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "signals += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "savefileheader = '../outputs/combine/categories/TTbarAllHad{}_'.format(year.replace('20', '').replace('all',''))\n",
    "                                                                \n",
    "fdata  = uproot.recreate(savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    fttbar = uproot.recreate(savefileheader+'TTbar.root')\n",
    "    \n",
    "    sigfiles = [uproot.recreate(savefileheader+'signal'+sig+'.root') for sig in signals ]\n",
    "\n",
    "for cat, catname in zip(cats, cat_labels):\n",
    "    \n",
    "    if inclusive:\n",
    "        \n",
    "        signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "        antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "        sum_axes = ['anacat']\n",
    "\n",
    "    else :\n",
    "        \n",
    "        signal_cats = label_to_int['2t'+cat]\n",
    "        antitag_cats = label_to_int['at'+cat]\n",
    "        sum_axes = []\n",
    "    \n",
    "    for syst in syst_labels:\n",
    "        print(syst, cat)\n",
    "\n",
    "        integrate_pass = {'anacat':signal_cats, 'systematic': syst}\n",
    "#         integrate_fail = {'anacat':antitag_cats, 'systematic': syst}\n",
    "\n",
    "        systname = syst.upper()[:-2] + 'up' if 'Up' in syst else syst.upper()[:-4] + 'down'\n",
    "\n",
    "        if 'nominal' in syst:\n",
    "\n",
    "            systname = ''\n",
    "            hdata_pass = functions.getHist2('ttbarmass', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             hdata_fail = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            fdata[\"data_obs_\"+catname+systname] = hdata_pass\n",
    "#             fdata[\"MttvsMt\"+catname+\"Fail\"+systname] = hdata_fail\n",
    "\n",
    "        if not dataOnly:\n",
    "            \n",
    "            sig_pass = [functions.getHist2('ttbarmass', sig, year, sum_axes=sum_axes, integrate_axes=integrate_pass) for sig in signals]\n",
    "#             sig_fail = [functions.getHist2('mtt_vs_mt', sig, year, sum_axes=sum_axes, integrate_axes=integrate_fail) for sig in signals]\n",
    "\n",
    "            httbar_pass = functions.getHist2('ttbarmass', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             httbar_fail = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "\n",
    "            # save hists\n",
    "\n",
    "            fttbar[\"ttbar_\"+catname+systname] = httbar_pass\n",
    "#             fttbar[\"MttvsMt\"+catname+\"Fail\"+systname] = httbar_fail\n",
    "            \n",
    "            \n",
    "            for i, file in enumerate(sigfiles):\n",
    "#                 print('signal'+str(i)+'_'+catname+systname)\n",
    "                file['ttbarmass_'+catname+systname] = sig_pass[i]\n",
    "#                 file[\"MttvsMt\"+catname+\"Fail\"+systname] = sig_fail[i]\n",
    "\n",
    "\n",
    "fdata.close()\n",
    "                                                                \n",
    "print('saving '+savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar.close()\n",
    "    for file in sigfiles:\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "\n",
    "    \n",
    "    print('saving '+savefileheader+'TTbar.root')\n",
    "    \n",
    "    for sig in signals:\n",
    "        print('saving '+savefileheader+sig+'.root')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

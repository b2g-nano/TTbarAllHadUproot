{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49d5c05",
   "metadata": {},
   "source": [
    "## 1) script to scale all histograms in coffea files\n",
    "- saved in outputs/scale/\n",
    "- also scales the cutflow dictionary\n",
    "## 2) adds the scaled files from multiple years.\n",
    "- the histograms in the files must all have the same axes\n",
    "## 3) makes root files for 2DAlphabet\n",
    "- inclusive or split into regions\n",
    "## 4) makes root files for combine\n",
    "- for the previous analysis methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b7c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "from coffea import util\n",
    "import itertools\n",
    "import os, sys\n",
    "import glob\n",
    "import copy\n",
    "import uproot\n",
    "import time\n",
    "\n",
    "sys.path.append('../python/')\n",
    "import functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01159053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8bd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = {\n",
    "    '2016': 6613811 + 120688407 + 124050331,\n",
    "    '2016APV': 9726665 + 133752091 + 46495988 + 73330042 + 69219288 + 41564915,\n",
    "    '2017': 96264601 + 46145204 + 89630771 + 115429972,\n",
    "    '2018': 171484635 + 78255208 + 70027804 + 356976276,\n",
    "    \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5869d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016': 251352549, '2016APV': 374088989, '2017': 347470548, '2018': 676743923}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.makeSaveDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad61b6",
   "metadata": {},
   "source": [
    "### analysis categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2293a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ analysis category map --------\n",
      "0: at0bcen\n",
      "1: at0bfwd\n",
      "2: at1bcen\n",
      "3: at1bfwd\n",
      "4: at2bcen\n",
      "5: at2bfwd\n",
      "6: pret0bcen\n",
      "7: pret0bfwd\n",
      "8: pret1bcen\n",
      "9: pret1bfwd\n",
      "10: pret2bcen\n",
      "11: pret2bfwd\n",
      "12: 2t0bcen\n",
      "13: 2t0bfwd\n",
      "14: 2t1bcen\n",
      "15: 2t1bfwd\n",
      "16: 2t2bcen\n",
      "17: 2t2bfwd\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "------ coffea file content --------\n",
      "ttbarmass\n",
      "numerator\n",
      "denominator\n",
      "jetmass\n",
      "jetpt\n",
      "jeteta\n",
      "jetphi\n",
      "jetp\n",
      "discriminators\n",
      "deepak8\n",
      "deepak8_over_jetp\n",
      "tau32_over_jetp\n",
      "bdisc_over_jetpt\n",
      "cutflow\n",
      "weights\n",
      "analysisCategories\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "label_map = functions.getLabelMap()\n",
    "label_to_int = {label: i for i, label in label_map.items()}\n",
    "signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "pretag_cats = [ i for label, i in label_to_int.items() if 'pre' in label]\n",
    "antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "\n",
    "\n",
    "\n",
    "print('------ analysis category map --------')\n",
    "for i, lab in label_map.items():\n",
    "    print(f'{i}: {lab}')\n",
    "print('-------------------------------------')\n",
    "\n",
    "\n",
    "print('\\n\\n------ coffea file content --------')\n",
    "\n",
    "for hname in functions.loadCoffeaFile().keys():\n",
    "    print(hname)\n",
    "print('-------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b9816",
   "metadata": {},
   "source": [
    "## 1) Scale histograms in IOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66e95aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttbarmass <class 'hist.hist.Hist'>\n",
      "numerator <class 'hist.hist.Hist'>\n",
      "denominator <class 'hist.hist.Hist'>\n",
      "jetmass <class 'hist.hist.Hist'>\n",
      "jetmsd <class 'hist.hist.Hist'>\n",
      "jetpt <class 'hist.hist.Hist'>\n",
      "jeteta <class 'hist.hist.Hist'>\n",
      "jetphi <class 'hist.hist.Hist'>\n",
      "jetp <class 'hist.hist.Hist'>\n",
      "discriminators <class 'hist.hist.Hist'>\n",
      "deepak8 <class 'hist.hist.Hist'>\n",
      "mtt_vs_mt <class 'hist.hist.Hist'>\n",
      "deepak8_over_jetp <class 'hist.hist.Hist'>\n",
      "tau32_over_jetp <class 'hist.hist.Hist'>\n",
      "bdisc_over_jetpt <class 'hist.hist.Hist'>\n",
      "cutflow <class 'coffea.processor.accumulator.defaultdict_accumulator'>\n",
      "weights <class 'coffea.processor.accumulator.defaultdict_accumulator'>\n",
      "systematics <class 'coffea.processor.accumulator.defaultdict_accumulator'>\n",
      "analysisCategories <class 'dict'>\n",
      "saving ../outputs/scale/QCD_2018.coffea\n",
      "saving ../outputs/scale/TTbar_2018.coffea\n",
      "saving ../outputs/scale/JetHT_2018.coffea\n"
     ]
    }
   ],
   "source": [
    "IOVs = [\n",
    "#     '2016APV',\n",
    "#     '2016',\n",
    "#     '2017', \n",
    "    '2018'\n",
    "]\n",
    "\n",
    "for IOV in IOVs:\n",
    "    \n",
    "    coffeafiles = functions.getCoffeaFilenames()\n",
    "\n",
    "    datasets = [\n",
    "        'QCD',\n",
    "        'TTbar', \n",
    "        'JetHT', \n",
    "#         'RSGluon', \n",
    "#         'ZPrime10', \n",
    "#         'ZPrime30', \n",
    "#         'ZPrimeDM'\n",
    "    ]\n",
    "    \n",
    "\n",
    "    hasBkgEst = False\n",
    "    blind = False #False if '2016' in IOV else True\n",
    "\n",
    "\n",
    "    bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "    filetype = 'weighted' if hasBkgEst else 'unweighted'\n",
    "\n",
    "    lumifactor = 0.1 if blind else 1.0\n",
    "\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            coffeafiles[ds][filetype][IOV].keys()\n",
    "            sections = coffeafiles[ds][filetype][IOV].keys()\n",
    "\n",
    "            files = []\n",
    "\n",
    "\n",
    "            for s in sections:\n",
    "\n",
    "                filename = coffeafiles[ds][filetype][IOV][s]\n",
    "                original_file = util.load(filename)\n",
    "\n",
    "                file = copy.deepcopy(original_file)\n",
    "\n",
    "                if 'JetHT' in ds:\n",
    "\n",
    "                    files.append(file)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    factor = 1.0 #functions.toptag_sf**2 if 'TTbar' in ds else 1.0\n",
    "                    sf = functions.lumi[IOV] * lumifactor * functions.xs[ds][s] * factor / file['cutflow']['sumw']\n",
    "                    sf_events = functions.lumi[IOV] * lumifactor * functions.xs[ds][s] / file['cutflow']['all events']\n",
    "                    \n",
    "                    for key in file.keys():\n",
    "\n",
    "                        if 'hist' in str(type(file[key])):\n",
    "                            file[key] = file[key] * sf\n",
    "\n",
    "                        elif 'accumulator' in str(type(file[key])):\n",
    "                            for cut in file[key].keys():\n",
    "                                file[key][cut] = file[key][cut] * sf_events\n",
    "\n",
    "\n",
    "\n",
    "                    files.append(file)\n",
    "\n",
    "                    if 'RSGluon' in ds: \n",
    "\n",
    "                        util.save(file, f'../outputs/scale/{ds}{s}_{IOV}.coffea')\n",
    "                        print(f'saving ../outputs/scale/{ds}{s}_{IOV}.coffea')\n",
    "\n",
    "                    elif 'ZPrime' in ds:\n",
    "\n",
    "                        util.save(file, f'../outputs/scale/ZPrime{s}_{ds.replace(\"ZPrime\",\"\")}_{IOV}.coffea')\n",
    "                        print(f'saving ../outputs/scale/ZPrime{s}_{ds.replace(\"ZPrime\",\"\")}_{IOV}.coffea')\n",
    "\n",
    "\n",
    "            if 'RSGluon' not in ds and 'ZPrime' not in ds:\n",
    "\n",
    "                file = files[0]\n",
    "\n",
    "                for f in files[1:]:\n",
    "                    for key in file.keys():\n",
    "\n",
    "                        if 'hist' in str(type(file[key])):\n",
    "                            file[key] = file[key] + f[key]\n",
    "\n",
    "                        elif 'accumulator' in str(type(file[key])):\n",
    "                            for cut in f[key].keys():\n",
    "                                f[key][cut] = f[key][cut] + file[key][cut]\n",
    "\n",
    "                savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "                util.save(file, savefilename)\n",
    "                print(f'saving {savefilename}')\n",
    "\n",
    "        except:\n",
    "\n",
    "            filename = coffeafiles[ds][filetype][IOV]\n",
    "            original_file = util.load(filename)\n",
    "            file = copy.deepcopy(original_file)\n",
    "\n",
    "\n",
    "            sf = functions.lumi[IOV] * lumifactor * functions.xs[ds] / file['cutflow']['sumw']\n",
    "            sf_events = functions.lumi[IOV] * lumifactor * functions.xs[ds] / file['cutflow']['all events']\n",
    "\n",
    "\n",
    "            for key in file.keys():\n",
    "                \n",
    "                print(key , str(type(file[key])))\n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] * sf\n",
    "\n",
    "                elif 'accumulator' in str(type(file[key])):\n",
    "\n",
    "                    for cut in file[key].keys():\n",
    "\n",
    "                        file[key][cut] = file[key][cut] * sf_events\n",
    "\n",
    "            savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "            util.save(file, savefilename)\n",
    "            print(f'saving {savefilename}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498ead3",
   "metadata": {},
   "source": [
    "## 2.1) Combine JetHT files (blinded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436ee8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ../outputs/scale/NTMJ_2016all_unblinded.coffea\n"
     ]
    }
   ],
   "source": [
    "IOVs = ['2016APV', '2016']#, '2017', '2018']\n",
    "\n",
    "\n",
    "hasBkgEst = True\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "files = []\n",
    "for IOV in IOVs:\n",
    "\n",
    "    file = util.load(f'../outputs/scale/JetHT_{IOV}{bkgest_str}.coffea')\n",
    "    files.append(file)\n",
    "    \n",
    "systs = ['nominal', 'pileupDown', 'pileupUp', 'prefiringDown', 'prefiringUp', 'pdfDown', 'pdfUp', 'btagDown', 'btagUp', 'jesDown', 'jesUp', 'jerDown', 'jerUp']\n",
    "file = files[0]\n",
    "for f in files[1:]:\n",
    "    for key in file.keys():\n",
    "\n",
    "        if 'hist' in str(type(file[key])):\n",
    "            \n",
    "            file[key] = file[key] + f[key]            \n",
    "\n",
    "        elif 'cutflow' in key:\n",
    "            for cut in f[key].keys():\n",
    "                f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "# savefilename = f'../outputs/scale/JetHT_blinded.coffea'\n",
    "\n",
    "if hasBkgEst:\n",
    "    savefilename = f'../outputs/scale/NTMJ_2016all_unblinded.coffea'\n",
    "    \n",
    "else:\n",
    "    savefilename = f'../outputs/scale/JetHT_2016all_unblinded.coffea'\n",
    "\n",
    "\n",
    "util.save(file, savefilename)\n",
    "print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492b8f7",
   "metadata": {},
   "source": [
    "## 2.2) Combine MC files (for plotting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dc1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ../outputs/scale/QCD_all.coffea\n",
      "saving ../outputs/scale/TTbar_all.coffea\n",
      "saving ../outputs/scale/RSGluon1000_all.coffea\n",
      "saving ../outputs/scale/RSGluon1500_all.coffea\n",
      "saving ../outputs/scale/RSGluon2000_all.coffea\n",
      "saving ../outputs/scale/RSGluon2500_all.coffea\n",
      "saving ../outputs/scale/RSGluon3000_all.coffea\n",
      "saving ../outputs/scale/RSGluon3500_all.coffea\n",
      "saving ../outputs/scale/RSGluon4000_all.coffea\n",
      "saving ../outputs/scale/RSGluon4500_all.coffea\n",
      "saving ../outputs/scale/RSGluon5000_all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime1500_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime2500_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime3500_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime4500_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime5000_DM_all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_10_all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_10_all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_10_all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_10_all.coffea\n",
      "saving ../outputs/scale/ZPrime1000_30_all.coffea\n",
      "saving ../outputs/scale/ZPrime2000_30_all.coffea\n",
      "saving ../outputs/scale/ZPrime3000_30_all.coffea\n",
      "saving ../outputs/scale/ZPrime4000_30_all.coffea\n"
     ]
    }
   ],
   "source": [
    "IOVs = ['2016APV', '2016']\n",
    "datasets = ['QCD', 'TTbar']\n",
    "\n",
    "files = []\n",
    "\n",
    "\n",
    "# all all RSGluon samples\n",
    "datasets += ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "datasets += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "datasets += ['ZPrime'+str(int(b))+'_10' for b in np.linspace(1000,4000,4)]\n",
    "datasets += ['ZPrime'+str(int(b))+'_30' for b in np.linspace(1000,4000,4)]\n",
    "\n",
    "for ds in datasets:\n",
    "\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_all.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7b5e8",
   "metadata": {},
   "source": [
    "## 2.3) Combine 2016noAPV and 2016APV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6158f64b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ../outputs/scale/TTbar_2016all.coffea\n",
      "saving ../outputs/scale/QCD_2016all.coffea\n",
      "saving ../outputs/scale/JetHT_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon1000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon1500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon2000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon2500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon3000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon3500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon4000_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon4500_2016all.coffea\n",
      "saving ../outputs/scale/RSGluon5000_2016all.coffea\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "IOVs = ['2016', '2016APV']\n",
    "datasets = ['TTbar', 'QCD', 'JetHT']\n",
    "\n",
    "\n",
    "hasBkgEst = False\n",
    "bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "\n",
    "\n",
    "# add all signal samples\n",
    "datasets += ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "# datasets += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "# datasets += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "# datasets += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "for ds in datasets:\n",
    "    \n",
    "    files = []\n",
    "    for IOV in IOVs:\n",
    "\n",
    "        file = util.load(f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea')\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "    file = files[0]\n",
    "    for f in files[1:]:\n",
    "        for key in file.keys():\n",
    "\n",
    "            if 'hist' in str(type(file[key])):\n",
    "\n",
    "                file[key] = file[key] + f[key]\n",
    "\n",
    "            elif 'cutflow' in key:\n",
    "                for cut in f[key].keys():\n",
    "                    f[key][cut] = f[key][cut] + file[key][cut]  \n",
    "\n",
    "    savefilename = f'../outputs/scale/{ds}_2016all{bkgest_str}.coffea'\n",
    "    util.save(file, savefilename)\n",
    "    print(f'saving {savefilename}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee29a26",
   "metadata": {},
   "source": [
    "## 2.4) Scale JetHT files if running over subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc855dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ../outputs/scale/JetHT_2018.coffea\n"
     ]
    }
   ],
   "source": [
    "IOVs = [\n",
    "#     '2016APV',\n",
    "#     '2016',\n",
    "#     '2017', \n",
    "    '2018'\n",
    "]\n",
    "\n",
    "for IOV in IOVs:\n",
    "    \n",
    "    coffeafiles = functions.getCoffeaFilenames()\n",
    "\n",
    "    datasets = [ 'JetHT' ]\n",
    "    \n",
    "\n",
    "    hasBkgEst = False\n",
    "    blind = False #False if '2016' in IOV else True\n",
    "\n",
    "\n",
    "    bkgest_str = '_bkgest' if hasBkgEst else ''\n",
    "    filetype = 'weighted' if hasBkgEst else 'unweighted'\n",
    "\n",
    "    lumifactor = 0.1 if blind else 1.0\n",
    "\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "        sections = coffeafiles[ds][filetype][IOV].keys()\n",
    "\n",
    "        files = []\n",
    "\n",
    "\n",
    "        for s in sections:\n",
    "\n",
    "            filename = coffeafiles[ds][filetype][IOV][s]\n",
    "            original_file = util.load(filename)\n",
    "\n",
    "            file = copy.deepcopy(original_file)\n",
    "\n",
    "            sf = data_events[IOV] / file['cutflow']['all events']\n",
    "\n",
    "            for key in file.keys():\n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] * sf\n",
    "\n",
    "                elif 'cutflow' in key:\n",
    "                    for cut in file[key].keys():\n",
    "                        file[key][cut] = file[key][cut] * sf\n",
    "\n",
    "\n",
    "\n",
    "                files.append(file)\n",
    "\n",
    "\n",
    "        file = files[0]\n",
    "\n",
    "        for f in files[1:]:\n",
    "            for key in file.keys():\n",
    "\n",
    "                if 'hist' in str(type(file[key])):\n",
    "                    file[key] = file[key] + f[key]\n",
    "\n",
    "                elif 'cutflow' in key:\n",
    "                    for cut in f[key].keys():\n",
    "                        f[key][cut] = f[key][cut] + file[key][cut]\n",
    "\n",
    "        savefilename = f'../outputs/scale/{ds}_{IOV}{bkgest_str}.coffea'\n",
    "        util.save(file, savefilename)\n",
    "        print(f'saving {savefilename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027a0d8",
   "metadata": {},
   "source": [
    "## 3) Make root files for 2DAlphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8260b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nominal', 'jesDown', 'jesUp', 'jerDown', 'jerUp', 'pileupDown', 'pileupUp', 'pdfDown', 'pdfUp', 'q2Down', 'q2Up', 'btagDown', 'btagUp', 'prefiringDown', 'prefiringUp']\n"
     ]
    }
   ],
   "source": [
    "year = '2016all'\n",
    "systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag', 'prefiring']\n",
    "if '2018' in year: systematics[-1] = 'hem'\n",
    "    \n",
    "systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "840945aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nominal 0bcen\n",
      "jesDown 0bcen\n",
      "jesUp 0bcen\n",
      "jerDown 0bcen\n",
      "jerUp 0bcen\n",
      "pileupDown 0bcen\n",
      "pileupUp 0bcen\n",
      "pdfDown 0bcen\n",
      "pdfUp 0bcen\n",
      "q2Down 0bcen\n",
      "q2Up 0bcen\n",
      "btagDown 0bcen\n",
      "btagUp 0bcen\n",
      "prefiringDown 0bcen\n",
      "prefiringUp 0bcen\n",
      "nominal 0bfwd\n",
      "jesDown 0bfwd\n",
      "jesUp 0bfwd\n",
      "jerDown 0bfwd\n",
      "jerUp 0bfwd\n",
      "pileupDown 0bfwd\n",
      "pileupUp 0bfwd\n",
      "pdfDown 0bfwd\n",
      "pdfUp 0bfwd\n",
      "q2Down 0bfwd\n",
      "q2Up 0bfwd\n",
      "btagDown 0bfwd\n",
      "btagUp 0bfwd\n",
      "prefiringDown 0bfwd\n",
      "prefiringUp 0bfwd\n",
      "nominal 1bcen\n",
      "jesDown 1bcen\n",
      "jesUp 1bcen\n",
      "jerDown 1bcen\n",
      "jerUp 1bcen\n",
      "pileupDown 1bcen\n",
      "pileupUp 1bcen\n",
      "pdfDown 1bcen\n",
      "pdfUp 1bcen\n",
      "q2Down 1bcen\n",
      "q2Up 1bcen\n",
      "btagDown 1bcen\n",
      "btagUp 1bcen\n",
      "prefiringDown 1bcen\n",
      "prefiringUp 1bcen\n",
      "nominal 1bfwd\n",
      "jesDown 1bfwd\n",
      "jesUp 1bfwd\n",
      "jerDown 1bfwd\n",
      "jerUp 1bfwd\n",
      "pileupDown 1bfwd\n",
      "pileupUp 1bfwd\n",
      "pdfDown 1bfwd\n",
      "pdfUp 1bfwd\n",
      "q2Down 1bfwd\n",
      "q2Up 1bfwd\n",
      "btagDown 1bfwd\n",
      "btagUp 1bfwd\n",
      "prefiringDown 1bfwd\n",
      "prefiringUp 1bfwd\n",
      "nominal 2bcen\n",
      "jesDown 2bcen\n",
      "jesUp 2bcen\n",
      "jerDown 2bcen\n",
      "jerUp 2bcen\n",
      "pileupDown 2bcen\n",
      "pileupUp 2bcen\n",
      "pdfDown 2bcen\n",
      "pdfUp 2bcen\n",
      "q2Down 2bcen\n",
      "q2Up 2bcen\n",
      "btagDown 2bcen\n",
      "btagUp 2bcen\n",
      "prefiringDown 2bcen\n",
      "prefiringUp 2bcen\n",
      "nominal 2bfwd\n",
      "jesDown 2bfwd\n",
      "jesUp 2bfwd\n",
      "jerDown 2bfwd\n",
      "jerUp 2bfwd\n",
      "pileupDown 2bfwd\n",
      "pileupUp 2bfwd\n",
      "pdfDown 2bfwd\n",
      "pdfUp 2bfwd\n",
      "q2Down 2bfwd\n",
      "q2Up 2bfwd\n",
      "btagDown 2bfwd\n",
      "btagUp 2bfwd\n",
      "prefiringDown 2bfwd\n",
      "prefiringUp 2bfwd\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_Data.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_TTbar.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon1000.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon1500.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon2000.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon2500.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon3000.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon3500.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon4000.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon4500.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_RSGluon5000.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime1000_10.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime2000_10.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime3000_10.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime4000_10.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime1000_30.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime2000_30.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime3000_30.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime4000_30.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime1000_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime1500_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime2000_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime2500_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime3000_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime3500_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime4000_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime4500_DM.root\n",
      "saving ../outputs/combine/categories/TTbarAllHad16_ZPrime5000_DM.root\n"
     ]
    }
   ],
   "source": [
    "toc = time.time()\n",
    "\n",
    "year = '2017'\n",
    "\n",
    "\n",
    "\n",
    "systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag', 'prefiring']\n",
    "syst_labels = ['nominal']\n",
    "if '2018' in year: \n",
    "    systematics = ['nominal', 'jes', 'jer', 'pileup', 'pdf', 'q2', 'btag']\n",
    "\n",
    "for s in systematics:\n",
    "    if not 'nominal' in s and not 'hem' in s:\n",
    "        syst_labels.append(s+'Down')\n",
    "        syst_labels.append(s+'Up')\n",
    "        \n",
    "print(syst_labels)\n",
    "\n",
    "\n",
    "dataOnly = False\n",
    "inclusive = False\n",
    "\n",
    "if inclusive:\n",
    "    \n",
    "    cats, cat_labels = [''], ['']\n",
    "    \n",
    "else:\n",
    "\n",
    "    cats = ['', '0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd']\n",
    "    cat_labels = ['', 'cen0b', 'fwd0b', 'cen1b', 'fwd1b', 'cen2b', 'fwd2b']\n",
    "\n",
    "\n",
    "# signals = ['RSGluon2000']\n",
    "signals = ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "signals += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "signals += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "signals += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "savefileheader = '../outputs/combine/categories/TTbarAllHad{}_'.format(year.replace('20', '').replace('all',''))\n",
    "                                                                \n",
    "fdata  = uproot.recreate(savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar = uproot.recreate(savefileheader+'TTbar.root')\n",
    "    sigfiles = [uproot.recreate(savefileheader+'signal'+sig+'.root') for sig in signals ]\n",
    "\n",
    "for cat, catname in zip(cats, cat_labels):\n",
    "    \n",
    "    if cat == '':\n",
    "        \n",
    "        signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "        antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "        sum_axes = ['anacat']\n",
    "\n",
    "    else :\n",
    "        \n",
    "        signal_cats = label_to_int['2t'+cat]\n",
    "        antitag_cats = label_to_int['at'+cat]\n",
    "        sum_axes = []\n",
    "    \n",
    "    for syst in syst_labels:\n",
    "        print(syst, cat)\n",
    "\n",
    "        integrate_pass = {'anacat':signal_cats, 'systematic': syst}\n",
    "#         integrate_fail = {'anacat':antitag_cats, 'systematic': syst}\n",
    "\n",
    "        systname = syst.upper()[:-2] + 'up' if 'Up' in syst else syst.upper()[:-4] + 'down'\n",
    "\n",
    "        if 'nominal' in syst:\n",
    "\n",
    "            systname = ''\n",
    "            hdata_pass = functions.getHist2('ttbarmass', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             hdata_fail = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            fdata[\"data_obs_\"+catname+systname] = hdata_pass\n",
    "#             fdata[\"MttvsMt\"+catname+\"Fail\"+systname] = hdata_fail\n",
    "\n",
    "        if not dataOnly:\n",
    "            \n",
    "            sig_pass = [functions.getHist2('ttbarmass', sig, year, sum_axes=sum_axes, integrate_axes=integrate_pass) for sig in signals]\n",
    "#             sig_fail = [functions.getHist2('mtt_vs_mt', sig, year, sum_axes=sum_axes, integrate_axes=integrate_fail) for sig in signals]\n",
    "\n",
    "            httbar_pass = functions.getHist2('ttbarmass', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             httbar_fail = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "\n",
    "            # save hists\n",
    "\n",
    "            fttbar[\"ttbar_\"+catname+systname] = httbar_pass\n",
    "#             fttbar[\"MttvsMt\"+catname+\"Fail\"+systname] = httbar_fail\n",
    "            \n",
    "            \n",
    "            for i, file in enumerate(sigfiles):\n",
    "#                 print('signal'+str(i)+'_'+catname+systname)\n",
    "                file['ttbarmass_'+catname+systname] = sig_pass[i]\n",
    "#                 file[\"MttvsMt\"+catname+\"Fail\"+systname] = sig_fail[i]\n",
    "\n",
    "\n",
    "fdata.close()\n",
    "                                                                \n",
    "print('saving '+savefileheader+'Data_unblinded.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar.close()\n",
    "    for file in sigfiles:\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "\n",
    "    \n",
    "    print('saving '+savefileheader+'TTbar.root')\n",
    "    \n",
    "    for sig in signals:\n",
    "        print('saving '+savefileheader+sig+'.root')\n",
    "\n",
    "        \n",
    "        \n",
    "tic = time.time()\n",
    "print()\n",
    "functions.printTime(tic-toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a74a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a307c84",
   "metadata": {},
   "source": [
    "## 4) Make root files for combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2016all'\n",
    "\n",
    "dataOnly = False\n",
    "inclusive = False\n",
    "\n",
    "if inclusive:\n",
    "    \n",
    "    cats, cat_labels = [''], ['']\n",
    "    \n",
    "else:\n",
    "\n",
    "    cats = ['0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd']\n",
    "    cat_labels = ['cen0b', 'fwd0b', 'cen1b', 'fwd1b', 'cen2b', 'fwd2b']\n",
    "\n",
    "\n",
    "signals = []\n",
    "signals = ['RSGluon'+str(int(b)) for b in np.linspace(1000,5000,9)]\n",
    "signals += ['ZPrime1000_10', 'ZPrime2000_10', 'ZPrime3000_10', 'ZPrime4000_10']\n",
    "signals += ['ZPrime1000_30', 'ZPrime2000_30', 'ZPrime3000_30', 'ZPrime4000_30']\n",
    "signals += ['ZPrime'+str(int(b))+'_DM' for b in np.linspace(1000,5000,9)]\n",
    "\n",
    "\n",
    "savefileheader = '../outputs/combine/categories/TTbarAllHad{}_'.format(year.replace('20', '').replace('all',''))\n",
    "                                                                \n",
    "fdata  = uproot.recreate(savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    fttbar = uproot.recreate(savefileheader+'TTbar.root')\n",
    "    \n",
    "    sigfiles = [uproot.recreate(savefileheader+'signal'+sig+'.root') for sig in signals ]\n",
    "\n",
    "for cat, catname in zip(cats, cat_labels):\n",
    "    \n",
    "    if inclusive:\n",
    "        \n",
    "        signal_cats = [ i for label, i in label_to_int.items() if '2t' in label]\n",
    "        antitag_cats = [ i for label, i in label_to_int.items() if 'at' in label]\n",
    "        sum_axes = ['anacat']\n",
    "\n",
    "    else :\n",
    "        \n",
    "        signal_cats = label_to_int['2t'+cat]\n",
    "        antitag_cats = label_to_int['at'+cat]\n",
    "        sum_axes = []\n",
    "    \n",
    "    for syst in syst_labels:\n",
    "        print(syst, cat)\n",
    "\n",
    "        integrate_pass = {'anacat':signal_cats, 'systematic': syst}\n",
    "#         integrate_fail = {'anacat':antitag_cats, 'systematic': syst}\n",
    "\n",
    "        systname = syst.upper()[:-2] + 'up' if 'Up' in syst else syst.upper()[:-4] + 'down'\n",
    "\n",
    "        if 'nominal' in syst:\n",
    "\n",
    "            systname = ''\n",
    "            hdata_pass = functions.getHist2('ttbarmass', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             hdata_fail = functions.getHist2('mtt_vs_mt', 'JetHT', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "            fdata[\"data_obs_\"+catname+systname] = hdata_pass\n",
    "#             fdata[\"MttvsMt\"+catname+\"Fail\"+systname] = hdata_fail\n",
    "\n",
    "        if not dataOnly:\n",
    "            \n",
    "            sig_pass = [functions.getHist2('ttbarmass', sig, year, sum_axes=sum_axes, integrate_axes=integrate_pass) for sig in signals]\n",
    "#             sig_fail = [functions.getHist2('mtt_vs_mt', sig, year, sum_axes=sum_axes, integrate_axes=integrate_fail) for sig in signals]\n",
    "\n",
    "            httbar_pass = functions.getHist2('ttbarmass', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_pass) \n",
    "#             httbar_fail = functions.getHist2('mtt_vs_mt', 'TTbar', year, sum_axes=sum_axes, integrate_axes=integrate_fail) \n",
    "\n",
    "\n",
    "            # save hists\n",
    "\n",
    "            fttbar[\"ttbar_\"+catname+systname] = httbar_pass\n",
    "#             fttbar[\"MttvsMt\"+catname+\"Fail\"+systname] = httbar_fail\n",
    "            \n",
    "            \n",
    "            for i, file in enumerate(sigfiles):\n",
    "#                 print('signal'+str(i)+'_'+catname+systname)\n",
    "                file['ttbarmass_'+catname+systname] = sig_pass[i]\n",
    "#                 file[\"MttvsMt\"+catname+\"Fail\"+systname] = sig_fail[i]\n",
    "\n",
    "\n",
    "fdata.close()\n",
    "                                                                \n",
    "print('saving '+savefileheader+'Data.root')\n",
    "\n",
    "if not dataOnly:\n",
    "    \n",
    "    fttbar.close()\n",
    "    for file in sigfiles:\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "\n",
    "    \n",
    "    print('saving '+savefileheader+'TTbar.root')\n",
    "    \n",
    "    for sig in signals:\n",
    "        print('saving '+savefileheader+sig+'.root')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
